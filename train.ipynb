{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf03d987-b2dc-4f35-9de3-141ab32631db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1/1000: 100%|█████████████| 63/63 [00:01<00:00, 39.88batch/s, loss=0.3492]\n",
      "Epoch 1/1000, Training Loss: 0.5974\n",
      "Epoch 1/1000, Validation Loss: 0.2681\n",
      "Epoch 2/1000: 100%|█████████████| 63/63 [00:01<00:00, 43.16batch/s, loss=0.1301]\n",
      "Epoch 2/1000, Training Loss: 0.2389\n",
      "Epoch 2/1000, Validation Loss: 0.1704\n",
      "Epoch 3/1000: 100%|█████████████| 63/63 [00:01<00:00, 41.23batch/s, loss=0.2163]\n",
      "Epoch 3/1000, Training Loss: 0.1879\n",
      "Epoch 3/1000, Validation Loss: 0.1437\n",
      "Epoch 4/1000: 100%|█████████████| 63/63 [00:01<00:00, 41.11batch/s, loss=0.1891]\n",
      "Epoch 4/1000, Training Loss: 0.1567\n",
      "Epoch 4/1000, Validation Loss: 0.1218\n",
      "Epoch 5/1000: 100%|█████████████| 63/63 [00:01<00:00, 41.78batch/s, loss=0.0862]\n",
      "Epoch 5/1000, Training Loss: 0.1390\n",
      "Epoch 5/1000, Validation Loss: 0.1077\n",
      "Epoch 6/1000: 100%|█████████████| 63/63 [00:01<00:00, 44.41batch/s, loss=0.0970]\n",
      "Epoch 6/1000, Training Loss: 0.1306\n",
      "Epoch 6/1000, Validation Loss: 0.1056\n",
      "Epoch 7/1000: 100%|█████████████| 63/63 [00:01<00:00, 42.23batch/s, loss=0.0794]\n",
      "Epoch 7/1000, Training Loss: 0.1192\n",
      "Epoch 7/1000, Validation Loss: 0.0938\n",
      "Epoch 8/1000: 100%|█████████████| 63/63 [00:01<00:00, 42.82batch/s, loss=0.1576]\n",
      "Epoch 8/1000, Training Loss: 0.1080\n",
      "Epoch 8/1000, Validation Loss: 0.0852\n",
      "Epoch 9/1000: 100%|█████████████| 63/63 [00:01<00:00, 42.18batch/s, loss=0.0967]\n",
      "Epoch 9/1000, Training Loss: 0.1005\n",
      "Epoch 9/1000, Validation Loss: 0.0859\n",
      "Epoch 10/1000: 100%|████████████| 63/63 [00:01<00:00, 43.07batch/s, loss=0.0723]\n",
      "Epoch 10/1000, Training Loss: 0.1054\n",
      "Epoch 10/1000, Validation Loss: 0.0887\n",
      "Epoch 11/1000: 100%|████████████| 63/63 [00:01<00:00, 42.94batch/s, loss=0.1019]\n",
      "Epoch 11/1000, Training Loss: 0.0960\n",
      "Epoch 11/1000, Validation Loss: 0.0785\n",
      "Epoch 12/1000: 100%|████████████| 63/63 [00:01<00:00, 45.25batch/s, loss=0.0815]\n",
      "Epoch 12/1000, Training Loss: 0.0934\n",
      "Epoch 12/1000, Validation Loss: 0.0739\n",
      "Epoch 13/1000: 100%|████████████| 63/63 [00:01<00:00, 43.31batch/s, loss=0.0796]\n",
      "Epoch 13/1000, Training Loss: 0.0915\n",
      "Epoch 13/1000, Validation Loss: 0.0729\n",
      "Epoch 14/1000: 100%|████████████| 63/63 [00:01<00:00, 43.29batch/s, loss=0.0730]\n",
      "Epoch 14/1000, Training Loss: 0.0858\n",
      "Epoch 14/1000, Validation Loss: 0.0662\n",
      "Epoch 15/1000: 100%|████████████| 63/63 [00:01<00:00, 42.13batch/s, loss=0.1113]\n",
      "Epoch 15/1000, Training Loss: 0.0830\n",
      "Epoch 15/1000, Validation Loss: 0.0652\n",
      "Epoch 16/1000: 100%|████████████| 63/63 [00:01<00:00, 41.66batch/s, loss=0.1372]\n",
      "Epoch 16/1000, Training Loss: 0.0799\n",
      "Epoch 16/1000, Validation Loss: 0.0643\n",
      "Epoch 17/1000: 100%|████████████| 63/63 [00:01<00:00, 41.93batch/s, loss=0.0578]\n",
      "Epoch 17/1000, Training Loss: 0.0820\n",
      "Epoch 17/1000, Validation Loss: 0.0646\n",
      "Epoch 18/1000: 100%|████████████| 63/63 [00:01<00:00, 42.71batch/s, loss=0.0777]\n",
      "Epoch 18/1000, Training Loss: 0.0791\n",
      "Epoch 18/1000, Validation Loss: 0.0620\n",
      "Epoch 19/1000: 100%|████████████| 63/63 [00:01<00:00, 42.81batch/s, loss=0.0805]\n",
      "Epoch 19/1000, Training Loss: 0.0784\n",
      "Epoch 19/1000, Validation Loss: 0.0584\n",
      "Epoch 20/1000: 100%|████████████| 63/63 [00:01<00:00, 42.13batch/s, loss=0.1133]\n",
      "Epoch 20/1000, Training Loss: 0.0767\n",
      "Epoch 20/1000, Validation Loss: 0.0604\n",
      "Epoch 21/1000: 100%|████████████| 63/63 [00:01<00:00, 41.25batch/s, loss=0.0575]\n",
      "Epoch 21/1000, Training Loss: 0.0727\n",
      "Epoch 21/1000, Validation Loss: 0.0667\n",
      "Epoch 22/1000: 100%|████████████| 63/63 [00:01<00:00, 42.06batch/s, loss=0.0556]\n",
      "Epoch 22/1000, Training Loss: 0.0764\n",
      "Epoch 22/1000, Validation Loss: 0.0627\n",
      "Epoch 23/1000: 100%|████████████| 63/63 [00:01<00:00, 42.34batch/s, loss=0.0463]\n",
      "Epoch 23/1000, Training Loss: 0.0730\n",
      "Epoch 23/1000, Validation Loss: 0.0589\n",
      "Epoch 24/1000: 100%|████████████| 63/63 [00:01<00:00, 42.47batch/s, loss=0.0260]\n",
      "Epoch 24/1000, Training Loss: 0.0717\n",
      "Epoch 24/1000, Validation Loss: 0.0582\n",
      "Epoch 25/1000: 100%|████████████| 63/63 [00:01<00:00, 40.70batch/s, loss=0.0416]\n",
      "Epoch 25/1000, Training Loss: 0.0686\n",
      "Epoch 25/1000, Validation Loss: 0.0557\n",
      "Epoch 26/1000: 100%|████████████| 63/63 [00:01<00:00, 41.80batch/s, loss=0.0975]\n",
      "Epoch 26/1000, Training Loss: 0.0706\n",
      "Epoch 26/1000, Validation Loss: 0.0575\n",
      "Epoch 27/1000: 100%|████████████| 63/63 [00:01<00:00, 42.32batch/s, loss=0.0606]\n",
      "Epoch 27/1000, Training Loss: 0.0665\n",
      "Epoch 27/1000, Validation Loss: 0.0521\n",
      "Epoch 28/1000: 100%|████████████| 63/63 [00:01<00:00, 40.99batch/s, loss=0.0316]\n",
      "Epoch 28/1000, Training Loss: 0.0671\n",
      "Epoch 28/1000, Validation Loss: 0.0596\n",
      "Epoch 29/1000: 100%|████████████| 63/63 [00:01<00:00, 41.48batch/s, loss=0.1060]\n",
      "Epoch 29/1000, Training Loss: 0.0684\n",
      "Epoch 29/1000, Validation Loss: 0.0543\n",
      "Epoch 30/1000: 100%|████████████| 63/63 [00:01<00:00, 42.37batch/s, loss=0.0650]\n",
      "Epoch 30/1000, Training Loss: 0.0682\n",
      "Epoch 30/1000, Validation Loss: 0.0624\n",
      "Epoch 31/1000: 100%|████████████| 63/63 [00:01<00:00, 42.37batch/s, loss=0.0978]\n",
      "Epoch 31/1000, Training Loss: 0.0668\n",
      "Epoch 31/1000, Validation Loss: 0.0545\n",
      "Epoch 32/1000: 100%|████████████| 63/63 [00:01<00:00, 42.23batch/s, loss=0.0624]\n",
      "Epoch 32/1000, Training Loss: 0.0712\n",
      "Epoch 32/1000, Validation Loss: 0.0531\n",
      "Epoch 33/1000: 100%|████████████| 63/63 [00:01<00:00, 42.11batch/s, loss=0.1149]\n",
      "Epoch 33/1000, Training Loss: 0.0671\n",
      "Epoch 33/1000, Validation Loss: 0.0519\n",
      "Epoch 34/1000: 100%|████████████| 63/63 [00:01<00:00, 41.86batch/s, loss=0.0762]\n",
      "Epoch 34/1000, Training Loss: 0.0657\n",
      "Epoch 34/1000, Validation Loss: 0.0550\n",
      "Epoch 35/1000: 100%|████████████| 63/63 [00:01<00:00, 41.96batch/s, loss=0.0771]\n",
      "Epoch 35/1000, Training Loss: 0.0627\n",
      "Epoch 35/1000, Validation Loss: 0.0489\n",
      "Epoch 36/1000: 100%|████████████| 63/63 [00:01<00:00, 43.38batch/s, loss=0.0912]\n",
      "Epoch 36/1000, Training Loss: 0.0633\n",
      "Epoch 36/1000, Validation Loss: 0.0520\n",
      "Epoch 37/1000: 100%|████████████| 63/63 [00:01<00:00, 41.77batch/s, loss=0.0914]\n",
      "Epoch 37/1000, Training Loss: 0.0624\n",
      "Epoch 37/1000, Validation Loss: 0.0559\n",
      "Epoch 38/1000: 100%|████████████| 63/63 [00:01<00:00, 41.70batch/s, loss=0.0625]\n",
      "Epoch 38/1000, Training Loss: 0.0652\n",
      "Epoch 38/1000, Validation Loss: 0.0538\n",
      "Epoch 39/1000: 100%|████████████| 63/63 [00:01<00:00, 42.73batch/s, loss=0.0381]\n",
      "Epoch 39/1000, Training Loss: 0.0624\n",
      "Epoch 39/1000, Validation Loss: 0.0501\n",
      "Epoch 40/1000: 100%|████████████| 63/63 [00:01<00:00, 41.28batch/s, loss=0.0674]\n",
      "Epoch 40/1000, Training Loss: 0.0621\n",
      "Epoch 40/1000, Validation Loss: 0.0545\n",
      "Epoch 41/1000: 100%|████████████| 63/63 [00:01<00:00, 42.91batch/s, loss=0.1192]\n",
      "Epoch 41/1000, Training Loss: 0.0603\n",
      "Epoch 41/1000, Validation Loss: 0.0450\n",
      "Epoch 42/1000: 100%|████████████| 63/63 [00:01<00:00, 41.03batch/s, loss=0.0658]\n",
      "Epoch 42/1000, Training Loss: 0.0588\n",
      "Epoch 42/1000, Validation Loss: 0.0490\n",
      "Epoch 43/1000: 100%|████████████| 63/63 [00:01<00:00, 41.95batch/s, loss=0.0545]\n",
      "Epoch 43/1000, Training Loss: 0.0590\n",
      "Epoch 43/1000, Validation Loss: 0.0471\n",
      "Epoch 44/1000: 100%|████████████| 63/63 [00:01<00:00, 41.29batch/s, loss=0.1434]\n",
      "Epoch 44/1000, Training Loss: 0.0647\n",
      "Epoch 44/1000, Validation Loss: 0.0491\n",
      "Epoch 45/1000: 100%|████████████| 63/63 [00:01<00:00, 40.93batch/s, loss=0.0551]\n",
      "Epoch 45/1000, Training Loss: 0.0659\n",
      "Epoch 45/1000, Validation Loss: 0.0470\n",
      "Epoch 46/1000: 100%|████████████| 63/63 [00:01<00:00, 40.39batch/s, loss=0.0618]\n",
      "Epoch 46/1000, Training Loss: 0.0583\n",
      "Epoch 46/1000, Validation Loss: 0.0456\n",
      "Epoch 47/1000: 100%|████████████| 63/63 [00:01<00:00, 42.95batch/s, loss=0.0736]\n",
      "Epoch 47/1000, Training Loss: 0.0618\n",
      "Epoch 47/1000, Validation Loss: 0.0485\n",
      "Epoch 48/1000: 100%|████████████| 63/63 [00:01<00:00, 43.04batch/s, loss=0.1177]\n",
      "Epoch 48/1000, Training Loss: 0.0586\n",
      "Epoch 48/1000, Validation Loss: 0.0573\n",
      "Epoch 49/1000: 100%|████████████| 63/63 [00:01<00:00, 42.37batch/s, loss=0.0607]\n",
      "Epoch 49/1000, Training Loss: 0.0613\n",
      "Epoch 49/1000, Validation Loss: 0.0437\n",
      "Epoch 50/1000: 100%|████████████| 63/63 [00:01<00:00, 41.95batch/s, loss=0.0629]\n",
      "Epoch 50/1000, Training Loss: 0.0555\n",
      "Epoch 50/1000, Validation Loss: 0.0406\n",
      "Epoch 51/1000: 100%|████████████| 63/63 [00:01<00:00, 40.42batch/s, loss=0.0279]\n",
      "Epoch 51/1000, Training Loss: 0.0568\n",
      "Epoch 51/1000, Validation Loss: 0.0432\n",
      "Epoch 52/1000: 100%|████████████| 63/63 [00:01<00:00, 40.55batch/s, loss=0.0581]\n",
      "Epoch 52/1000, Training Loss: 0.0550\n",
      "Epoch 52/1000, Validation Loss: 0.0408\n",
      "Epoch 53/1000: 100%|████████████| 63/63 [00:01<00:00, 40.88batch/s, loss=0.0220]\n",
      "Epoch 53/1000, Training Loss: 0.0566\n",
      "Epoch 53/1000, Validation Loss: 0.0435\n",
      "Epoch 54/1000: 100%|████████████| 63/63 [00:01<00:00, 41.46batch/s, loss=0.0763]\n",
      "Epoch 54/1000, Training Loss: 0.0547\n",
      "Epoch 54/1000, Validation Loss: 0.0470\n",
      "Epoch 55/1000: 100%|████████████| 63/63 [00:01<00:00, 41.54batch/s, loss=0.0683]\n",
      "Epoch 55/1000, Training Loss: 0.0546\n",
      "Epoch 55/1000, Validation Loss: 0.0433\n",
      "Epoch 56/1000: 100%|████████████| 63/63 [00:01<00:00, 43.52batch/s, loss=0.0681]\n",
      "Epoch 56/1000, Training Loss: 0.0544\n",
      "Epoch 56/1000, Validation Loss: 0.0393\n",
      "Epoch 57/1000: 100%|████████████| 63/63 [00:01<00:00, 42.93batch/s, loss=0.0524]\n",
      "Epoch 57/1000, Training Loss: 0.0539\n",
      "Epoch 57/1000, Validation Loss: 0.0420\n",
      "Epoch 58/1000: 100%|████████████| 63/63 [00:01<00:00, 42.18batch/s, loss=0.0583]\n",
      "Epoch 58/1000, Training Loss: 0.0571\n",
      "Epoch 58/1000, Validation Loss: 0.0410\n",
      "Epoch 59/1000: 100%|████████████| 63/63 [00:01<00:00, 43.80batch/s, loss=0.0540]\n",
      "Epoch 59/1000, Training Loss: 0.0528\n",
      "Epoch 59/1000, Validation Loss: 0.0422\n",
      "Epoch 60/1000: 100%|████████████| 63/63 [00:01<00:00, 42.44batch/s, loss=0.0586]\n",
      "Epoch 60/1000, Training Loss: 0.0566\n",
      "Epoch 60/1000, Validation Loss: 0.0435\n",
      "Epoch 61/1000: 100%|████████████| 63/63 [00:01<00:00, 41.70batch/s, loss=0.0376]\n",
      "Epoch 61/1000, Training Loss: 0.0535\n",
      "Epoch 61/1000, Validation Loss: 0.0425\n",
      "Epoch 62/1000: 100%|████████████| 63/63 [00:01<00:00, 41.96batch/s, loss=0.0262]\n",
      "Epoch 62/1000, Training Loss: 0.0528\n",
      "Epoch 62/1000, Validation Loss: 0.0422\n",
      "Epoch 63/1000: 100%|████████████| 63/63 [00:01<00:00, 41.17batch/s, loss=0.0468]\n",
      "Epoch 63/1000, Training Loss: 0.0505\n",
      "Epoch 63/1000, Validation Loss: 0.0413\n",
      "Epoch 64/1000: 100%|████████████| 63/63 [00:01<00:00, 41.68batch/s, loss=0.0616]\n",
      "Epoch 64/1000, Training Loss: 0.0517\n",
      "Epoch 64/1000, Validation Loss: 0.0459\n",
      "Epoch 65/1000: 100%|████████████| 63/63 [00:01<00:00, 42.20batch/s, loss=0.0559]\n",
      "Epoch 65/1000, Training Loss: 0.0531\n",
      "Epoch 65/1000, Validation Loss: 0.0417\n",
      "Epoch 66/1000: 100%|████████████| 63/63 [00:01<00:00, 41.99batch/s, loss=0.0741]\n",
      "Epoch 66/1000, Training Loss: 0.0515\n",
      "Epoch 66/1000, Validation Loss: 0.0413\n",
      "Epoch 67/1000: 100%|████████████| 63/63 [00:01<00:00, 41.51batch/s, loss=0.0442]\n",
      "Epoch 67/1000, Training Loss: 0.0552\n",
      "Epoch 67/1000, Validation Loss: 0.0432\n",
      "Epoch 68/1000: 100%|████████████| 63/63 [00:01<00:00, 41.97batch/s, loss=0.0476]\n",
      "Epoch 68/1000, Training Loss: 0.0529\n",
      "Epoch 68/1000, Validation Loss: 0.0417\n",
      "Epoch 69/1000: 100%|████████████| 63/63 [00:01<00:00, 40.19batch/s, loss=0.0517]\n",
      "Epoch 69/1000, Training Loss: 0.0517\n",
      "Epoch 69/1000, Validation Loss: 0.0387\n",
      "Epoch 70/1000: 100%|████████████| 63/63 [00:01<00:00, 41.09batch/s, loss=0.0410]\n",
      "Epoch 70/1000, Training Loss: 0.0494\n",
      "Epoch 70/1000, Validation Loss: 0.0431\n",
      "Epoch 71/1000: 100%|████████████| 63/63 [00:01<00:00, 42.26batch/s, loss=0.0768]\n",
      "Epoch 71/1000, Training Loss: 0.0504\n",
      "Epoch 71/1000, Validation Loss: 0.0402\n",
      "Epoch 72/1000: 100%|████████████| 63/63 [00:01<00:00, 40.89batch/s, loss=0.0473]\n",
      "Epoch 72/1000, Training Loss: 0.0504\n",
      "Epoch 72/1000, Validation Loss: 0.0419\n",
      "Epoch 73/1000: 100%|████████████| 63/63 [00:01<00:00, 41.21batch/s, loss=0.0495]\n",
      "Epoch 73/1000, Training Loss: 0.0509\n",
      "Epoch 73/1000, Validation Loss: 0.0408\n",
      "Epoch 74/1000: 100%|████████████| 63/63 [00:01<00:00, 40.11batch/s, loss=0.0430]\n",
      "Epoch 74/1000, Training Loss: 0.0492\n",
      "Epoch 74/1000, Validation Loss: 0.0385\n",
      "Epoch 75/1000: 100%|████████████| 63/63 [00:01<00:00, 40.59batch/s, loss=0.0407]\n",
      "Epoch 75/1000, Training Loss: 0.0514\n",
      "Epoch 75/1000, Validation Loss: 0.0386\n",
      "Epoch 76/1000: 100%|████████████| 63/63 [00:01<00:00, 41.38batch/s, loss=0.0391]\n",
      "Epoch 76/1000, Training Loss: 0.0508\n",
      "Epoch 76/1000, Validation Loss: 0.0399\n",
      "Epoch 77/1000: 100%|████████████| 63/63 [00:01<00:00, 41.29batch/s, loss=0.0337]\n",
      "Epoch 77/1000, Training Loss: 0.0491\n",
      "Epoch 77/1000, Validation Loss: 0.0381\n",
      "Epoch 78/1000: 100%|████████████| 63/63 [00:01<00:00, 41.40batch/s, loss=0.0655]\n",
      "Epoch 78/1000, Training Loss: 0.0510\n",
      "Epoch 78/1000, Validation Loss: 0.0364\n",
      "Epoch 79/1000: 100%|████████████| 63/63 [00:01<00:00, 41.77batch/s, loss=0.0381]\n",
      "Epoch 79/1000, Training Loss: 0.0514\n",
      "Epoch 79/1000, Validation Loss: 0.0382\n",
      "Epoch 80/1000: 100%|████████████| 63/63 [00:01<00:00, 40.01batch/s, loss=0.0629]\n",
      "Epoch 80/1000, Training Loss: 0.0493\n",
      "Epoch 80/1000, Validation Loss: 0.0383\n",
      "Epoch 81/1000: 100%|████████████| 63/63 [00:01<00:00, 42.42batch/s, loss=0.0573]\n",
      "Epoch 81/1000, Training Loss: 0.0487\n",
      "Epoch 81/1000, Validation Loss: 0.0374\n",
      "Epoch 82/1000: 100%|████████████| 63/63 [00:01<00:00, 42.37batch/s, loss=0.0348]\n",
      "Epoch 82/1000, Training Loss: 0.0496\n",
      "Epoch 82/1000, Validation Loss: 0.0414\n",
      "Epoch 83/1000: 100%|████████████| 63/63 [00:01<00:00, 41.64batch/s, loss=0.0175]\n",
      "Epoch 83/1000, Training Loss: 0.0565\n",
      "Epoch 83/1000, Validation Loss: 0.0418\n",
      "Epoch 84/1000: 100%|████████████| 63/63 [00:01<00:00, 42.64batch/s, loss=0.0995]\n",
      "Epoch 84/1000, Training Loss: 0.0512\n",
      "Epoch 84/1000, Validation Loss: 0.0389\n",
      "Epoch 85/1000: 100%|████████████| 63/63 [00:01<00:00, 42.26batch/s, loss=0.0415]\n",
      "Epoch 85/1000, Training Loss: 0.0497\n",
      "Epoch 85/1000, Validation Loss: 0.0379\n",
      "Epoch 86/1000: 100%|████████████| 63/63 [00:01<00:00, 39.89batch/s, loss=0.0396]\n",
      "Epoch 86/1000, Training Loss: 0.0498\n",
      "Epoch 86/1000, Validation Loss: 0.0392\n",
      "Epoch 87/1000: 100%|████████████| 63/63 [00:01<00:00, 41.80batch/s, loss=0.0447]\n",
      "Epoch 87/1000, Training Loss: 0.0483\n",
      "Epoch 87/1000, Validation Loss: 0.0423\n",
      "Epoch 88/1000: 100%|████████████| 63/63 [00:01<00:00, 42.25batch/s, loss=0.0366]\n",
      "Epoch 88/1000, Training Loss: 0.0504\n",
      "Epoch 88/1000, Validation Loss: 0.0384\n",
      "Epoch 89/1000: 100%|████████████| 63/63 [00:01<00:00, 41.74batch/s, loss=0.0475]\n",
      "Epoch 89/1000, Training Loss: 0.0514\n",
      "Epoch 89/1000, Validation Loss: 0.0358\n",
      "Epoch 90/1000: 100%|████████████| 63/63 [00:01<00:00, 42.76batch/s, loss=0.0432]\n",
      "Epoch 90/1000, Training Loss: 0.0486\n",
      "Epoch 90/1000, Validation Loss: 0.0373\n",
      "Epoch 91/1000: 100%|████████████| 63/63 [00:01<00:00, 40.77batch/s, loss=0.0500]\n",
      "Epoch 91/1000, Training Loss: 0.0472\n",
      "Epoch 91/1000, Validation Loss: 0.0399\n",
      "Epoch 92/1000: 100%|████████████| 63/63 [00:01<00:00, 42.11batch/s, loss=0.0359]\n",
      "Epoch 92/1000, Training Loss: 0.0474\n",
      "Epoch 92/1000, Validation Loss: 0.0374\n",
      "Epoch 93/1000: 100%|████████████| 63/63 [00:01<00:00, 42.23batch/s, loss=0.0344]\n",
      "Epoch 93/1000, Training Loss: 0.0480\n",
      "Epoch 93/1000, Validation Loss: 0.0337\n",
      "Epoch 94/1000: 100%|████████████| 63/63 [00:01<00:00, 41.33batch/s, loss=0.0340]\n",
      "Epoch 94/1000, Training Loss: 0.0473\n",
      "Epoch 94/1000, Validation Loss: 0.0415\n",
      "Epoch 95/1000: 100%|████████████| 63/63 [00:01<00:00, 41.24batch/s, loss=0.0769]\n",
      "Epoch 95/1000, Training Loss: 0.0507\n",
      "Epoch 95/1000, Validation Loss: 0.0444\n",
      "Epoch 96/1000: 100%|████████████| 63/63 [00:01<00:00, 41.38batch/s, loss=0.0451]\n",
      "Epoch 96/1000, Training Loss: 0.0527\n",
      "Epoch 96/1000, Validation Loss: 0.0373\n",
      "Epoch 97/1000: 100%|████████████| 63/63 [00:01<00:00, 42.18batch/s, loss=0.0618]\n",
      "Epoch 97/1000, Training Loss: 0.0462\n",
      "Epoch 97/1000, Validation Loss: 0.0354\n",
      "Epoch 98/1000: 100%|████████████| 63/63 [00:01<00:00, 41.86batch/s, loss=0.0497]\n",
      "Epoch 98/1000, Training Loss: 0.0456\n",
      "Epoch 98/1000, Validation Loss: 0.0363\n",
      "Epoch 99/1000: 100%|████████████| 63/63 [00:01<00:00, 41.67batch/s, loss=0.0526]\n",
      "Epoch 99/1000, Training Loss: 0.0493\n",
      "Epoch 99/1000, Validation Loss: 0.0341\n",
      "Epoch 100/1000: 100%|███████████| 63/63 [00:01<00:00, 41.37batch/s, loss=0.0335]\n",
      "Epoch 100/1000, Training Loss: 0.0466\n",
      "Epoch 100/1000, Validation Loss: 0.0351\n",
      "Epoch 101/1000: 100%|███████████| 63/63 [00:01<00:00, 42.34batch/s, loss=0.0344]\n",
      "Epoch 101/1000, Training Loss: 0.0453\n",
      "Epoch 101/1000, Validation Loss: 0.0378\n",
      "Epoch 102/1000: 100%|███████████| 63/63 [00:01<00:00, 40.80batch/s, loss=0.0267]\n",
      "Epoch 102/1000, Training Loss: 0.0460\n",
      "Epoch 102/1000, Validation Loss: 0.0376\n",
      "Epoch 103/1000: 100%|███████████| 63/63 [00:01<00:00, 41.01batch/s, loss=0.0584]\n",
      "Epoch 103/1000, Training Loss: 0.0448\n",
      "Epoch 103/1000, Validation Loss: 0.0346\n",
      "Epoch 104/1000: 100%|███████████| 63/63 [00:01<00:00, 40.38batch/s, loss=0.0315]\n",
      "Epoch 104/1000, Training Loss: 0.0439\n",
      "Epoch 104/1000, Validation Loss: 0.0334\n",
      "Epoch 105/1000: 100%|███████████| 63/63 [00:01<00:00, 42.06batch/s, loss=0.0565]\n",
      "Epoch 105/1000, Training Loss: 0.0446\n",
      "Epoch 105/1000, Validation Loss: 0.0343\n",
      "Epoch 106/1000: 100%|███████████| 63/63 [00:01<00:00, 42.09batch/s, loss=0.0646]\n",
      "Epoch 106/1000, Training Loss: 0.0473\n",
      "Epoch 106/1000, Validation Loss: 0.0340\n",
      "Epoch 107/1000: 100%|███████████| 63/63 [00:01<00:00, 41.62batch/s, loss=0.0553]\n",
      "Epoch 107/1000, Training Loss: 0.0437\n",
      "Epoch 107/1000, Validation Loss: 0.0342\n",
      "Epoch 108/1000: 100%|███████████| 63/63 [00:01<00:00, 43.70batch/s, loss=0.0672]\n",
      "Epoch 108/1000, Training Loss: 0.0456\n",
      "Epoch 108/1000, Validation Loss: 0.0377\n",
      "Epoch 109/1000: 100%|███████████| 63/63 [00:01<00:00, 44.46batch/s, loss=0.0281]\n",
      "Epoch 109/1000, Training Loss: 0.0472\n",
      "Epoch 109/1000, Validation Loss: 0.0350\n",
      "Epoch 110/1000: 100%|███████████| 63/63 [00:01<00:00, 42.26batch/s, loss=0.0238]\n",
      "Epoch 110/1000, Training Loss: 0.0430\n",
      "Epoch 110/1000, Validation Loss: 0.0364\n",
      "Epoch 111/1000: 100%|███████████| 63/63 [00:01<00:00, 42.49batch/s, loss=0.0143]\n",
      "Epoch 111/1000, Training Loss: 0.0441\n",
      "Epoch 111/1000, Validation Loss: 0.0381\n",
      "Epoch 112/1000: 100%|███████████| 63/63 [00:01<00:00, 42.58batch/s, loss=0.0683]\n",
      "Epoch 112/1000, Training Loss: 0.0429\n",
      "Epoch 112/1000, Validation Loss: 0.0331\n",
      "Epoch 113/1000: 100%|███████████| 63/63 [00:01<00:00, 41.91batch/s, loss=0.0472]\n",
      "Epoch 113/1000, Training Loss: 0.0440\n",
      "Epoch 113/1000, Validation Loss: 0.0331\n",
      "Epoch 114/1000: 100%|███████████| 63/63 [00:01<00:00, 43.10batch/s, loss=0.0281]\n",
      "Epoch 114/1000, Training Loss: 0.0451\n",
      "Epoch 114/1000, Validation Loss: 0.0365\n",
      "Epoch 115/1000: 100%|███████████| 63/63 [00:01<00:00, 44.16batch/s, loss=0.0459]\n",
      "Epoch 115/1000, Training Loss: 0.0440\n",
      "Epoch 115/1000, Validation Loss: 0.0325\n",
      "Epoch 116/1000: 100%|███████████| 63/63 [00:01<00:00, 43.47batch/s, loss=0.0337]\n",
      "Epoch 116/1000, Training Loss: 0.0429\n",
      "Epoch 116/1000, Validation Loss: 0.0357\n",
      "Epoch 117/1000: 100%|███████████| 63/63 [00:01<00:00, 44.03batch/s, loss=0.0343]\n",
      "Epoch 117/1000, Training Loss: 0.0449\n",
      "Epoch 117/1000, Validation Loss: 0.0386\n",
      "Epoch 118/1000: 100%|███████████| 63/63 [00:01<00:00, 41.53batch/s, loss=0.0500]\n",
      "Epoch 118/1000, Training Loss: 0.0435\n",
      "Epoch 118/1000, Validation Loss: 0.0335\n",
      "Epoch 119/1000: 100%|███████████| 63/63 [00:01<00:00, 40.23batch/s, loss=0.0792]\n",
      "Epoch 119/1000, Training Loss: 0.0456\n",
      "Epoch 119/1000, Validation Loss: 0.0318\n",
      "Epoch 120/1000: 100%|███████████| 63/63 [00:01<00:00, 41.52batch/s, loss=0.0494]\n",
      "Epoch 120/1000, Training Loss: 0.0459\n",
      "Epoch 120/1000, Validation Loss: 0.0341\n",
      "Epoch 121/1000: 100%|███████████| 63/63 [00:01<00:00, 41.08batch/s, loss=0.0292]\n",
      "Epoch 121/1000, Training Loss: 0.0432\n",
      "Epoch 121/1000, Validation Loss: 0.0307\n",
      "Epoch 122/1000: 100%|███████████| 63/63 [00:01<00:00, 39.63batch/s, loss=0.0241]\n",
      "Epoch 122/1000, Training Loss: 0.0424\n",
      "Epoch 122/1000, Validation Loss: 0.0347\n",
      "Epoch 123/1000: 100%|███████████| 63/63 [00:01<00:00, 42.65batch/s, loss=0.0273]\n",
      "Epoch 123/1000, Training Loss: 0.0445\n",
      "Epoch 123/1000, Validation Loss: 0.0338\n",
      "Epoch 124/1000: 100%|███████████| 63/63 [00:01<00:00, 40.57batch/s, loss=0.0510]\n",
      "Epoch 124/1000, Training Loss: 0.0427\n",
      "Epoch 124/1000, Validation Loss: 0.0304\n",
      "Epoch 125/1000: 100%|███████████| 63/63 [00:01<00:00, 41.31batch/s, loss=0.0179]\n",
      "Epoch 125/1000, Training Loss: 0.0434\n",
      "Epoch 125/1000, Validation Loss: 0.0344\n",
      "Epoch 126/1000: 100%|███████████| 63/63 [00:01<00:00, 42.31batch/s, loss=0.0556]\n",
      "Epoch 126/1000, Training Loss: 0.0439\n",
      "Epoch 126/1000, Validation Loss: 0.0314\n",
      "Epoch 127/1000: 100%|███████████| 63/63 [00:01<00:00, 42.15batch/s, loss=0.0372]\n",
      "Epoch 127/1000, Training Loss: 0.0429\n",
      "Epoch 127/1000, Validation Loss: 0.0347\n",
      "Epoch 128/1000: 100%|███████████| 63/63 [00:01<00:00, 40.58batch/s, loss=0.0779]\n",
      "Epoch 128/1000, Training Loss: 0.0443\n",
      "Epoch 128/1000, Validation Loss: 0.0362\n",
      "Epoch 129/1000: 100%|███████████| 63/63 [00:01<00:00, 40.18batch/s, loss=0.0314]\n",
      "Epoch 129/1000, Training Loss: 0.0425\n",
      "Epoch 129/1000, Validation Loss: 0.0349\n",
      "Epoch 130/1000: 100%|███████████| 63/63 [00:01<00:00, 42.02batch/s, loss=0.0442]\n",
      "Epoch 130/1000, Training Loss: 0.0449\n",
      "Epoch 130/1000, Validation Loss: 0.0317\n",
      "Epoch 131/1000: 100%|███████████| 63/63 [00:01<00:00, 41.79batch/s, loss=0.0541]\n",
      "Epoch 131/1000, Training Loss: 0.0428\n",
      "Epoch 131/1000, Validation Loss: 0.0344\n",
      "Epoch 132/1000: 100%|███████████| 63/63 [00:01<00:00, 40.51batch/s, loss=0.0558]\n",
      "Epoch 132/1000, Training Loss: 0.0450\n",
      "Epoch 132/1000, Validation Loss: 0.0330\n",
      "Epoch 133/1000: 100%|███████████| 63/63 [00:01<00:00, 40.93batch/s, loss=0.0296]\n",
      "Epoch 133/1000, Training Loss: 0.0422\n",
      "Epoch 133/1000, Validation Loss: 0.0324\n",
      "Epoch 134/1000: 100%|███████████| 63/63 [00:01<00:00, 41.21batch/s, loss=0.0262]\n",
      "Epoch 134/1000, Training Loss: 0.0403\n",
      "Epoch 134/1000, Validation Loss: 0.0298\n",
      "Epoch 135/1000: 100%|███████████| 63/63 [00:01<00:00, 41.31batch/s, loss=0.0614]\n",
      "Epoch 135/1000, Training Loss: 0.0382\n",
      "Epoch 135/1000, Validation Loss: 0.0306\n",
      "Epoch 136/1000: 100%|███████████| 63/63 [00:01<00:00, 41.58batch/s, loss=0.0262]\n",
      "Epoch 136/1000, Training Loss: 0.0427\n",
      "Epoch 136/1000, Validation Loss: 0.0340\n",
      "Epoch 137/1000: 100%|███████████| 63/63 [00:01<00:00, 41.27batch/s, loss=0.0295]\n",
      "Epoch 137/1000, Training Loss: 0.0409\n",
      "Epoch 137/1000, Validation Loss: 0.0296\n",
      "Epoch 138/1000: 100%|███████████| 63/63 [00:01<00:00, 40.64batch/s, loss=0.0483]\n",
      "Epoch 138/1000, Training Loss: 0.0412\n",
      "Epoch 138/1000, Validation Loss: 0.0330\n",
      "Epoch 139/1000: 100%|███████████| 63/63 [00:01<00:00, 42.06batch/s, loss=0.0198]\n",
      "Epoch 139/1000, Training Loss: 0.0405\n",
      "Epoch 139/1000, Validation Loss: 0.0292\n",
      "Epoch 140/1000: 100%|███████████| 63/63 [00:01<00:00, 41.89batch/s, loss=0.0212]\n",
      "Epoch 140/1000, Training Loss: 0.0402\n",
      "Epoch 140/1000, Validation Loss: 0.0306\n",
      "Epoch 141/1000: 100%|███████████| 63/63 [00:01<00:00, 40.72batch/s, loss=0.0834]\n",
      "Epoch 141/1000, Training Loss: 0.0407\n",
      "Epoch 141/1000, Validation Loss: 0.0294\n",
      "Epoch 142/1000: 100%|███████████| 63/63 [00:01<00:00, 41.62batch/s, loss=0.0405]\n",
      "Epoch 142/1000, Training Loss: 0.0426\n",
      "Epoch 142/1000, Validation Loss: 0.0309\n",
      "Epoch 143/1000: 100%|███████████| 63/63 [00:01<00:00, 41.54batch/s, loss=0.0446]\n",
      "Epoch 143/1000, Training Loss: 0.0416\n",
      "Epoch 143/1000, Validation Loss: 0.0347\n",
      "Epoch 144/1000: 100%|███████████| 63/63 [00:01<00:00, 41.52batch/s, loss=0.0455]\n",
      "Epoch 144/1000, Training Loss: 0.0403\n",
      "Epoch 144/1000, Validation Loss: 0.0359\n",
      "Epoch 145/1000: 100%|███████████| 63/63 [00:01<00:00, 40.69batch/s, loss=0.0387]\n",
      "Epoch 145/1000, Training Loss: 0.0424\n",
      "Epoch 145/1000, Validation Loss: 0.0315\n",
      "Epoch 146/1000: 100%|███████████| 63/63 [00:01<00:00, 42.34batch/s, loss=0.0208]\n",
      "Epoch 146/1000, Training Loss: 0.0396\n",
      "Epoch 146/1000, Validation Loss: 0.0307\n",
      "Epoch 147/1000: 100%|███████████| 63/63 [00:01<00:00, 41.87batch/s, loss=0.0330]\n",
      "Epoch 147/1000, Training Loss: 0.0407\n",
      "Epoch 147/1000, Validation Loss: 0.0305\n",
      "Epoch 148/1000: 100%|███████████| 63/63 [00:01<00:00, 41.40batch/s, loss=0.0721]\n",
      "Epoch 148/1000, Training Loss: 0.0416\n",
      "Epoch 148/1000, Validation Loss: 0.0301\n",
      "Epoch 149/1000: 100%|███████████| 63/63 [00:01<00:00, 40.77batch/s, loss=0.0272]\n",
      "Epoch 149/1000, Training Loss: 0.0410\n",
      "Epoch 149/1000, Validation Loss: 0.0310\n",
      "Epoch 150/1000: 100%|███████████| 63/63 [00:01<00:00, 41.74batch/s, loss=0.0267]\n",
      "Epoch 150/1000, Training Loss: 0.0394\n",
      "Epoch 150/1000, Validation Loss: 0.0316\n",
      "Epoch 151/1000: 100%|███████████| 63/63 [00:01<00:00, 41.55batch/s, loss=0.0292]\n",
      "Epoch 151/1000, Training Loss: 0.0432\n",
      "Epoch 151/1000, Validation Loss: 0.0342\n",
      "Epoch 152/1000: 100%|███████████| 63/63 [00:01<00:00, 40.09batch/s, loss=0.0307]\n",
      "Epoch 152/1000, Training Loss: 0.0385\n",
      "Epoch 152/1000, Validation Loss: 0.0296\n",
      "Epoch 153/1000: 100%|███████████| 63/63 [00:01<00:00, 42.52batch/s, loss=0.0649]\n",
      "Epoch 153/1000, Training Loss: 0.0387\n",
      "Epoch 153/1000, Validation Loss: 0.0299\n",
      "Epoch 154/1000: 100%|███████████| 63/63 [00:01<00:00, 40.66batch/s, loss=0.0341]\n",
      "Epoch 154/1000, Training Loss: 0.0393\n",
      "Epoch 154/1000, Validation Loss: 0.0282\n",
      "Epoch 155/1000: 100%|███████████| 63/63 [00:01<00:00, 41.02batch/s, loss=0.0310]\n",
      "Epoch 155/1000, Training Loss: 0.0399\n",
      "Epoch 155/1000, Validation Loss: 0.0323\n",
      "Epoch 156/1000: 100%|███████████| 63/63 [00:01<00:00, 42.20batch/s, loss=0.0743]\n",
      "Epoch 156/1000, Training Loss: 0.0396\n",
      "Epoch 156/1000, Validation Loss: 0.0326\n",
      "Epoch 157/1000: 100%|███████████| 63/63 [00:01<00:00, 41.12batch/s, loss=0.0457]\n",
      "Epoch 157/1000, Training Loss: 0.0399\n",
      "Epoch 157/1000, Validation Loss: 0.0286\n",
      "Epoch 158/1000: 100%|███████████| 63/63 [00:01<00:00, 40.83batch/s, loss=0.0443]\n",
      "Epoch 158/1000, Training Loss: 0.0385\n",
      "Epoch 158/1000, Validation Loss: 0.0301\n",
      "Epoch 159/1000: 100%|███████████| 63/63 [00:01<00:00, 42.26batch/s, loss=0.0403]\n",
      "Epoch 159/1000, Training Loss: 0.0412\n",
      "Epoch 159/1000, Validation Loss: 0.0345\n",
      "Epoch 160/1000: 100%|███████████| 63/63 [00:01<00:00, 42.00batch/s, loss=0.0400]\n",
      "Epoch 160/1000, Training Loss: 0.0418\n",
      "Epoch 160/1000, Validation Loss: 0.0289\n",
      "Epoch 161/1000: 100%|███████████| 63/63 [00:01<00:00, 41.51batch/s, loss=0.0403]\n",
      "Epoch 161/1000, Training Loss: 0.0390\n",
      "Epoch 161/1000, Validation Loss: 0.0292\n",
      "Epoch 162/1000: 100%|███████████| 63/63 [00:01<00:00, 40.64batch/s, loss=0.0391]\n",
      "Epoch 162/1000, Training Loss: 0.0384\n",
      "Epoch 162/1000, Validation Loss: 0.0276\n",
      "Epoch 163/1000: 100%|███████████| 63/63 [00:01<00:00, 40.76batch/s, loss=0.0603]\n",
      "Epoch 163/1000, Training Loss: 0.0389\n",
      "Epoch 163/1000, Validation Loss: 0.0302\n",
      "Epoch 164/1000: 100%|███████████| 63/63 [00:01<00:00, 41.86batch/s, loss=0.0283]\n",
      "Epoch 164/1000, Training Loss: 0.0422\n",
      "Epoch 164/1000, Validation Loss: 0.0362\n",
      "Epoch 165/1000: 100%|███████████| 63/63 [00:01<00:00, 41.02batch/s, loss=0.0441]\n",
      "Epoch 165/1000, Training Loss: 0.0439\n",
      "Epoch 165/1000, Validation Loss: 0.0302\n",
      "Epoch 166/1000: 100%|███████████| 63/63 [00:01<00:00, 41.75batch/s, loss=0.0707]\n",
      "Epoch 166/1000, Training Loss: 0.0408\n",
      "Epoch 166/1000, Validation Loss: 0.0294\n",
      "Epoch 167/1000: 100%|███████████| 63/63 [00:01<00:00, 41.28batch/s, loss=0.0555]\n",
      "Epoch 167/1000, Training Loss: 0.0397\n",
      "Epoch 167/1000, Validation Loss: 0.0317\n",
      "Epoch 168/1000: 100%|███████████| 63/63 [00:01<00:00, 40.20batch/s, loss=0.0609]\n",
      "Epoch 168/1000, Training Loss: 0.0418\n",
      "Epoch 168/1000, Validation Loss: 0.0296\n",
      "Epoch 169/1000: 100%|███████████| 63/63 [00:01<00:00, 42.86batch/s, loss=0.0277]\n",
      "Epoch 169/1000, Training Loss: 0.0376\n",
      "Epoch 169/1000, Validation Loss: 0.0318\n",
      "Epoch 170/1000: 100%|███████████| 63/63 [00:01<00:00, 40.86batch/s, loss=0.0262]\n",
      "Epoch 170/1000, Training Loss: 0.0401\n",
      "Epoch 170/1000, Validation Loss: 0.0276\n",
      "Epoch 171/1000: 100%|███████████| 63/63 [00:01<00:00, 41.77batch/s, loss=0.0346]\n",
      "Epoch 171/1000, Training Loss: 0.0388\n",
      "Epoch 171/1000, Validation Loss: 0.0291\n",
      "Epoch 172/1000: 100%|███████████| 63/63 [00:01<00:00, 43.13batch/s, loss=0.0373]\n",
      "Epoch 172/1000, Training Loss: 0.0396\n",
      "Epoch 172/1000, Validation Loss: 0.0287\n",
      "Epoch 173/1000: 100%|███████████| 63/63 [00:01<00:00, 40.41batch/s, loss=0.0321]\n",
      "Epoch 173/1000, Training Loss: 0.0376\n",
      "Epoch 173/1000, Validation Loss: 0.0270\n",
      "Epoch 174/1000: 100%|███████████| 63/63 [00:01<00:00, 41.42batch/s, loss=0.0233]\n",
      "Epoch 174/1000, Training Loss: 0.0380\n",
      "Epoch 174/1000, Validation Loss: 0.0303\n",
      "Epoch 175/1000: 100%|███████████| 63/63 [00:01<00:00, 41.68batch/s, loss=0.0305]\n",
      "Epoch 175/1000, Training Loss: 0.0403\n",
      "Epoch 175/1000, Validation Loss: 0.0314\n",
      "Epoch 176/1000: 100%|███████████| 63/63 [00:01<00:00, 41.21batch/s, loss=0.0329]\n",
      "Epoch 176/1000, Training Loss: 0.0387\n",
      "Epoch 176/1000, Validation Loss: 0.0337\n",
      "Epoch 177/1000: 100%|███████████| 63/63 [00:01<00:00, 41.96batch/s, loss=0.0220]\n",
      "Epoch 177/1000, Training Loss: 0.0387\n",
      "Epoch 177/1000, Validation Loss: 0.0273\n",
      "Epoch 178/1000: 100%|███████████| 63/63 [00:01<00:00, 41.62batch/s, loss=0.0577]\n",
      "Epoch 178/1000, Training Loss: 0.0368\n",
      "Epoch 178/1000, Validation Loss: 0.0274\n",
      "Epoch 179/1000: 100%|███████████| 63/63 [00:01<00:00, 41.75batch/s, loss=0.0316]\n",
      "Epoch 179/1000, Training Loss: 0.0384\n",
      "Epoch 179/1000, Validation Loss: 0.0297\n",
      "Epoch 180/1000: 100%|███████████| 63/63 [00:01<00:00, 41.07batch/s, loss=0.0311]\n",
      "Epoch 180/1000, Training Loss: 0.0420\n",
      "Epoch 180/1000, Validation Loss: 0.0283\n",
      "Epoch 181/1000: 100%|███████████| 63/63 [00:01<00:00, 41.39batch/s, loss=0.0250]\n",
      "Epoch 181/1000, Training Loss: 0.0396\n",
      "Epoch 181/1000, Validation Loss: 0.0277\n",
      "Epoch 182/1000: 100%|███████████| 63/63 [00:01<00:00, 41.92batch/s, loss=0.0383]\n",
      "Epoch 182/1000, Training Loss: 0.0377\n",
      "Epoch 182/1000, Validation Loss: 0.0264\n",
      "Epoch 183/1000: 100%|███████████| 63/63 [00:01<00:00, 40.52batch/s, loss=0.0234]\n",
      "Epoch 183/1000, Training Loss: 0.0371\n",
      "Epoch 183/1000, Validation Loss: 0.0288\n",
      "Epoch 184/1000: 100%|███████████| 63/63 [00:01<00:00, 41.59batch/s, loss=0.0176]\n",
      "Epoch 184/1000, Training Loss: 0.0365\n",
      "Epoch 184/1000, Validation Loss: 0.0260\n",
      "Epoch 185/1000: 100%|███████████| 63/63 [00:01<00:00, 41.31batch/s, loss=0.0970]\n",
      "Epoch 185/1000, Training Loss: 0.0384\n",
      "Epoch 185/1000, Validation Loss: 0.0300\n",
      "Epoch 186/1000: 100%|███████████| 63/63 [00:01<00:00, 41.56batch/s, loss=0.0414]\n",
      "Epoch 186/1000, Training Loss: 0.0380\n",
      "Epoch 186/1000, Validation Loss: 0.0354\n",
      "Epoch 187/1000: 100%|███████████| 63/63 [00:01<00:00, 42.71batch/s, loss=0.0778]\n",
      "Epoch 187/1000, Training Loss: 0.0391\n",
      "Epoch 187/1000, Validation Loss: 0.0302\n",
      "Epoch 188/1000: 100%|███████████| 63/63 [00:01<00:00, 40.60batch/s, loss=0.0280]\n",
      "Epoch 188/1000, Training Loss: 0.0392\n",
      "Epoch 188/1000, Validation Loss: 0.0365\n",
      "Epoch 189/1000: 100%|███████████| 63/63 [00:01<00:00, 41.96batch/s, loss=0.0211]\n",
      "Epoch 189/1000, Training Loss: 0.0390\n",
      "Epoch 189/1000, Validation Loss: 0.0297\n",
      "Epoch 190/1000: 100%|███████████| 63/63 [00:01<00:00, 41.02batch/s, loss=0.0537]\n",
      "Epoch 190/1000, Training Loss: 0.0372\n",
      "Epoch 190/1000, Validation Loss: 0.0278\n",
      "Epoch 191/1000: 100%|███████████| 63/63 [00:01<00:00, 41.33batch/s, loss=0.0297]\n",
      "Epoch 191/1000, Training Loss: 0.0360\n",
      "Epoch 191/1000, Validation Loss: 0.0290\n",
      "Epoch 192/1000: 100%|███████████| 63/63 [00:01<00:00, 40.86batch/s, loss=0.0369]\n",
      "Epoch 192/1000, Training Loss: 0.0366\n",
      "Epoch 192/1000, Validation Loss: 0.0288\n",
      "Epoch 193/1000: 100%|███████████| 63/63 [00:01<00:00, 41.61batch/s, loss=0.0234]\n",
      "Epoch 193/1000, Training Loss: 0.0366\n",
      "Epoch 193/1000, Validation Loss: 0.0285\n",
      "Epoch 194/1000: 100%|███████████| 63/63 [00:01<00:00, 41.06batch/s, loss=0.0457]\n",
      "Epoch 194/1000, Training Loss: 0.0357\n",
      "Epoch 194/1000, Validation Loss: 0.0290\n",
      "Epoch 195/1000: 100%|███████████| 63/63 [00:01<00:00, 41.42batch/s, loss=0.0284]\n",
      "Epoch 195/1000, Training Loss: 0.0375\n",
      "Epoch 195/1000, Validation Loss: 0.0282\n",
      "Epoch 196/1000: 100%|███████████| 63/63 [00:01<00:00, 43.05batch/s, loss=0.0286]\n",
      "Epoch 196/1000, Training Loss: 0.0385\n",
      "Epoch 196/1000, Validation Loss: 0.0280\n",
      "Epoch 197/1000: 100%|███████████| 63/63 [00:01<00:00, 43.99batch/s, loss=0.0194]\n",
      "Epoch 197/1000, Training Loss: 0.0386\n",
      "Epoch 197/1000, Validation Loss: 0.0301\n",
      "Epoch 198/1000: 100%|███████████| 63/63 [00:01<00:00, 43.32batch/s, loss=0.0292]\n",
      "Epoch 198/1000, Training Loss: 0.0395\n",
      "Epoch 198/1000, Validation Loss: 0.0264\n",
      "Epoch 199/1000: 100%|███████████| 63/63 [00:01<00:00, 41.00batch/s, loss=0.0436]\n",
      "Epoch 199/1000, Training Loss: 0.0368\n",
      "Epoch 199/1000, Validation Loss: 0.0307\n",
      "Epoch 200/1000: 100%|███████████| 63/63 [00:01<00:00, 42.10batch/s, loss=0.0188]\n",
      "Epoch 200/1000, Training Loss: 0.0369\n",
      "Epoch 200/1000, Validation Loss: 0.0273\n",
      "Epoch 201/1000: 100%|███████████| 63/63 [00:01<00:00, 40.51batch/s, loss=0.0329]\n",
      "Epoch 201/1000, Training Loss: 0.0373\n",
      "Epoch 201/1000, Validation Loss: 0.0291\n",
      "Epoch 202/1000: 100%|███████████| 63/63 [00:01<00:00, 40.40batch/s, loss=0.0733]\n",
      "Epoch 202/1000, Training Loss: 0.0368\n",
      "Epoch 202/1000, Validation Loss: 0.0264\n",
      "Epoch 203/1000: 100%|███████████| 63/63 [00:01<00:00, 41.13batch/s, loss=0.0378]\n",
      "Epoch 203/1000, Training Loss: 0.0367\n",
      "Epoch 203/1000, Validation Loss: 0.0293\n",
      "Epoch 204/1000: 100%|███████████| 63/63 [00:01<00:00, 40.89batch/s, loss=0.0476]\n",
      "Epoch 204/1000, Training Loss: 0.0394\n",
      "Epoch 204/1000, Validation Loss: 0.0285\n",
      "Epoch 205/1000: 100%|███████████| 63/63 [00:01<00:00, 40.64batch/s, loss=0.0262]\n",
      "Epoch 205/1000, Training Loss: 0.0348\n",
      "Epoch 205/1000, Validation Loss: 0.0253\n",
      "Epoch 206/1000: 100%|███████████| 63/63 [00:01<00:00, 42.22batch/s, loss=0.0640]\n",
      "Epoch 206/1000, Training Loss: 0.0373\n",
      "Epoch 206/1000, Validation Loss: 0.0285\n",
      "Epoch 207/1000: 100%|███████████| 63/63 [00:01<00:00, 42.18batch/s, loss=0.0272]\n",
      "Epoch 207/1000, Training Loss: 0.0361\n",
      "Epoch 207/1000, Validation Loss: 0.0251\n",
      "Epoch 208/1000: 100%|███████████| 63/63 [00:01<00:00, 42.73batch/s, loss=0.0459]\n",
      "Epoch 208/1000, Training Loss: 0.0357\n",
      "Epoch 208/1000, Validation Loss: 0.0260\n",
      "Epoch 209/1000: 100%|███████████| 63/63 [00:01<00:00, 39.23batch/s, loss=0.0248]\n",
      "Epoch 209/1000, Training Loss: 0.0361\n",
      "Epoch 209/1000, Validation Loss: 0.0260\n",
      "Epoch 210/1000: 100%|███████████| 63/63 [00:01<00:00, 40.16batch/s, loss=0.0104]\n",
      "Epoch 210/1000, Training Loss: 0.0356\n",
      "Epoch 210/1000, Validation Loss: 0.0259\n",
      "Epoch 211/1000: 100%|███████████| 63/63 [00:01<00:00, 39.21batch/s, loss=0.0360]\n",
      "Epoch 211/1000, Training Loss: 0.0371\n",
      "Epoch 211/1000, Validation Loss: 0.0292\n",
      "Epoch 212/1000: 100%|███████████| 63/63 [00:01<00:00, 39.94batch/s, loss=0.0257]\n",
      "Epoch 212/1000, Training Loss: 0.0370\n",
      "Epoch 212/1000, Validation Loss: 0.0286\n",
      "Epoch 213/1000: 100%|███████████| 63/63 [00:01<00:00, 41.27batch/s, loss=0.0614]\n",
      "Epoch 213/1000, Training Loss: 0.0374\n",
      "Epoch 213/1000, Validation Loss: 0.0269\n",
      "Epoch 214/1000: 100%|███████████| 63/63 [00:01<00:00, 42.04batch/s, loss=0.0502]\n",
      "Epoch 214/1000, Training Loss: 0.0368\n",
      "Epoch 214/1000, Validation Loss: 0.0259\n",
      "Epoch 215/1000: 100%|███████████| 63/63 [00:01<00:00, 40.27batch/s, loss=0.0857]\n",
      "Epoch 215/1000, Training Loss: 0.0352\n",
      "Epoch 215/1000, Validation Loss: 0.0284\n",
      "Epoch 216/1000: 100%|███████████| 63/63 [00:01<00:00, 40.06batch/s, loss=0.0326]\n",
      "Epoch 216/1000, Training Loss: 0.0379\n",
      "Epoch 216/1000, Validation Loss: 0.0267\n",
      "Epoch 217/1000: 100%|███████████| 63/63 [00:01<00:00, 40.87batch/s, loss=0.0211]\n",
      "Epoch 217/1000, Training Loss: 0.0368\n",
      "Epoch 217/1000, Validation Loss: 0.0273\n",
      "Epoch 218/1000: 100%|███████████| 63/63 [00:01<00:00, 40.19batch/s, loss=0.0324]\n",
      "Epoch 218/1000, Training Loss: 0.0339\n",
      "Epoch 218/1000, Validation Loss: 0.0266\n",
      "Epoch 219/1000: 100%|███████████| 63/63 [00:01<00:00, 38.09batch/s, loss=0.0330]\n",
      "Epoch 219/1000, Training Loss: 0.0354\n",
      "Epoch 219/1000, Validation Loss: 0.0272\n",
      "Epoch 220/1000: 100%|███████████| 63/63 [00:01<00:00, 36.44batch/s, loss=0.0161]\n",
      "Epoch 220/1000, Training Loss: 0.0347\n",
      "Epoch 220/1000, Validation Loss: 0.0268\n",
      "Epoch 221/1000: 100%|███████████| 63/63 [00:01<00:00, 38.17batch/s, loss=0.0535]\n",
      "Epoch 221/1000, Training Loss: 0.0354\n",
      "Epoch 221/1000, Validation Loss: 0.0238\n",
      "Epoch 222/1000: 100%|███████████| 63/63 [00:01<00:00, 37.58batch/s, loss=0.0434]\n",
      "Epoch 222/1000, Training Loss: 0.0345\n",
      "Epoch 222/1000, Validation Loss: 0.0292\n",
      "Epoch 223/1000: 100%|███████████| 63/63 [00:01<00:00, 38.66batch/s, loss=0.0227]\n",
      "Epoch 223/1000, Training Loss: 0.0347\n",
      "Epoch 223/1000, Validation Loss: 0.0258\n",
      "Epoch 224/1000: 100%|███████████| 63/63 [00:01<00:00, 36.48batch/s, loss=0.0563]\n",
      "Epoch 224/1000, Training Loss: 0.0368\n",
      "Epoch 224/1000, Validation Loss: 0.0354\n",
      "Epoch 225/1000: 100%|███████████| 63/63 [00:01<00:00, 38.24batch/s, loss=0.0773]\n",
      "Epoch 225/1000, Training Loss: 0.0411\n",
      "Epoch 225/1000, Validation Loss: 0.0251\n",
      "Epoch 226/1000: 100%|███████████| 63/63 [00:01<00:00, 36.95batch/s, loss=0.0942]\n",
      "Epoch 226/1000, Training Loss: 0.0346\n",
      "Epoch 226/1000, Validation Loss: 0.0265\n",
      "Epoch 227/1000: 100%|███████████| 63/63 [00:01<00:00, 38.66batch/s, loss=0.0630]\n",
      "Epoch 227/1000, Training Loss: 0.0348\n",
      "Epoch 227/1000, Validation Loss: 0.0251\n",
      "Epoch 228/1000: 100%|███████████| 63/63 [00:01<00:00, 37.31batch/s, loss=0.0263]\n",
      "Epoch 228/1000, Training Loss: 0.0335\n",
      "Epoch 228/1000, Validation Loss: 0.0257\n",
      "Epoch 229/1000: 100%|███████████| 63/63 [00:01<00:00, 36.96batch/s, loss=0.0568]\n",
      "Epoch 229/1000, Training Loss: 0.0337\n",
      "Epoch 229/1000, Validation Loss: 0.0263\n",
      "Epoch 230/1000: 100%|███████████| 63/63 [00:01<00:00, 38.43batch/s, loss=0.0539]\n",
      "Epoch 230/1000, Training Loss: 0.0363\n",
      "Epoch 230/1000, Validation Loss: 0.0284\n",
      "Epoch 231/1000: 100%|███████████| 63/63 [00:01<00:00, 36.35batch/s, loss=0.0074]\n",
      "Epoch 231/1000, Training Loss: 0.0337\n",
      "Epoch 231/1000, Validation Loss: 0.0264\n",
      "Epoch 232/1000: 100%|███████████| 63/63 [00:01<00:00, 37.99batch/s, loss=0.0443]\n",
      "Epoch 232/1000, Training Loss: 0.0346\n",
      "Epoch 232/1000, Validation Loss: 0.0276\n",
      "Epoch 233/1000: 100%|███████████| 63/63 [00:01<00:00, 37.43batch/s, loss=0.0486]\n",
      "Epoch 233/1000, Training Loss: 0.0347\n",
      "Epoch 233/1000, Validation Loss: 0.0242\n",
      "Epoch 234/1000: 100%|███████████| 63/63 [00:01<00:00, 37.61batch/s, loss=0.0533]\n",
      "Epoch 234/1000, Training Loss: 0.0330\n",
      "Epoch 234/1000, Validation Loss: 0.0242\n",
      "Epoch 235/1000: 100%|███████████| 63/63 [00:01<00:00, 36.04batch/s, loss=0.0249]\n",
      "Epoch 235/1000, Training Loss: 0.0332\n",
      "Epoch 235/1000, Validation Loss: 0.0254\n",
      "Epoch 236/1000: 100%|███████████| 63/63 [00:01<00:00, 37.50batch/s, loss=0.0291]\n",
      "Epoch 236/1000, Training Loss: 0.0367\n",
      "Epoch 236/1000, Validation Loss: 0.0283\n",
      "Epoch 237/1000: 100%|███████████| 63/63 [00:01<00:00, 37.93batch/s, loss=0.0267]\n",
      "Epoch 237/1000, Training Loss: 0.0340\n",
      "Epoch 237/1000, Validation Loss: 0.0253\n",
      "Epoch 238/1000: 100%|███████████| 63/63 [00:01<00:00, 38.04batch/s, loss=0.0128]\n",
      "Epoch 238/1000, Training Loss: 0.0324\n",
      "Epoch 238/1000, Validation Loss: 0.0246\n",
      "Epoch 239/1000: 100%|███████████| 63/63 [00:01<00:00, 39.06batch/s, loss=0.0451]\n",
      "Epoch 239/1000, Training Loss: 0.0335\n",
      "Epoch 239/1000, Validation Loss: 0.0257\n",
      "Epoch 240/1000: 100%|███████████| 63/63 [00:01<00:00, 37.18batch/s, loss=0.0349]\n",
      "Epoch 240/1000, Training Loss: 0.0336\n",
      "Epoch 240/1000, Validation Loss: 0.0235\n",
      "Epoch 241/1000: 100%|███████████| 63/63 [00:01<00:00, 35.92batch/s, loss=0.0423]\n",
      "Epoch 241/1000, Training Loss: 0.0329\n",
      "Epoch 241/1000, Validation Loss: 0.0262\n",
      "Epoch 242/1000: 100%|███████████| 63/63 [00:01<00:00, 36.49batch/s, loss=0.0567]\n",
      "Epoch 242/1000, Training Loss: 0.0326\n",
      "Epoch 242/1000, Validation Loss: 0.0281\n",
      "Epoch 243/1000: 100%|███████████| 63/63 [00:01<00:00, 37.51batch/s, loss=0.0509]\n",
      "Epoch 243/1000, Training Loss: 0.0352\n",
      "Epoch 243/1000, Validation Loss: 0.0243\n",
      "Epoch 244/1000: 100%|███████████| 63/63 [00:01<00:00, 37.80batch/s, loss=0.0619]\n",
      "Epoch 244/1000, Training Loss: 0.0349\n",
      "Epoch 244/1000, Validation Loss: 0.0297\n",
      "Epoch 245/1000: 100%|███████████| 63/63 [00:01<00:00, 37.08batch/s, loss=0.0269]\n",
      "Epoch 245/1000, Training Loss: 0.0371\n",
      "Epoch 245/1000, Validation Loss: 0.0408\n",
      "Epoch 246/1000: 100%|███████████| 63/63 [00:01<00:00, 36.62batch/s, loss=0.0287]\n",
      "Epoch 246/1000, Training Loss: 0.0396\n",
      "Epoch 246/1000, Validation Loss: 0.0257\n",
      "Epoch 247/1000: 100%|███████████| 63/63 [00:01<00:00, 37.73batch/s, loss=0.0222]\n",
      "Epoch 247/1000, Training Loss: 0.0330\n",
      "Epoch 247/1000, Validation Loss: 0.0282\n",
      "Epoch 248/1000: 100%|███████████| 63/63 [00:01<00:00, 36.97batch/s, loss=0.0387]\n",
      "Epoch 248/1000, Training Loss: 0.0336\n",
      "Epoch 248/1000, Validation Loss: 0.0273\n",
      "Epoch 249/1000: 100%|███████████| 63/63 [00:01<00:00, 36.54batch/s, loss=0.0636]\n",
      "Epoch 249/1000, Training Loss: 0.0345\n",
      "Epoch 249/1000, Validation Loss: 0.0247\n",
      "Epoch 250/1000: 100%|███████████| 63/63 [00:01<00:00, 37.42batch/s, loss=0.0418]\n",
      "Epoch 250/1000, Training Loss: 0.0370\n",
      "Epoch 250/1000, Validation Loss: 0.0264\n",
      "Epoch 251/1000: 100%|███████████| 63/63 [00:01<00:00, 36.75batch/s, loss=0.0465]\n",
      "Epoch 251/1000, Training Loss: 0.0337\n",
      "Epoch 251/1000, Validation Loss: 0.0250\n",
      "Epoch 252/1000: 100%|███████████| 63/63 [00:01<00:00, 37.38batch/s, loss=0.0242]\n",
      "Epoch 252/1000, Training Loss: 0.0327\n",
      "Epoch 252/1000, Validation Loss: 0.0245\n",
      "Epoch 253/1000: 100%|███████████| 63/63 [00:01<00:00, 36.70batch/s, loss=0.0223]\n",
      "Epoch 253/1000, Training Loss: 0.0348\n",
      "Epoch 253/1000, Validation Loss: 0.0255\n",
      "Epoch 254/1000: 100%|███████████| 63/63 [00:01<00:00, 37.19batch/s, loss=0.0077]\n",
      "Epoch 254/1000, Training Loss: 0.0339\n",
      "Epoch 254/1000, Validation Loss: 0.0257\n",
      "Epoch 255/1000: 100%|███████████| 63/63 [00:01<00:00, 36.89batch/s, loss=0.0114]\n",
      "Epoch 255/1000, Training Loss: 0.0329\n",
      "Epoch 255/1000, Validation Loss: 0.0259\n",
      "Epoch 256/1000: 100%|███████████| 63/63 [00:01<00:00, 35.43batch/s, loss=0.0378]\n",
      "Epoch 256/1000, Training Loss: 0.0335\n",
      "Epoch 256/1000, Validation Loss: 0.0257\n",
      "Epoch 257/1000: 100%|███████████| 63/63 [00:01<00:00, 36.69batch/s, loss=0.0365]\n",
      "Epoch 257/1000, Training Loss: 0.0312\n",
      "Epoch 257/1000, Validation Loss: 0.0280\n",
      "Epoch 258/1000: 100%|███████████| 63/63 [00:01<00:00, 38.08batch/s, loss=0.0339]\n",
      "Epoch 258/1000, Training Loss: 0.0327\n",
      "Epoch 258/1000, Validation Loss: 0.0285\n",
      "Epoch 259/1000: 100%|███████████| 63/63 [00:01<00:00, 36.55batch/s, loss=0.0228]\n",
      "Epoch 259/1000, Training Loss: 0.0333\n",
      "Epoch 259/1000, Validation Loss: 0.0279\n",
      "Epoch 260/1000: 100%|███████████| 63/63 [00:01<00:00, 36.90batch/s, loss=0.0442]\n",
      "Epoch 260/1000, Training Loss: 0.0343\n",
      "Epoch 260/1000, Validation Loss: 0.0276\n",
      "Epoch 261/1000: 100%|███████████| 63/63 [00:01<00:00, 37.83batch/s, loss=0.0437]\n",
      "Epoch 261/1000, Training Loss: 0.0363\n",
      "Epoch 261/1000, Validation Loss: 0.0257\n",
      "Epoch 262/1000: 100%|███████████| 63/63 [00:01<00:00, 36.91batch/s, loss=0.0413]\n",
      "Epoch 262/1000, Training Loss: 0.0374\n",
      "Epoch 262/1000, Validation Loss: 0.0272\n",
      "Epoch 263/1000: 100%|███████████| 63/63 [00:01<00:00, 37.02batch/s, loss=0.0231]\n",
      "Epoch 263/1000, Training Loss: 0.0335\n",
      "Epoch 263/1000, Validation Loss: 0.0243\n",
      "Epoch 264/1000: 100%|███████████| 63/63 [00:01<00:00, 37.19batch/s, loss=0.0336]\n",
      "Epoch 264/1000, Training Loss: 0.0326\n",
      "Epoch 264/1000, Validation Loss: 0.0257\n",
      "Epoch 265/1000: 100%|███████████| 63/63 [00:01<00:00, 35.82batch/s, loss=0.0142]\n",
      "Epoch 265/1000, Training Loss: 0.0339\n",
      "Epoch 265/1000, Validation Loss: 0.0246\n",
      "Epoch 266/1000: 100%|███████████| 63/63 [00:01<00:00, 34.61batch/s, loss=0.0227]\n",
      "Epoch 266/1000, Training Loss: 0.0328\n",
      "Epoch 266/1000, Validation Loss: 0.0292\n",
      "Epoch 267/1000: 100%|███████████| 63/63 [00:01<00:00, 36.93batch/s, loss=0.0336]\n",
      "Epoch 267/1000, Training Loss: 0.0305\n",
      "Epoch 267/1000, Validation Loss: 0.0249\n",
      "Epoch 268/1000: 100%|███████████| 63/63 [00:01<00:00, 35.99batch/s, loss=0.0319]\n",
      "Epoch 268/1000, Training Loss: 0.0323\n",
      "Epoch 268/1000, Validation Loss: 0.0259\n",
      "Epoch 269/1000: 100%|███████████| 63/63 [00:01<00:00, 36.43batch/s, loss=0.0469]\n",
      "Epoch 269/1000, Training Loss: 0.0328\n",
      "Epoch 269/1000, Validation Loss: 0.0307\n",
      "Epoch 270/1000: 100%|███████████| 63/63 [00:01<00:00, 37.32batch/s, loss=0.0228]\n",
      "Epoch 270/1000, Training Loss: 0.0334\n",
      "Epoch 270/1000, Validation Loss: 0.0236\n",
      "Epoch 271/1000: 100%|███████████| 63/63 [00:01<00:00, 36.26batch/s, loss=0.0710]\n",
      "Epoch 271/1000, Training Loss: 0.0311\n",
      "Epoch 271/1000, Validation Loss: 0.0273\n",
      "Epoch 272/1000: 100%|███████████| 63/63 [00:01<00:00, 36.76batch/s, loss=0.0142]\n",
      "Epoch 272/1000, Training Loss: 0.0320\n",
      "Epoch 272/1000, Validation Loss: 0.0220\n",
      "Epoch 273/1000: 100%|███████████| 63/63 [00:01<00:00, 35.81batch/s, loss=0.0557]\n",
      "Epoch 273/1000, Training Loss: 0.0317\n",
      "Epoch 273/1000, Validation Loss: 0.0265\n",
      "Epoch 274/1000: 100%|███████████| 63/63 [00:01<00:00, 36.80batch/s, loss=0.0205]\n",
      "Epoch 274/1000, Training Loss: 0.0334\n",
      "Epoch 274/1000, Validation Loss: 0.0239\n",
      "Epoch 275/1000: 100%|███████████| 63/63 [00:01<00:00, 36.29batch/s, loss=0.0294]\n",
      "Epoch 275/1000, Training Loss: 0.0319\n",
      "Epoch 275/1000, Validation Loss: 0.0258\n",
      "Epoch 276/1000: 100%|███████████| 63/63 [00:01<00:00, 37.43batch/s, loss=0.0149]\n",
      "Epoch 276/1000, Training Loss: 0.0341\n",
      "Epoch 276/1000, Validation Loss: 0.0259\n",
      "Epoch 277/1000: 100%|███████████| 63/63 [00:01<00:00, 35.83batch/s, loss=0.0315]\n",
      "Epoch 277/1000, Training Loss: 0.0336\n",
      "Epoch 277/1000, Validation Loss: 0.0252\n",
      "Epoch 278/1000: 100%|███████████| 63/63 [00:01<00:00, 35.11batch/s, loss=0.0185]\n",
      "Epoch 278/1000, Training Loss: 0.0330\n",
      "Epoch 278/1000, Validation Loss: 0.0243\n",
      "Epoch 279/1000: 100%|███████████| 63/63 [00:01<00:00, 36.09batch/s, loss=0.0574]\n",
      "Epoch 279/1000, Training Loss: 0.0302\n",
      "Epoch 279/1000, Validation Loss: 0.0236\n",
      "Epoch 280/1000: 100%|███████████| 63/63 [00:01<00:00, 36.88batch/s, loss=0.0256]\n",
      "Epoch 280/1000, Training Loss: 0.0333\n",
      "Epoch 280/1000, Validation Loss: 0.0238\n",
      "Epoch 281/1000: 100%|███████████| 63/63 [00:01<00:00, 35.48batch/s, loss=0.0171]\n",
      "Epoch 281/1000, Training Loss: 0.0353\n",
      "Epoch 281/1000, Validation Loss: 0.0253\n",
      "Epoch 282/1000: 100%|███████████| 63/63 [00:01<00:00, 35.39batch/s, loss=0.0344]\n",
      "Epoch 282/1000, Training Loss: 0.0311\n",
      "Epoch 282/1000, Validation Loss: 0.0267\n",
      "Epoch 283/1000: 100%|███████████| 63/63 [00:01<00:00, 35.64batch/s, loss=0.0191]\n",
      "Epoch 283/1000, Training Loss: 0.0352\n",
      "Epoch 283/1000, Validation Loss: 0.0264\n",
      "Epoch 284/1000: 100%|███████████| 63/63 [00:01<00:00, 36.49batch/s, loss=0.0415]\n",
      "Epoch 284/1000, Training Loss: 0.0331\n",
      "Epoch 284/1000, Validation Loss: 0.0224\n",
      "Epoch 285/1000: 100%|███████████| 63/63 [00:01<00:00, 36.57batch/s, loss=0.0293]\n",
      "Epoch 285/1000, Training Loss: 0.0318\n",
      "Epoch 285/1000, Validation Loss: 0.0298\n",
      "Epoch 286/1000: 100%|███████████| 63/63 [00:01<00:00, 36.81batch/s, loss=0.0325]\n",
      "Epoch 286/1000, Training Loss: 0.0317\n",
      "Epoch 286/1000, Validation Loss: 0.0245\n",
      "Epoch 287/1000: 100%|███████████| 63/63 [00:02<00:00, 31.19batch/s, loss=0.0296]\n",
      "Epoch 287/1000, Training Loss: 0.0289\n",
      "Epoch 287/1000, Validation Loss: 0.0251\n",
      "Epoch 288/1000: 100%|███████████| 63/63 [00:01<00:00, 35.60batch/s, loss=0.0206]\n",
      "Epoch 288/1000, Training Loss: 0.0311\n",
      "Epoch 288/1000, Validation Loss: 0.0243\n",
      "Epoch 289/1000: 100%|███████████| 63/63 [00:01<00:00, 35.54batch/s, loss=0.0369]\n",
      "Epoch 289/1000, Training Loss: 0.0329\n",
      "Epoch 289/1000, Validation Loss: 0.0264\n",
      "Epoch 290/1000: 100%|███████████| 63/63 [00:01<00:00, 36.46batch/s, loss=0.0409]\n",
      "Epoch 290/1000, Training Loss: 0.0342\n",
      "Epoch 290/1000, Validation Loss: 0.0226\n",
      "Epoch 291/1000: 100%|███████████| 63/63 [00:01<00:00, 36.61batch/s, loss=0.0314]\n",
      "Epoch 291/1000, Training Loss: 0.0333\n",
      "Epoch 291/1000, Validation Loss: 0.0246\n",
      "Epoch 292/1000: 100%|███████████| 63/63 [00:01<00:00, 36.40batch/s, loss=0.0321]\n",
      "Epoch 292/1000, Training Loss: 0.0305\n",
      "Epoch 292/1000, Validation Loss: 0.0218\n",
      "Epoch 293/1000: 100%|███████████| 63/63 [00:01<00:00, 36.47batch/s, loss=0.0511]\n",
      "Epoch 293/1000, Training Loss: 0.0328\n",
      "Epoch 293/1000, Validation Loss: 0.0213\n",
      "Epoch 294/1000: 100%|███████████| 63/63 [00:01<00:00, 34.90batch/s, loss=0.0236]\n",
      "Epoch 294/1000, Training Loss: 0.0331\n",
      "Epoch 294/1000, Validation Loss: 0.0237\n",
      "Epoch 295/1000: 100%|███████████| 63/63 [00:01<00:00, 37.47batch/s, loss=0.0278]\n",
      "Epoch 295/1000, Training Loss: 0.0313\n",
      "Epoch 295/1000, Validation Loss: 0.0230\n",
      "Epoch 296/1000: 100%|███████████| 63/63 [00:01<00:00, 35.13batch/s, loss=0.0257]\n",
      "Epoch 296/1000, Training Loss: 0.0317\n",
      "Epoch 296/1000, Validation Loss: 0.0252\n",
      "Epoch 297/1000: 100%|███████████| 63/63 [00:01<00:00, 35.64batch/s, loss=0.0277]\n",
      "Epoch 297/1000, Training Loss: 0.0337\n",
      "Epoch 297/1000, Validation Loss: 0.0255\n",
      "Epoch 298/1000: 100%|███████████| 63/63 [00:01<00:00, 36.66batch/s, loss=0.0115]\n",
      "Epoch 298/1000, Training Loss: 0.0330\n",
      "Epoch 298/1000, Validation Loss: 0.0265\n",
      "Epoch 299/1000: 100%|███████████| 63/63 [00:01<00:00, 37.03batch/s, loss=0.0280]\n",
      "Epoch 299/1000, Training Loss: 0.0310\n",
      "Epoch 299/1000, Validation Loss: 0.0233\n",
      "Epoch 300/1000: 100%|███████████| 63/63 [00:01<00:00, 36.71batch/s, loss=0.0440]\n",
      "Epoch 300/1000, Training Loss: 0.0296\n",
      "Epoch 300/1000, Validation Loss: 0.0218\n",
      "Epoch 301/1000: 100%|███████████| 63/63 [00:01<00:00, 37.11batch/s, loss=0.0533]\n",
      "Epoch 301/1000, Training Loss: 0.0360\n",
      "Epoch 301/1000, Validation Loss: 0.0232\n",
      "Epoch 302/1000: 100%|███████████| 63/63 [00:01<00:00, 36.20batch/s, loss=0.0149]\n",
      "Epoch 302/1000, Training Loss: 0.0296\n",
      "Epoch 302/1000, Validation Loss: 0.0213\n",
      "Epoch 303/1000: 100%|███████████| 63/63 [00:01<00:00, 36.69batch/s, loss=0.0141]\n",
      "Epoch 303/1000, Training Loss: 0.0299\n",
      "Epoch 303/1000, Validation Loss: 0.0244\n",
      "Epoch 304/1000: 100%|███████████| 63/63 [00:01<00:00, 37.18batch/s, loss=0.0265]\n",
      "Epoch 304/1000, Training Loss: 0.0303\n",
      "Epoch 304/1000, Validation Loss: 0.0206\n",
      "Epoch 305/1000: 100%|███████████| 63/63 [00:01<00:00, 36.17batch/s, loss=0.0365]\n",
      "Epoch 305/1000, Training Loss: 0.0303\n",
      "Epoch 305/1000, Validation Loss: 0.0217\n",
      "Epoch 306/1000: 100%|███████████| 63/63 [00:01<00:00, 36.52batch/s, loss=0.0502]\n",
      "Epoch 306/1000, Training Loss: 0.0292\n",
      "Epoch 306/1000, Validation Loss: 0.0240\n",
      "Epoch 307/1000: 100%|███████████| 63/63 [00:01<00:00, 36.48batch/s, loss=0.0287]\n",
      "Epoch 307/1000, Training Loss: 0.0329\n",
      "Epoch 307/1000, Validation Loss: 0.0304\n",
      "Epoch 308/1000: 100%|███████████| 63/63 [00:01<00:00, 36.86batch/s, loss=0.0279]\n",
      "Epoch 308/1000, Training Loss: 0.0351\n",
      "Epoch 308/1000, Validation Loss: 0.0232\n",
      "Epoch 309/1000: 100%|███████████| 63/63 [00:01<00:00, 33.94batch/s, loss=0.0199]\n",
      "Epoch 309/1000, Training Loss: 0.0303\n",
      "Epoch 309/1000, Validation Loss: 0.0270\n",
      "Epoch 310/1000: 100%|███████████| 63/63 [00:01<00:00, 36.04batch/s, loss=0.0293]\n",
      "Epoch 310/1000, Training Loss: 0.0310\n",
      "Epoch 310/1000, Validation Loss: 0.0230\n",
      "Epoch 311/1000: 100%|███████████| 63/63 [00:01<00:00, 35.14batch/s, loss=0.0174]\n",
      "Epoch 311/1000, Training Loss: 0.0309\n",
      "Epoch 311/1000, Validation Loss: 0.0222\n",
      "Epoch 312/1000: 100%|███████████| 63/63 [00:01<00:00, 36.37batch/s, loss=0.0282]\n",
      "Epoch 312/1000, Training Loss: 0.0317\n",
      "Epoch 312/1000, Validation Loss: 0.0235\n",
      "Epoch 313/1000: 100%|███████████| 63/63 [00:01<00:00, 37.00batch/s, loss=0.0137]\n",
      "Epoch 313/1000, Training Loss: 0.0317\n",
      "Epoch 313/1000, Validation Loss: 0.0218\n",
      "Epoch 314/1000: 100%|███████████| 63/63 [00:01<00:00, 36.95batch/s, loss=0.0217]\n",
      "Epoch 314/1000, Training Loss: 0.0314\n",
      "Epoch 314/1000, Validation Loss: 0.0229\n",
      "Epoch 315/1000: 100%|███████████| 63/63 [00:01<00:00, 35.37batch/s, loss=0.0303]\n",
      "Epoch 315/1000, Training Loss: 0.0296\n",
      "Epoch 315/1000, Validation Loss: 0.0228\n",
      "Epoch 316/1000: 100%|███████████| 63/63 [00:01<00:00, 36.55batch/s, loss=0.0356]\n",
      "Epoch 316/1000, Training Loss: 0.0335\n",
      "Epoch 316/1000, Validation Loss: 0.0271\n",
      "Epoch 317/1000: 100%|███████████| 63/63 [00:01<00:00, 37.33batch/s, loss=0.0225]\n",
      "Epoch 317/1000, Training Loss: 0.0324\n",
      "Epoch 317/1000, Validation Loss: 0.0220\n",
      "Epoch 318/1000: 100%|███████████| 63/63 [00:01<00:00, 37.82batch/s, loss=0.0582]\n",
      "Epoch 318/1000, Training Loss: 0.0300\n",
      "Epoch 318/1000, Validation Loss: 0.0312\n",
      "Epoch 319/1000: 100%|███████████| 63/63 [00:01<00:00, 36.03batch/s, loss=0.0195]\n",
      "Epoch 319/1000, Training Loss: 0.0322\n",
      "Epoch 319/1000, Validation Loss: 0.0211\n",
      "Epoch 320/1000: 100%|███████████| 63/63 [00:01<00:00, 36.17batch/s, loss=0.0130]\n",
      "Epoch 320/1000, Training Loss: 0.0296\n",
      "Epoch 320/1000, Validation Loss: 0.0204\n",
      "Epoch 321/1000: 100%|███████████| 63/63 [00:01<00:00, 34.73batch/s, loss=0.0184]\n",
      "Epoch 321/1000, Training Loss: 0.0305\n",
      "Epoch 321/1000, Validation Loss: 0.0223\n",
      "Epoch 322/1000: 100%|███████████| 63/63 [00:01<00:00, 36.31batch/s, loss=0.0635]\n",
      "Epoch 322/1000, Training Loss: 0.0305\n",
      "Epoch 322/1000, Validation Loss: 0.0215\n",
      "Epoch 323/1000: 100%|███████████| 63/63 [00:01<00:00, 35.52batch/s, loss=0.0330]\n",
      "Epoch 323/1000, Training Loss: 0.0311\n",
      "Epoch 323/1000, Validation Loss: 0.0247\n",
      "Epoch 324/1000: 100%|███████████| 63/63 [00:01<00:00, 35.89batch/s, loss=0.0433]\n",
      "Epoch 324/1000, Training Loss: 0.0323\n",
      "Epoch 324/1000, Validation Loss: 0.0212\n",
      "Epoch 325/1000: 100%|███████████| 63/63 [00:01<00:00, 36.08batch/s, loss=0.0178]\n",
      "Epoch 325/1000, Training Loss: 0.0305\n",
      "Epoch 325/1000, Validation Loss: 0.0220\n",
      "Epoch 326/1000: 100%|███████████| 63/63 [00:01<00:00, 35.68batch/s, loss=0.0508]\n",
      "Epoch 326/1000, Training Loss: 0.0306\n",
      "Epoch 326/1000, Validation Loss: 0.0216\n",
      "Epoch 327/1000: 100%|███████████| 63/63 [00:01<00:00, 34.97batch/s, loss=0.0263]\n",
      "Epoch 327/1000, Training Loss: 0.0345\n",
      "Epoch 327/1000, Validation Loss: 0.0269\n",
      "Epoch 328/1000: 100%|███████████| 63/63 [00:01<00:00, 35.42batch/s, loss=0.0350]\n",
      "Epoch 328/1000, Training Loss: 0.0304\n",
      "Epoch 328/1000, Validation Loss: 0.0212\n",
      "Epoch 329/1000: 100%|███████████| 63/63 [00:01<00:00, 36.53batch/s, loss=0.0391]\n",
      "Epoch 329/1000, Training Loss: 0.0294\n",
      "Epoch 329/1000, Validation Loss: 0.0231\n",
      "Epoch 330/1000: 100%|███████████| 63/63 [00:01<00:00, 35.57batch/s, loss=0.0232]\n",
      "Epoch 330/1000, Training Loss: 0.0276\n",
      "Epoch 330/1000, Validation Loss: 0.0222\n",
      "Epoch 331/1000: 100%|███████████| 63/63 [00:01<00:00, 34.42batch/s, loss=0.0265]\n",
      "Epoch 331/1000, Training Loss: 0.0291\n",
      "Epoch 331/1000, Validation Loss: 0.0221\n",
      "Epoch 332/1000: 100%|███████████| 63/63 [00:01<00:00, 35.40batch/s, loss=0.0311]\n",
      "Epoch 332/1000, Training Loss: 0.0325\n",
      "Epoch 332/1000, Validation Loss: 0.0226\n",
      "Epoch 333/1000: 100%|███████████| 63/63 [00:01<00:00, 34.97batch/s, loss=0.0209]\n",
      "Epoch 333/1000, Training Loss: 0.0314\n",
      "Epoch 333/1000, Validation Loss: 0.0224\n",
      "Epoch 334/1000: 100%|███████████| 63/63 [00:01<00:00, 34.46batch/s, loss=0.0244]\n",
      "Epoch 334/1000, Training Loss: 0.0298\n",
      "Epoch 334/1000, Validation Loss: 0.0195\n",
      "Epoch 335/1000: 100%|███████████| 63/63 [00:01<00:00, 36.15batch/s, loss=0.0209]\n",
      "Epoch 335/1000, Training Loss: 0.0299\n",
      "Epoch 335/1000, Validation Loss: 0.0217\n",
      "Epoch 336/1000: 100%|███████████| 63/63 [00:01<00:00, 34.56batch/s, loss=0.0200]\n",
      "Epoch 336/1000, Training Loss: 0.0323\n",
      "Epoch 336/1000, Validation Loss: 0.0221\n",
      "Epoch 337/1000: 100%|███████████| 63/63 [00:01<00:00, 36.08batch/s, loss=0.0368]\n",
      "Epoch 337/1000, Training Loss: 0.0282\n",
      "Epoch 337/1000, Validation Loss: 0.0222\n",
      "Epoch 338/1000: 100%|███████████| 63/63 [00:01<00:00, 36.75batch/s, loss=0.0131]\n",
      "Epoch 338/1000, Training Loss: 0.0297\n",
      "Epoch 338/1000, Validation Loss: 0.0218\n",
      "Epoch 339/1000: 100%|███████████| 63/63 [00:01<00:00, 35.04batch/s, loss=0.0495]\n",
      "Epoch 339/1000, Training Loss: 0.0285\n",
      "Epoch 339/1000, Validation Loss: 0.0208\n",
      "Epoch 340/1000: 100%|███████████| 63/63 [00:01<00:00, 35.90batch/s, loss=0.0304]\n",
      "Epoch 340/1000, Training Loss: 0.0293\n",
      "Epoch 340/1000, Validation Loss: 0.0204\n",
      "Epoch 341/1000: 100%|███████████| 63/63 [00:01<00:00, 36.67batch/s, loss=0.0332]\n",
      "Epoch 341/1000, Training Loss: 0.0273\n",
      "Epoch 341/1000, Validation Loss: 0.0213\n",
      "Epoch 342/1000: 100%|███████████| 63/63 [00:01<00:00, 37.21batch/s, loss=0.0372]\n",
      "Epoch 342/1000, Training Loss: 0.0305\n",
      "Epoch 342/1000, Validation Loss: 0.0201\n",
      "Epoch 343/1000: 100%|███████████| 63/63 [00:01<00:00, 36.25batch/s, loss=0.0204]\n",
      "Epoch 343/1000, Training Loss: 0.0287\n",
      "Epoch 343/1000, Validation Loss: 0.0204\n",
      "Epoch 344/1000: 100%|███████████| 63/63 [00:01<00:00, 36.44batch/s, loss=0.0252]\n",
      "Epoch 344/1000, Training Loss: 0.0300\n",
      "Epoch 344/1000, Validation Loss: 0.0230\n",
      "Epoch 345/1000: 100%|███████████| 63/63 [00:01<00:00, 36.41batch/s, loss=0.0196]\n",
      "Epoch 345/1000, Training Loss: 0.0304\n",
      "Epoch 345/1000, Validation Loss: 0.0241\n",
      "Epoch 346/1000: 100%|███████████| 63/63 [00:01<00:00, 36.92batch/s, loss=0.0749]\n",
      "Epoch 346/1000, Training Loss: 0.0291\n",
      "Epoch 346/1000, Validation Loss: 0.0217\n",
      "Epoch 347/1000: 100%|███████████| 63/63 [00:01<00:00, 35.49batch/s, loss=0.0450]\n",
      "Epoch 347/1000, Training Loss: 0.0310\n",
      "Epoch 347/1000, Validation Loss: 0.0236\n",
      "Epoch 348/1000: 100%|███████████| 63/63 [00:01<00:00, 35.74batch/s, loss=0.0441]\n",
      "Epoch 348/1000, Training Loss: 0.0332\n",
      "Epoch 348/1000, Validation Loss: 0.0255\n",
      "Epoch 349/1000: 100%|███████████| 63/63 [00:01<00:00, 33.17batch/s, loss=0.0196]\n",
      "Epoch 349/1000, Training Loss: 0.0331\n",
      "Epoch 349/1000, Validation Loss: 0.0279\n",
      "Epoch 350/1000: 100%|███████████| 63/63 [00:01<00:00, 35.82batch/s, loss=0.0206]\n",
      "Epoch 350/1000, Training Loss: 0.0304\n",
      "Epoch 350/1000, Validation Loss: 0.0221\n",
      "Epoch 351/1000: 100%|███████████| 63/63 [00:01<00:00, 35.92batch/s, loss=0.0415]\n",
      "Epoch 351/1000, Training Loss: 0.0309\n",
      "Epoch 351/1000, Validation Loss: 0.0216\n",
      "Epoch 352/1000: 100%|███████████| 63/63 [00:01<00:00, 36.83batch/s, loss=0.0304]\n",
      "Epoch 352/1000, Training Loss: 0.0302\n",
      "Epoch 352/1000, Validation Loss: 0.0219\n",
      "Epoch 353/1000: 100%|███████████| 63/63 [00:01<00:00, 36.69batch/s, loss=0.0178]\n",
      "Epoch 353/1000, Training Loss: 0.0292\n",
      "Epoch 353/1000, Validation Loss: 0.0230\n",
      "Epoch 354/1000: 100%|███████████| 63/63 [00:01<00:00, 35.35batch/s, loss=0.0258]\n",
      "Epoch 354/1000, Training Loss: 0.0291\n",
      "Epoch 354/1000, Validation Loss: 0.0216\n",
      "Epoch 355/1000: 100%|███████████| 63/63 [00:01<00:00, 35.53batch/s, loss=0.0142]\n",
      "Epoch 355/1000, Training Loss: 0.0282\n",
      "Epoch 355/1000, Validation Loss: 0.0218\n",
      "Epoch 356/1000: 100%|███████████| 63/63 [00:01<00:00, 35.92batch/s, loss=0.0416]\n",
      "Epoch 356/1000, Training Loss: 0.0270\n",
      "Epoch 356/1000, Validation Loss: 0.0192\n",
      "Epoch 357/1000: 100%|███████████| 63/63 [00:01<00:00, 34.98batch/s, loss=0.0348]\n",
      "Epoch 357/1000, Training Loss: 0.0265\n",
      "Epoch 357/1000, Validation Loss: 0.0192\n",
      "Epoch 358/1000: 100%|███████████| 63/63 [00:01<00:00, 34.81batch/s, loss=0.0377]\n",
      "Epoch 358/1000, Training Loss: 0.0295\n",
      "Epoch 358/1000, Validation Loss: 0.0203\n",
      "Epoch 359/1000: 100%|███████████| 63/63 [00:01<00:00, 35.89batch/s, loss=0.0302]\n",
      "Epoch 359/1000, Training Loss: 0.0286\n",
      "Epoch 359/1000, Validation Loss: 0.0197\n",
      "Epoch 360/1000: 100%|███████████| 63/63 [00:01<00:00, 35.99batch/s, loss=0.0363]\n",
      "Epoch 360/1000, Training Loss: 0.0288\n",
      "Epoch 360/1000, Validation Loss: 0.0206\n",
      "Epoch 361/1000: 100%|███████████| 63/63 [00:01<00:00, 36.02batch/s, loss=0.0258]\n",
      "Epoch 361/1000, Training Loss: 0.0290\n",
      "Epoch 361/1000, Validation Loss: 0.0211\n",
      "Epoch 362/1000: 100%|███████████| 63/63 [00:01<00:00, 35.83batch/s, loss=0.0425]\n",
      "Epoch 362/1000, Training Loss: 0.0310\n",
      "Epoch 362/1000, Validation Loss: 0.0241\n",
      "Epoch 363/1000: 100%|███████████| 63/63 [00:01<00:00, 35.86batch/s, loss=0.0484]\n",
      "Epoch 363/1000, Training Loss: 0.0297\n",
      "Epoch 363/1000, Validation Loss: 0.0204\n",
      "Epoch 364/1000: 100%|███████████| 63/63 [00:01<00:00, 36.50batch/s, loss=0.0383]\n",
      "Epoch 364/1000, Training Loss: 0.0288\n",
      "Epoch 364/1000, Validation Loss: 0.0218\n",
      "Epoch 365/1000: 100%|███████████| 63/63 [00:01<00:00, 36.39batch/s, loss=0.0251]\n",
      "Epoch 365/1000, Training Loss: 0.0286\n",
      "Epoch 365/1000, Validation Loss: 0.0190\n",
      "Epoch 366/1000: 100%|███████████| 63/63 [00:01<00:00, 35.00batch/s, loss=0.0241]\n",
      "Epoch 366/1000, Training Loss: 0.0273\n",
      "Epoch 366/1000, Validation Loss: 0.0190\n",
      "Epoch 367/1000: 100%|███████████| 63/63 [00:01<00:00, 35.30batch/s, loss=0.0274]\n",
      "Epoch 367/1000, Training Loss: 0.0286\n",
      "Epoch 367/1000, Validation Loss: 0.0212\n",
      "Epoch 368/1000: 100%|███████████| 63/63 [00:01<00:00, 35.30batch/s, loss=0.0301]\n",
      "Epoch 368/1000, Training Loss: 0.0268\n",
      "Epoch 368/1000, Validation Loss: 0.0197\n",
      "Epoch 369/1000: 100%|███████████| 63/63 [00:01<00:00, 35.71batch/s, loss=0.0170]\n",
      "Epoch 369/1000, Training Loss: 0.0299\n",
      "Epoch 369/1000, Validation Loss: 0.0221\n",
      "Epoch 370/1000: 100%|███████████| 63/63 [00:01<00:00, 35.08batch/s, loss=0.0158]\n",
      "Epoch 370/1000, Training Loss: 0.0287\n",
      "Epoch 370/1000, Validation Loss: 0.0187\n",
      "Epoch 371/1000: 100%|███████████| 63/63 [00:01<00:00, 35.88batch/s, loss=0.0141]\n",
      "Epoch 371/1000, Training Loss: 0.0274\n",
      "Epoch 371/1000, Validation Loss: 0.0187\n",
      "Epoch 372/1000: 100%|███████████| 63/63 [00:01<00:00, 35.04batch/s, loss=0.0316]\n",
      "Epoch 372/1000, Training Loss: 0.0277\n",
      "Epoch 372/1000, Validation Loss: 0.0194\n",
      "Epoch 373/1000: 100%|███████████| 63/63 [00:01<00:00, 35.77batch/s, loss=0.0278]\n",
      "Epoch 373/1000, Training Loss: 0.0283\n",
      "Epoch 373/1000, Validation Loss: 0.0203\n",
      "Epoch 374/1000: 100%|███████████| 63/63 [00:01<00:00, 35.96batch/s, loss=0.0215]\n",
      "Epoch 374/1000, Training Loss: 0.0293\n",
      "Epoch 374/1000, Validation Loss: 0.0228\n",
      "Epoch 375/1000: 100%|███████████| 63/63 [00:01<00:00, 36.10batch/s, loss=0.0319]\n",
      "Epoch 375/1000, Training Loss: 0.0278\n",
      "Epoch 375/1000, Validation Loss: 0.0226\n",
      "Epoch 376/1000: 100%|███████████| 63/63 [00:01<00:00, 36.76batch/s, loss=0.0208]\n",
      "Epoch 376/1000, Training Loss: 0.0299\n",
      "Epoch 376/1000, Validation Loss: 0.0193\n",
      "Epoch 377/1000: 100%|███████████| 63/63 [00:01<00:00, 36.27batch/s, loss=0.0241]\n",
      "Epoch 377/1000, Training Loss: 0.0288\n",
      "Epoch 377/1000, Validation Loss: 0.0209\n",
      "Epoch 378/1000: 100%|███████████| 63/63 [00:01<00:00, 35.70batch/s, loss=0.0177]\n",
      "Epoch 378/1000, Training Loss: 0.0274\n",
      "Epoch 378/1000, Validation Loss: 0.0215\n",
      "Epoch 379/1000: 100%|███████████| 63/63 [00:01<00:00, 35.74batch/s, loss=0.0328]\n",
      "Epoch 379/1000, Training Loss: 0.0289\n",
      "Epoch 379/1000, Validation Loss: 0.0208\n",
      "Epoch 380/1000: 100%|███████████| 63/63 [00:01<00:00, 35.68batch/s, loss=0.0515]\n",
      "Epoch 380/1000, Training Loss: 0.0298\n",
      "Epoch 380/1000, Validation Loss: 0.0191\n",
      "Epoch 381/1000: 100%|███████████| 63/63 [00:01<00:00, 35.94batch/s, loss=0.0091]\n",
      "Epoch 381/1000, Training Loss: 0.0282\n",
      "Epoch 381/1000, Validation Loss: 0.0206\n",
      "Epoch 382/1000: 100%|███████████| 63/63 [00:01<00:00, 35.32batch/s, loss=0.0219]\n",
      "Epoch 382/1000, Training Loss: 0.0274\n",
      "Epoch 382/1000, Validation Loss: 0.0196\n",
      "Epoch 383/1000: 100%|███████████| 63/63 [00:01<00:00, 34.96batch/s, loss=0.0318]\n",
      "Epoch 383/1000, Training Loss: 0.0260\n",
      "Epoch 383/1000, Validation Loss: 0.0201\n",
      "Epoch 384/1000: 100%|███████████| 63/63 [00:01<00:00, 35.75batch/s, loss=0.0438]\n",
      "Epoch 384/1000, Training Loss: 0.0298\n",
      "Epoch 384/1000, Validation Loss: 0.0228\n",
      "Epoch 385/1000: 100%|███████████| 63/63 [00:01<00:00, 36.06batch/s, loss=0.0338]\n",
      "Epoch 385/1000, Training Loss: 0.0330\n",
      "Epoch 385/1000, Validation Loss: 0.0229\n",
      "Epoch 386/1000: 100%|███████████| 63/63 [00:01<00:00, 35.53batch/s, loss=0.0169]\n",
      "Epoch 386/1000, Training Loss: 0.0287\n",
      "Epoch 386/1000, Validation Loss: 0.0220\n",
      "Epoch 387/1000: 100%|███████████| 63/63 [00:01<00:00, 33.63batch/s, loss=0.0282]\n",
      "Epoch 387/1000, Training Loss: 0.0303\n",
      "Epoch 387/1000, Validation Loss: 0.0194\n",
      "Epoch 388/1000: 100%|███████████| 63/63 [00:01<00:00, 34.49batch/s, loss=0.0794]\n",
      "Epoch 388/1000, Training Loss: 0.0262\n",
      "Epoch 388/1000, Validation Loss: 0.0203\n",
      "Epoch 389/1000: 100%|███████████| 63/63 [00:01<00:00, 35.27batch/s, loss=0.0468]\n",
      "Epoch 389/1000, Training Loss: 0.0285\n",
      "Epoch 389/1000, Validation Loss: 0.0193\n",
      "Epoch 390/1000: 100%|███████████| 63/63 [00:01<00:00, 36.06batch/s, loss=0.0590]\n",
      "Epoch 390/1000, Training Loss: 0.0281\n",
      "Epoch 390/1000, Validation Loss: 0.0218\n",
      "Epoch 391/1000: 100%|███████████| 63/63 [00:01<00:00, 36.07batch/s, loss=0.0213]\n",
      "Epoch 391/1000, Training Loss: 0.0292\n",
      "Epoch 391/1000, Validation Loss: 0.0205\n",
      "Epoch 392/1000: 100%|███████████| 63/63 [00:01<00:00, 36.19batch/s, loss=0.0376]\n",
      "Epoch 392/1000, Training Loss: 0.0282\n",
      "Epoch 392/1000, Validation Loss: 0.0224\n",
      "Epoch 393/1000: 100%|███████████| 63/63 [00:01<00:00, 34.80batch/s, loss=0.0226]\n",
      "Epoch 393/1000, Training Loss: 0.0295\n",
      "Epoch 393/1000, Validation Loss: 0.0200\n",
      "Epoch 394/1000: 100%|███████████| 63/63 [00:01<00:00, 36.38batch/s, loss=0.0270]\n",
      "Epoch 394/1000, Training Loss: 0.0267\n",
      "Epoch 394/1000, Validation Loss: 0.0213\n",
      "Epoch 395/1000: 100%|███████████| 63/63 [00:01<00:00, 34.70batch/s, loss=0.0456]\n",
      "Epoch 395/1000, Training Loss: 0.0279\n",
      "Epoch 395/1000, Validation Loss: 0.0213\n",
      "Epoch 396/1000: 100%|███████████| 63/63 [00:01<00:00, 36.05batch/s, loss=0.0366]\n",
      "Epoch 396/1000, Training Loss: 0.0330\n",
      "Epoch 396/1000, Validation Loss: 0.0201\n",
      "Epoch 397/1000: 100%|███████████| 63/63 [00:01<00:00, 36.03batch/s, loss=0.0184]\n",
      "Epoch 397/1000, Training Loss: 0.0285\n",
      "Epoch 397/1000, Validation Loss: 0.0218\n",
      "Epoch 398/1000: 100%|███████████| 63/63 [00:01<00:00, 35.55batch/s, loss=0.0475]\n",
      "Epoch 398/1000, Training Loss: 0.0289\n",
      "Epoch 398/1000, Validation Loss: 0.0229\n",
      "Epoch 399/1000: 100%|███████████| 63/63 [00:01<00:00, 36.48batch/s, loss=0.0300]\n",
      "Epoch 399/1000, Training Loss: 0.0281\n",
      "Epoch 399/1000, Validation Loss: 0.0195\n",
      "Epoch 400/1000: 100%|███████████| 63/63 [00:01<00:00, 35.68batch/s, loss=0.0282]\n",
      "Epoch 400/1000, Training Loss: 0.0272\n",
      "Epoch 400/1000, Validation Loss: 0.0192\n",
      "Epoch 401/1000: 100%|███████████| 63/63 [00:01<00:00, 36.04batch/s, loss=0.0270]\n",
      "Epoch 401/1000, Training Loss: 0.0290\n",
      "Epoch 401/1000, Validation Loss: 0.0205\n",
      "Epoch 402/1000: 100%|███████████| 63/63 [00:01<00:00, 34.68batch/s, loss=0.0313]\n",
      "Epoch 402/1000, Training Loss: 0.0287\n",
      "Epoch 402/1000, Validation Loss: 0.0197\n",
      "Epoch 403/1000: 100%|███████████| 63/63 [00:01<00:00, 35.97batch/s, loss=0.0329]\n",
      "Epoch 403/1000, Training Loss: 0.0288\n",
      "Epoch 403/1000, Validation Loss: 0.0204\n",
      "Epoch 404/1000: 100%|███████████| 63/63 [00:01<00:00, 36.38batch/s, loss=0.0119]\n",
      "Epoch 404/1000, Training Loss: 0.0266\n",
      "Epoch 404/1000, Validation Loss: 0.0195\n",
      "Epoch 405/1000: 100%|███████████| 63/63 [00:01<00:00, 36.10batch/s, loss=0.0117]\n",
      "Epoch 405/1000, Training Loss: 0.0244\n",
      "Epoch 405/1000, Validation Loss: 0.0193\n",
      "Epoch 406/1000: 100%|███████████| 63/63 [00:01<00:00, 35.54batch/s, loss=0.0218]\n",
      "Epoch 406/1000, Training Loss: 0.0278\n",
      "Epoch 406/1000, Validation Loss: 0.0228\n",
      "Epoch 407/1000: 100%|███████████| 63/63 [00:01<00:00, 34.61batch/s, loss=0.0218]\n",
      "Epoch 407/1000, Training Loss: 0.0281\n",
      "Epoch 407/1000, Validation Loss: 0.0197\n",
      "Epoch 408/1000: 100%|███████████| 63/63 [00:01<00:00, 34.85batch/s, loss=0.0293]\n",
      "Epoch 408/1000, Training Loss: 0.0260\n",
      "Epoch 408/1000, Validation Loss: 0.0197\n",
      "Epoch 409/1000: 100%|███████████| 63/63 [00:01<00:00, 35.78batch/s, loss=0.0269]\n",
      "Epoch 409/1000, Training Loss: 0.0301\n",
      "Epoch 409/1000, Validation Loss: 0.0208\n",
      "Epoch 410/1000: 100%|███████████| 63/63 [00:01<00:00, 34.98batch/s, loss=0.0052]\n",
      "Epoch 410/1000, Training Loss: 0.0273\n",
      "Epoch 410/1000, Validation Loss: 0.0183\n",
      "Epoch 411/1000: 100%|███████████| 63/63 [00:01<00:00, 35.75batch/s, loss=0.0176]\n",
      "Epoch 411/1000, Training Loss: 0.0272\n",
      "Epoch 411/1000, Validation Loss: 0.0234\n",
      "Epoch 412/1000: 100%|███████████| 63/63 [00:01<00:00, 35.87batch/s, loss=0.0143]\n",
      "Epoch 412/1000, Training Loss: 0.0274\n",
      "Epoch 412/1000, Validation Loss: 0.0202\n",
      "Epoch 413/1000: 100%|███████████| 63/63 [00:01<00:00, 36.11batch/s, loss=0.0191]\n",
      "Epoch 413/1000, Training Loss: 0.0284\n",
      "Epoch 413/1000, Validation Loss: 0.0192\n",
      "Epoch 414/1000: 100%|███████████| 63/63 [00:01<00:00, 34.25batch/s, loss=0.0228]\n",
      "Epoch 414/1000, Training Loss: 0.0269\n",
      "Epoch 414/1000, Validation Loss: 0.0219\n",
      "Epoch 415/1000: 100%|███████████| 63/63 [00:01<00:00, 35.36batch/s, loss=0.0395]\n",
      "Epoch 415/1000, Training Loss: 0.0253\n",
      "Epoch 415/1000, Validation Loss: 0.0203\n",
      "Epoch 416/1000: 100%|███████████| 63/63 [00:01<00:00, 35.77batch/s, loss=0.0188]\n",
      "Epoch 416/1000, Training Loss: 0.0264\n",
      "Epoch 416/1000, Validation Loss: 0.0202\n",
      "Epoch 417/1000: 100%|███████████| 63/63 [00:01<00:00, 36.60batch/s, loss=0.0415]\n",
      "Epoch 417/1000, Training Loss: 0.0260\n",
      "Epoch 417/1000, Validation Loss: 0.0200\n",
      "Epoch 418/1000: 100%|███████████| 63/63 [00:01<00:00, 35.17batch/s, loss=0.0247]\n",
      "Epoch 418/1000, Training Loss: 0.0290\n",
      "Epoch 418/1000, Validation Loss: 0.0199\n",
      "Epoch 419/1000: 100%|███████████| 63/63 [00:01<00:00, 35.23batch/s, loss=0.0245]\n",
      "Epoch 419/1000, Training Loss: 0.0283\n",
      "Epoch 419/1000, Validation Loss: 0.0202\n",
      "Epoch 420/1000: 100%|███████████| 63/63 [00:01<00:00, 36.87batch/s, loss=0.0218]\n",
      "Epoch 420/1000, Training Loss: 0.0316\n",
      "Epoch 420/1000, Validation Loss: 0.0219\n",
      "Epoch 421/1000: 100%|███████████| 63/63 [00:01<00:00, 37.22batch/s, loss=0.0238]\n",
      "Epoch 421/1000, Training Loss: 0.0281\n",
      "Epoch 421/1000, Validation Loss: 0.0218\n",
      "Epoch 422/1000: 100%|███████████| 63/63 [00:01<00:00, 36.33batch/s, loss=0.0250]\n",
      "Epoch 422/1000, Training Loss: 0.0272\n",
      "Epoch 422/1000, Validation Loss: 0.0182\n",
      "Epoch 423/1000: 100%|███████████| 63/63 [00:01<00:00, 35.85batch/s, loss=0.0206]\n",
      "Epoch 423/1000, Training Loss: 0.0258\n",
      "Epoch 423/1000, Validation Loss: 0.0198\n",
      "Epoch 424/1000: 100%|███████████| 63/63 [00:01<00:00, 36.04batch/s, loss=0.0339]\n",
      "Epoch 424/1000, Training Loss: 0.0264\n",
      "Epoch 424/1000, Validation Loss: 0.0172\n",
      "Epoch 425/1000: 100%|███████████| 63/63 [00:01<00:00, 34.49batch/s, loss=0.0403]\n",
      "Epoch 425/1000, Training Loss: 0.0253\n",
      "Epoch 425/1000, Validation Loss: 0.0206\n",
      "Epoch 426/1000: 100%|███████████| 63/63 [00:01<00:00, 35.95batch/s, loss=0.0204]\n",
      "Epoch 426/1000, Training Loss: 0.0247\n",
      "Epoch 426/1000, Validation Loss: 0.0189\n",
      "Epoch 427/1000: 100%|███████████| 63/63 [00:01<00:00, 36.49batch/s, loss=0.0284]\n",
      "Epoch 427/1000, Training Loss: 0.0277\n",
      "Epoch 427/1000, Validation Loss: 0.0211\n",
      "Epoch 428/1000: 100%|███████████| 63/63 [00:01<00:00, 35.82batch/s, loss=0.0536]\n",
      "Epoch 428/1000, Training Loss: 0.0267\n",
      "Epoch 428/1000, Validation Loss: 0.0182\n",
      "Epoch 429/1000: 100%|███████████| 63/63 [00:01<00:00, 35.83batch/s, loss=0.0297]\n",
      "Epoch 429/1000, Training Loss: 0.0275\n",
      "Epoch 429/1000, Validation Loss: 0.0188\n",
      "Epoch 430/1000: 100%|███████████| 63/63 [00:01<00:00, 35.26batch/s, loss=0.0336]\n",
      "Epoch 430/1000, Training Loss: 0.0303\n",
      "Epoch 430/1000, Validation Loss: 0.0211\n",
      "Epoch 431/1000: 100%|███████████| 63/63 [00:01<00:00, 35.49batch/s, loss=0.0176]\n",
      "Epoch 431/1000, Training Loss: 0.0287\n",
      "Epoch 431/1000, Validation Loss: 0.0228\n",
      "Epoch 432/1000: 100%|███████████| 63/63 [00:01<00:00, 35.89batch/s, loss=0.0242]\n",
      "Epoch 432/1000, Training Loss: 0.0273\n",
      "Epoch 432/1000, Validation Loss: 0.0185\n",
      "Epoch 433/1000: 100%|███████████| 63/63 [00:01<00:00, 34.60batch/s, loss=0.0254]\n",
      "Epoch 433/1000, Training Loss: 0.0272\n",
      "Epoch 433/1000, Validation Loss: 0.0192\n",
      "Epoch 434/1000: 100%|███████████| 63/63 [00:01<00:00, 35.13batch/s, loss=0.0161]\n",
      "Epoch 434/1000, Training Loss: 0.0272\n",
      "Epoch 434/1000, Validation Loss: 0.0233\n",
      "Epoch 435/1000: 100%|███████████| 63/63 [00:01<00:00, 35.61batch/s, loss=0.0278]\n",
      "Epoch 435/1000, Training Loss: 0.0271\n",
      "Epoch 435/1000, Validation Loss: 0.0188\n",
      "Epoch 436/1000: 100%|███████████| 63/63 [00:01<00:00, 35.86batch/s, loss=0.0224]\n",
      "Epoch 436/1000, Training Loss: 0.0251\n",
      "Epoch 436/1000, Validation Loss: 0.0189\n",
      "Epoch 437/1000: 100%|███████████| 63/63 [00:01<00:00, 36.00batch/s, loss=0.0351]\n",
      "Epoch 437/1000, Training Loss: 0.0280\n",
      "Epoch 437/1000, Validation Loss: 0.0194\n",
      "Epoch 438/1000: 100%|███████████| 63/63 [00:01<00:00, 35.41batch/s, loss=0.0188]\n",
      "Epoch 438/1000, Training Loss: 0.0268\n",
      "Epoch 438/1000, Validation Loss: 0.0207\n",
      "Epoch 439/1000: 100%|███████████| 63/63 [00:01<00:00, 36.04batch/s, loss=0.0278]\n",
      "Epoch 439/1000, Training Loss: 0.0280\n",
      "Epoch 439/1000, Validation Loss: 0.0246\n",
      "Epoch 440/1000: 100%|███████████| 63/63 [00:01<00:00, 36.86batch/s, loss=0.0132]\n",
      "Epoch 440/1000, Training Loss: 0.0282\n",
      "Epoch 440/1000, Validation Loss: 0.0194\n",
      "Epoch 441/1000: 100%|███████████| 63/63 [00:01<00:00, 37.22batch/s, loss=0.0136]\n",
      "Epoch 441/1000, Training Loss: 0.0247\n",
      "Epoch 441/1000, Validation Loss: 0.0175\n",
      "Epoch 442/1000: 100%|███████████| 63/63 [00:01<00:00, 37.69batch/s, loss=0.0287]\n",
      "Epoch 442/1000, Training Loss: 0.0257\n",
      "Epoch 442/1000, Validation Loss: 0.0188\n",
      "Epoch 443/1000: 100%|███████████| 63/63 [00:01<00:00, 36.23batch/s, loss=0.0167]\n",
      "Epoch 443/1000, Training Loss: 0.0249\n",
      "Epoch 443/1000, Validation Loss: 0.0197\n",
      "Epoch 444/1000: 100%|███████████| 63/63 [00:01<00:00, 34.98batch/s, loss=0.0219]\n",
      "Epoch 444/1000, Training Loss: 0.0266\n",
      "Epoch 444/1000, Validation Loss: 0.0183\n",
      "Epoch 445/1000: 100%|███████████| 63/63 [00:01<00:00, 36.44batch/s, loss=0.0208]\n",
      "Epoch 445/1000, Training Loss: 0.0263\n",
      "Epoch 445/1000, Validation Loss: 0.0183\n",
      "Epoch 446/1000: 100%|███████████| 63/63 [00:01<00:00, 36.85batch/s, loss=0.0276]\n",
      "Epoch 446/1000, Training Loss: 0.0246\n",
      "Epoch 446/1000, Validation Loss: 0.0213\n",
      "Epoch 447/1000: 100%|███████████| 63/63 [00:01<00:00, 36.23batch/s, loss=0.0340]\n",
      "Epoch 447/1000, Training Loss: 0.0259\n",
      "Epoch 447/1000, Validation Loss: 0.0175\n",
      "Epoch 448/1000: 100%|███████████| 63/63 [00:01<00:00, 36.23batch/s, loss=0.0235]\n",
      "Epoch 448/1000, Training Loss: 0.0273\n",
      "Epoch 448/1000, Validation Loss: 0.0201\n",
      "Epoch 449/1000: 100%|███████████| 63/63 [00:01<00:00, 35.88batch/s, loss=0.0337]\n",
      "Epoch 449/1000, Training Loss: 0.0284\n",
      "Epoch 449/1000, Validation Loss: 0.0228\n",
      "Epoch 450/1000: 100%|███████████| 63/63 [00:01<00:00, 35.72batch/s, loss=0.0301]\n",
      "Epoch 450/1000, Training Loss: 0.0281\n",
      "Epoch 450/1000, Validation Loss: 0.0187\n",
      "Epoch 451/1000: 100%|███████████| 63/63 [00:01<00:00, 36.45batch/s, loss=0.0160]\n",
      "Epoch 451/1000, Training Loss: 0.0276\n",
      "Epoch 451/1000, Validation Loss: 0.0189\n",
      "Epoch 452/1000: 100%|███████████| 63/63 [00:01<00:00, 35.41batch/s, loss=0.0351]\n",
      "Epoch 452/1000, Training Loss: 0.0266\n",
      "Epoch 452/1000, Validation Loss: 0.0191\n",
      "Epoch 453/1000: 100%|███████████| 63/63 [00:01<00:00, 36.04batch/s, loss=0.0188]\n",
      "Epoch 453/1000, Training Loss: 0.0269\n",
      "Epoch 453/1000, Validation Loss: 0.0182\n",
      "Epoch 454/1000: 100%|███████████| 63/63 [00:01<00:00, 36.37batch/s, loss=0.0304]\n",
      "Epoch 454/1000, Training Loss: 0.0253\n",
      "Epoch 454/1000, Validation Loss: 0.0193\n",
      "Epoch 455/1000: 100%|███████████| 63/63 [00:01<00:00, 36.41batch/s, loss=0.0173]\n",
      "Epoch 455/1000, Training Loss: 0.0256\n",
      "Epoch 455/1000, Validation Loss: 0.0194\n",
      "Epoch 456/1000: 100%|███████████| 63/63 [00:01<00:00, 35.44batch/s, loss=0.0297]\n",
      "Epoch 456/1000, Training Loss: 0.0262\n",
      "Epoch 456/1000, Validation Loss: 0.0180\n",
      "Epoch 457/1000: 100%|███████████| 63/63 [00:01<00:00, 36.73batch/s, loss=0.0154]\n",
      "Epoch 457/1000, Training Loss: 0.0268\n",
      "Epoch 457/1000, Validation Loss: 0.0213\n",
      "Epoch 458/1000: 100%|███████████| 63/63 [00:01<00:00, 36.67batch/s, loss=0.0222]\n",
      "Epoch 458/1000, Training Loss: 0.0277\n",
      "Epoch 458/1000, Validation Loss: 0.0180\n",
      "Epoch 459/1000: 100%|███████████| 63/63 [00:01<00:00, 37.53batch/s, loss=0.0355]\n",
      "Epoch 459/1000, Training Loss: 0.0251\n",
      "Epoch 459/1000, Validation Loss: 0.0179\n",
      "Epoch 460/1000: 100%|███████████| 63/63 [00:01<00:00, 36.28batch/s, loss=0.0369]\n",
      "Epoch 460/1000, Training Loss: 0.0256\n",
      "Epoch 460/1000, Validation Loss: 0.0176\n",
      "Epoch 461/1000: 100%|███████████| 63/63 [00:01<00:00, 35.07batch/s, loss=0.0255]\n",
      "Epoch 461/1000, Training Loss: 0.0282\n",
      "Epoch 461/1000, Validation Loss: 0.0195\n",
      "Epoch 462/1000: 100%|███████████| 63/63 [00:01<00:00, 36.01batch/s, loss=0.0748]\n",
      "Epoch 462/1000, Training Loss: 0.0260\n",
      "Epoch 462/1000, Validation Loss: 0.0214\n",
      "Epoch 463/1000: 100%|███████████| 63/63 [00:01<00:00, 34.58batch/s, loss=0.0360]\n",
      "Epoch 463/1000, Training Loss: 0.0298\n",
      "Epoch 463/1000, Validation Loss: 0.0202\n",
      "Epoch 464/1000: 100%|███████████| 63/63 [00:01<00:00, 36.20batch/s, loss=0.0439]\n",
      "Epoch 464/1000, Training Loss: 0.0274\n",
      "Epoch 464/1000, Validation Loss: 0.0189\n",
      "Epoch 465/1000: 100%|███████████| 63/63 [00:01<00:00, 35.80batch/s, loss=0.0343]\n",
      "Epoch 465/1000, Training Loss: 0.0258\n",
      "Epoch 465/1000, Validation Loss: 0.0207\n",
      "Epoch 466/1000: 100%|███████████| 63/63 [00:01<00:00, 35.98batch/s, loss=0.0153]\n",
      "Epoch 466/1000, Training Loss: 0.0258\n",
      "Epoch 466/1000, Validation Loss: 0.0231\n",
      "Epoch 467/1000: 100%|███████████| 63/63 [00:01<00:00, 35.94batch/s, loss=0.0080]\n",
      "Epoch 467/1000, Training Loss: 0.0254\n",
      "Epoch 467/1000, Validation Loss: 0.0207\n",
      "Epoch 468/1000: 100%|███████████| 63/63 [00:01<00:00, 36.66batch/s, loss=0.0352]\n",
      "Epoch 468/1000, Training Loss: 0.0247\n",
      "Epoch 468/1000, Validation Loss: 0.0180\n",
      "Epoch 469/1000: 100%|███████████| 63/63 [00:01<00:00, 36.88batch/s, loss=0.0222]\n",
      "Epoch 469/1000, Training Loss: 0.0260\n",
      "Epoch 469/1000, Validation Loss: 0.0172\n",
      "Epoch 470/1000: 100%|███████████| 63/63 [00:01<00:00, 35.30batch/s, loss=0.0455]\n",
      "Epoch 470/1000, Training Loss: 0.0251\n",
      "Epoch 470/1000, Validation Loss: 0.0197\n",
      "Epoch 471/1000: 100%|███████████| 63/63 [00:01<00:00, 33.96batch/s, loss=0.0330]\n",
      "Epoch 471/1000, Training Loss: 0.0275\n",
      "Epoch 471/1000, Validation Loss: 0.0194\n",
      "Epoch 472/1000: 100%|███████████| 63/63 [00:01<00:00, 35.95batch/s, loss=0.0557]\n",
      "Epoch 472/1000, Training Loss: 0.0254\n",
      "Epoch 472/1000, Validation Loss: 0.0182\n",
      "Epoch 473/1000: 100%|███████████| 63/63 [00:01<00:00, 36.57batch/s, loss=0.0126]\n",
      "Epoch 473/1000, Training Loss: 0.0262\n",
      "Epoch 473/1000, Validation Loss: 0.0179\n",
      "Epoch 474/1000: 100%|███████████| 63/63 [00:01<00:00, 37.09batch/s, loss=0.0253]\n",
      "Epoch 474/1000, Training Loss: 0.0261\n",
      "Epoch 474/1000, Validation Loss: 0.0177\n",
      "Epoch 475/1000: 100%|███████████| 63/63 [00:01<00:00, 34.98batch/s, loss=0.0096]\n",
      "Epoch 475/1000, Training Loss: 0.0263\n",
      "Epoch 475/1000, Validation Loss: 0.0187\n",
      "Epoch 476/1000: 100%|███████████| 63/63 [00:01<00:00, 36.02batch/s, loss=0.0296]\n",
      "Epoch 476/1000, Training Loss: 0.0237\n",
      "Epoch 476/1000, Validation Loss: 0.0176\n",
      "Epoch 477/1000: 100%|███████████| 63/63 [00:01<00:00, 36.21batch/s, loss=0.0119]\n",
      "Epoch 477/1000, Training Loss: 0.0269\n",
      "Epoch 477/1000, Validation Loss: 0.0206\n",
      "Epoch 478/1000: 100%|███████████| 63/63 [00:01<00:00, 35.13batch/s, loss=0.0395]\n",
      "Epoch 478/1000, Training Loss: 0.0285\n",
      "Epoch 478/1000, Validation Loss: 0.0168\n",
      "Epoch 479/1000: 100%|███████████| 63/63 [00:01<00:00, 36.38batch/s, loss=0.0197]\n",
      "Epoch 479/1000, Training Loss: 0.0244\n",
      "Epoch 479/1000, Validation Loss: 0.0186\n",
      "Epoch 480/1000: 100%|███████████| 63/63 [00:01<00:00, 36.21batch/s, loss=0.0323]\n",
      "Epoch 480/1000, Training Loss: 0.0244\n",
      "Epoch 480/1000, Validation Loss: 0.0169\n",
      "Epoch 481/1000: 100%|███████████| 63/63 [00:01<00:00, 36.27batch/s, loss=0.0294]\n",
      "Epoch 481/1000, Training Loss: 0.0240\n",
      "Epoch 481/1000, Validation Loss: 0.0190\n",
      "Epoch 482/1000: 100%|███████████| 63/63 [00:01<00:00, 35.46batch/s, loss=0.0293]\n",
      "Epoch 482/1000, Training Loss: 0.0262\n",
      "Epoch 482/1000, Validation Loss: 0.0175\n",
      "Epoch 483/1000: 100%|███████████| 63/63 [00:01<00:00, 35.91batch/s, loss=0.0566]\n",
      "Epoch 483/1000, Training Loss: 0.0284\n",
      "Epoch 483/1000, Validation Loss: 0.0169\n",
      "Epoch 484/1000: 100%|███████████| 63/63 [00:01<00:00, 36.14batch/s, loss=0.0546]\n",
      "Epoch 484/1000, Training Loss: 0.0250\n",
      "Epoch 484/1000, Validation Loss: 0.0169\n",
      "Epoch 485/1000: 100%|███████████| 63/63 [00:01<00:00, 36.13batch/s, loss=0.0459]\n",
      "Epoch 485/1000, Training Loss: 0.0266\n",
      "Epoch 485/1000, Validation Loss: 0.0192\n",
      "Epoch 486/1000: 100%|███████████| 63/63 [00:01<00:00, 34.47batch/s, loss=0.0075]\n",
      "Epoch 486/1000, Training Loss: 0.0263\n",
      "Epoch 486/1000, Validation Loss: 0.0241\n",
      "Epoch 487/1000: 100%|███████████| 63/63 [00:01<00:00, 35.71batch/s, loss=0.0230]\n",
      "Epoch 487/1000, Training Loss: 0.0256\n",
      "Epoch 487/1000, Validation Loss: 0.0174\n",
      "Epoch 488/1000: 100%|███████████| 63/63 [00:01<00:00, 35.50batch/s, loss=0.0082]\n",
      "Epoch 488/1000, Training Loss: 0.0244\n",
      "Epoch 488/1000, Validation Loss: 0.0172\n",
      "Epoch 489/1000: 100%|███████████| 63/63 [00:01<00:00, 35.55batch/s, loss=0.0324]\n",
      "Epoch 489/1000, Training Loss: 0.0234\n",
      "Epoch 489/1000, Validation Loss: 0.0173\n",
      "Epoch 490/1000: 100%|███████████| 63/63 [00:01<00:00, 35.47batch/s, loss=0.0212]\n",
      "Epoch 490/1000, Training Loss: 0.0235\n",
      "Epoch 490/1000, Validation Loss: 0.0169\n",
      "Epoch 491/1000: 100%|███████████| 63/63 [00:01<00:00, 36.13batch/s, loss=0.0332]\n",
      "Epoch 491/1000, Training Loss: 0.0257\n",
      "Epoch 491/1000, Validation Loss: 0.0182\n",
      "Epoch 492/1000: 100%|███████████| 63/63 [00:01<00:00, 37.68batch/s, loss=0.0450]\n",
      "Epoch 492/1000, Training Loss: 0.0247\n",
      "Epoch 492/1000, Validation Loss: 0.0183\n",
      "Epoch 493/1000: 100%|███████████| 63/63 [00:01<00:00, 38.17batch/s, loss=0.0144]\n",
      "Epoch 493/1000, Training Loss: 0.0265\n",
      "Epoch 493/1000, Validation Loss: 0.0208\n",
      "Epoch 494/1000: 100%|███████████| 63/63 [00:01<00:00, 36.45batch/s, loss=0.0206]\n",
      "Epoch 494/1000, Training Loss: 0.0280\n",
      "Epoch 494/1000, Validation Loss: 0.0211\n",
      "Epoch 495/1000: 100%|███████████| 63/63 [00:01<00:00, 36.80batch/s, loss=0.0187]\n",
      "Epoch 495/1000, Training Loss: 0.0266\n",
      "Epoch 495/1000, Validation Loss: 0.0199\n",
      "Epoch 496/1000: 100%|███████████| 63/63 [00:01<00:00, 37.44batch/s, loss=0.0123]\n",
      "Epoch 496/1000, Training Loss: 0.0270\n",
      "Epoch 496/1000, Validation Loss: 0.0193\n",
      "Epoch 497/1000: 100%|███████████| 63/63 [00:01<00:00, 36.93batch/s, loss=0.0263]\n",
      "Epoch 497/1000, Training Loss: 0.0250\n",
      "Epoch 497/1000, Validation Loss: 0.0181\n",
      "Epoch 498/1000: 100%|███████████| 63/63 [00:01<00:00, 37.85batch/s, loss=0.0378]\n",
      "Epoch 498/1000, Training Loss: 0.0245\n",
      "Epoch 498/1000, Validation Loss: 0.0191\n",
      "Epoch 499/1000: 100%|███████████| 63/63 [00:01<00:00, 36.86batch/s, loss=0.0268]\n",
      "Epoch 499/1000, Training Loss: 0.0242\n",
      "Epoch 499/1000, Validation Loss: 0.0188\n",
      "Epoch 500/1000: 100%|███████████| 63/63 [00:01<00:00, 37.25batch/s, loss=0.0300]\n",
      "Epoch 500/1000, Training Loss: 0.0251\n",
      "Epoch 500/1000, Validation Loss: 0.0181\n",
      "Epoch 501/1000: 100%|███████████| 63/63 [00:01<00:00, 37.23batch/s, loss=0.0183]\n",
      "Epoch 501/1000, Training Loss: 0.0237\n",
      "Epoch 501/1000, Validation Loss: 0.0181\n",
      "Epoch 502/1000: 100%|███████████| 63/63 [00:01<00:00, 36.83batch/s, loss=0.0274]\n",
      "Epoch 502/1000, Training Loss: 0.0234\n",
      "Epoch 502/1000, Validation Loss: 0.0167\n",
      "Epoch 503/1000: 100%|███████████| 63/63 [00:01<00:00, 35.28batch/s, loss=0.0676]\n",
      "Epoch 503/1000, Training Loss: 0.0245\n",
      "Epoch 503/1000, Validation Loss: 0.0165\n",
      "Epoch 504/1000: 100%|███████████| 63/63 [00:01<00:00, 34.26batch/s, loss=0.0210]\n",
      "Epoch 504/1000, Training Loss: 0.0234\n",
      "Epoch 504/1000, Validation Loss: 0.0194\n",
      "Epoch 505/1000: 100%|███████████| 63/63 [00:01<00:00, 37.06batch/s, loss=0.0314]\n",
      "Epoch 505/1000, Training Loss: 0.0251\n",
      "Epoch 505/1000, Validation Loss: 0.0198\n",
      "Epoch 506/1000: 100%|███████████| 63/63 [00:01<00:00, 37.50batch/s, loss=0.0041]\n",
      "Epoch 506/1000, Training Loss: 0.0260\n",
      "Epoch 506/1000, Validation Loss: 0.0177\n",
      "Epoch 507/1000: 100%|███████████| 63/63 [00:01<00:00, 38.09batch/s, loss=0.0538]\n",
      "Epoch 507/1000, Training Loss: 0.0246\n",
      "Epoch 507/1000, Validation Loss: 0.0165\n",
      "Epoch 508/1000: 100%|███████████| 63/63 [00:01<00:00, 37.57batch/s, loss=0.0346]\n",
      "Epoch 508/1000, Training Loss: 0.0260\n",
      "Epoch 508/1000, Validation Loss: 0.0188\n",
      "Epoch 509/1000: 100%|███████████| 63/63 [00:01<00:00, 36.27batch/s, loss=0.0356]\n",
      "Epoch 509/1000, Training Loss: 0.0243\n",
      "Epoch 509/1000, Validation Loss: 0.0170\n",
      "Epoch 510/1000: 100%|███████████| 63/63 [00:01<00:00, 35.31batch/s, loss=0.0084]\n",
      "Epoch 510/1000, Training Loss: 0.0246\n",
      "Epoch 510/1000, Validation Loss: 0.0178\n",
      "Epoch 511/1000: 100%|███████████| 63/63 [00:01<00:00, 38.86batch/s, loss=0.0233]\n",
      "Epoch 511/1000, Training Loss: 0.0313\n",
      "Epoch 511/1000, Validation Loss: 0.0219\n",
      "Epoch 512/1000: 100%|███████████| 63/63 [00:01<00:00, 38.32batch/s, loss=0.0165]\n",
      "Epoch 512/1000, Training Loss: 0.0261\n",
      "Epoch 512/1000, Validation Loss: 0.0188\n",
      "Epoch 513/1000: 100%|███████████| 63/63 [00:01<00:00, 37.92batch/s, loss=0.0186]\n",
      "Epoch 513/1000, Training Loss: 0.0241\n",
      "Epoch 513/1000, Validation Loss: 0.0175\n",
      "Epoch 514/1000: 100%|███████████| 63/63 [00:01<00:00, 37.52batch/s, loss=0.0239]\n",
      "Epoch 514/1000, Training Loss: 0.0249\n",
      "Epoch 514/1000, Validation Loss: 0.0184\n",
      "Epoch 515/1000: 100%|███████████| 63/63 [00:01<00:00, 38.29batch/s, loss=0.0285]\n",
      "Epoch 515/1000, Training Loss: 0.0224\n",
      "Epoch 515/1000, Validation Loss: 0.0174\n",
      "Epoch 516/1000: 100%|███████████| 63/63 [00:01<00:00, 38.38batch/s, loss=0.0375]\n",
      "Epoch 516/1000, Training Loss: 0.0240\n",
      "Epoch 516/1000, Validation Loss: 0.0186\n",
      "Epoch 517/1000: 100%|███████████| 63/63 [00:01<00:00, 37.17batch/s, loss=0.0130]\n",
      "Epoch 517/1000, Training Loss: 0.0258\n",
      "Epoch 517/1000, Validation Loss: 0.0184\n",
      "Epoch 518/1000: 100%|███████████| 63/63 [00:01<00:00, 37.97batch/s, loss=0.0312]\n",
      "Epoch 518/1000, Training Loss: 0.0254\n",
      "Epoch 518/1000, Validation Loss: 0.0178\n",
      "Epoch 519/1000: 100%|███████████| 63/63 [00:01<00:00, 37.94batch/s, loss=0.0340]\n",
      "Epoch 519/1000, Training Loss: 0.0231\n",
      "Epoch 519/1000, Validation Loss: 0.0167\n",
      "Epoch 520/1000: 100%|███████████| 63/63 [00:01<00:00, 36.85batch/s, loss=0.0160]\n",
      "Epoch 520/1000, Training Loss: 0.0255\n",
      "Epoch 520/1000, Validation Loss: 0.0213\n",
      "Epoch 521/1000: 100%|███████████| 63/63 [00:01<00:00, 36.61batch/s, loss=0.0458]\n",
      "Epoch 521/1000, Training Loss: 0.0267\n",
      "Epoch 521/1000, Validation Loss: 0.0182\n",
      "Epoch 522/1000: 100%|███████████| 63/63 [00:01<00:00, 38.05batch/s, loss=0.0170]\n",
      "Epoch 522/1000, Training Loss: 0.0268\n",
      "Epoch 522/1000, Validation Loss: 0.0191\n",
      "Epoch 523/1000: 100%|███████████| 63/63 [00:01<00:00, 37.21batch/s, loss=0.0314]\n",
      "Epoch 523/1000, Training Loss: 0.0261\n",
      "Epoch 523/1000, Validation Loss: 0.0206\n",
      "Epoch 524/1000: 100%|███████████| 63/63 [00:01<00:00, 38.47batch/s, loss=0.0089]\n",
      "Epoch 524/1000, Training Loss: 0.0253\n",
      "Epoch 524/1000, Validation Loss: 0.0188\n",
      "Epoch 525/1000: 100%|███████████| 63/63 [00:01<00:00, 37.15batch/s, loss=0.0269]\n",
      "Epoch 525/1000, Training Loss: 0.0248\n",
      "Epoch 525/1000, Validation Loss: 0.0216\n",
      "Epoch 526/1000: 100%|███████████| 63/63 [00:01<00:00, 37.96batch/s, loss=0.0229]\n",
      "Epoch 526/1000, Training Loss: 0.0247\n",
      "Epoch 526/1000, Validation Loss: 0.0180\n",
      "Epoch 527/1000: 100%|███████████| 63/63 [00:01<00:00, 38.78batch/s, loss=0.0156]\n",
      "Epoch 527/1000, Training Loss: 0.0237\n",
      "Epoch 527/1000, Validation Loss: 0.0202\n",
      "Epoch 528/1000: 100%|███████████| 63/63 [00:01<00:00, 37.97batch/s, loss=0.0380]\n",
      "Epoch 528/1000, Training Loss: 0.0256\n",
      "Epoch 528/1000, Validation Loss: 0.0166\n",
      "Epoch 529/1000: 100%|███████████| 63/63 [00:01<00:00, 37.75batch/s, loss=0.0065]\n",
      "Epoch 529/1000, Training Loss: 0.0268\n",
      "Epoch 529/1000, Validation Loss: 0.0172\n",
      "Epoch 530/1000: 100%|███████████| 63/63 [00:01<00:00, 38.63batch/s, loss=0.0258]\n",
      "Epoch 530/1000, Training Loss: 0.0248\n",
      "Epoch 530/1000, Validation Loss: 0.0180\n",
      "Epoch 531/1000: 100%|███████████| 63/63 [00:01<00:00, 38.84batch/s, loss=0.0205]\n",
      "Epoch 531/1000, Training Loss: 0.0238\n",
      "Epoch 531/1000, Validation Loss: 0.0183\n",
      "Epoch 532/1000: 100%|███████████| 63/63 [00:01<00:00, 40.97batch/s, loss=0.0109]\n",
      "Epoch 532/1000, Training Loss: 0.0223\n",
      "Epoch 532/1000, Validation Loss: 0.0150\n",
      "Epoch 533/1000: 100%|███████████| 63/63 [00:01<00:00, 37.71batch/s, loss=0.0215]\n",
      "Epoch 533/1000, Training Loss: 0.0229\n",
      "Epoch 533/1000, Validation Loss: 0.0193\n",
      "Epoch 534/1000: 100%|███████████| 63/63 [00:01<00:00, 39.16batch/s, loss=0.0190]\n",
      "Epoch 534/1000, Training Loss: 0.0237\n",
      "Epoch 534/1000, Validation Loss: 0.0179\n",
      "Epoch 535/1000: 100%|███████████| 63/63 [00:01<00:00, 38.53batch/s, loss=0.0424]\n",
      "Epoch 535/1000, Training Loss: 0.0233\n",
      "Epoch 535/1000, Validation Loss: 0.0169\n",
      "Epoch 536/1000: 100%|███████████| 63/63 [00:01<00:00, 38.84batch/s, loss=0.0064]\n",
      "Epoch 536/1000, Training Loss: 0.0244\n",
      "Epoch 536/1000, Validation Loss: 0.0166\n",
      "Epoch 537/1000: 100%|███████████| 63/63 [00:01<00:00, 38.56batch/s, loss=0.0227]\n",
      "Epoch 537/1000, Training Loss: 0.0253\n",
      "Epoch 537/1000, Validation Loss: 0.0183\n",
      "Epoch 538/1000: 100%|███████████| 63/63 [00:01<00:00, 39.08batch/s, loss=0.0259]\n",
      "Epoch 538/1000, Training Loss: 0.0256\n",
      "Epoch 538/1000, Validation Loss: 0.0163\n",
      "Epoch 539/1000: 100%|███████████| 63/63 [00:01<00:00, 39.71batch/s, loss=0.0190]\n",
      "Epoch 539/1000, Training Loss: 0.0239\n",
      "Epoch 539/1000, Validation Loss: 0.0179\n",
      "Epoch 540/1000: 100%|███████████| 63/63 [00:01<00:00, 39.29batch/s, loss=0.0943]\n",
      "Epoch 540/1000, Training Loss: 0.0241\n",
      "Epoch 540/1000, Validation Loss: 0.0177\n",
      "Epoch 541/1000: 100%|███████████| 63/63 [00:01<00:00, 37.28batch/s, loss=0.0145]\n",
      "Epoch 541/1000, Training Loss: 0.0232\n",
      "Epoch 541/1000, Validation Loss: 0.0168\n",
      "Epoch 542/1000: 100%|███████████| 63/63 [00:01<00:00, 40.48batch/s, loss=0.0085]\n",
      "Epoch 542/1000, Training Loss: 0.0216\n",
      "Epoch 542/1000, Validation Loss: 0.0177\n",
      "Epoch 543/1000: 100%|███████████| 63/63 [00:01<00:00, 38.92batch/s, loss=0.0179]\n",
      "Epoch 543/1000, Training Loss: 0.0238\n",
      "Epoch 543/1000, Validation Loss: 0.0183\n",
      "Epoch 544/1000: 100%|███████████| 63/63 [00:01<00:00, 38.10batch/s, loss=0.0427]\n",
      "Epoch 544/1000, Training Loss: 0.0239\n",
      "Epoch 544/1000, Validation Loss: 0.0161\n",
      "Epoch 545/1000: 100%|███████████| 63/63 [00:01<00:00, 38.96batch/s, loss=0.0165]\n",
      "Epoch 545/1000, Training Loss: 0.0236\n",
      "Epoch 545/1000, Validation Loss: 0.0164\n",
      "Epoch 546/1000: 100%|███████████| 63/63 [00:01<00:00, 39.04batch/s, loss=0.0187]\n",
      "Epoch 546/1000, Training Loss: 0.0227\n",
      "Epoch 546/1000, Validation Loss: 0.0210\n",
      "Epoch 547/1000: 100%|███████████| 63/63 [00:01<00:00, 38.84batch/s, loss=0.0133]\n",
      "Epoch 547/1000, Training Loss: 0.0241\n",
      "Epoch 547/1000, Validation Loss: 0.0187\n",
      "Epoch 548/1000: 100%|███████████| 63/63 [00:01<00:00, 39.21batch/s, loss=0.0033]\n",
      "Epoch 548/1000, Training Loss: 0.0250\n",
      "Epoch 548/1000, Validation Loss: 0.0193\n",
      "Epoch 549/1000: 100%|███████████| 63/63 [00:01<00:00, 38.94batch/s, loss=0.0120]\n",
      "Epoch 549/1000, Training Loss: 0.0250\n",
      "Epoch 549/1000, Validation Loss: 0.0230\n",
      "Epoch 550/1000: 100%|███████████| 63/63 [00:01<00:00, 38.01batch/s, loss=0.0301]\n",
      "Epoch 550/1000, Training Loss: 0.0248\n",
      "Epoch 550/1000, Validation Loss: 0.0163\n",
      "Epoch 551/1000: 100%|███████████| 63/63 [00:01<00:00, 39.48batch/s, loss=0.0354]\n",
      "Epoch 551/1000, Training Loss: 0.0231\n",
      "Epoch 551/1000, Validation Loss: 0.0160\n",
      "Epoch 552/1000: 100%|███████████| 63/63 [00:01<00:00, 38.73batch/s, loss=0.0288]\n",
      "Epoch 552/1000, Training Loss: 0.0265\n",
      "Epoch 552/1000, Validation Loss: 0.0206\n",
      "Epoch 553/1000: 100%|███████████| 63/63 [00:01<00:00, 38.11batch/s, loss=0.0423]\n",
      "Epoch 553/1000, Training Loss: 0.0272\n",
      "Epoch 553/1000, Validation Loss: 0.0168\n",
      "Epoch 554/1000: 100%|███████████| 63/63 [00:01<00:00, 38.58batch/s, loss=0.0131]\n",
      "Epoch 554/1000, Training Loss: 0.0258\n",
      "Epoch 554/1000, Validation Loss: 0.0186\n",
      "Epoch 555/1000: 100%|███████████| 63/63 [00:01<00:00, 34.69batch/s, loss=0.0155]\n",
      "Epoch 555/1000, Training Loss: 0.0241\n",
      "Epoch 555/1000, Validation Loss: 0.0204\n",
      "Epoch 556/1000: 100%|███████████| 63/63 [00:01<00:00, 37.39batch/s, loss=0.0232]\n",
      "Epoch 556/1000, Training Loss: 0.0249\n",
      "Epoch 556/1000, Validation Loss: 0.0183\n",
      "Epoch 557/1000: 100%|███████████| 63/63 [00:01<00:00, 35.18batch/s, loss=0.0369]\n",
      "Epoch 557/1000, Training Loss: 0.0236\n",
      "Epoch 557/1000, Validation Loss: 0.0161\n",
      "Epoch 558/1000: 100%|███████████| 63/63 [00:01<00:00, 37.19batch/s, loss=0.0290]\n",
      "Epoch 558/1000, Training Loss: 0.0242\n",
      "Epoch 558/1000, Validation Loss: 0.0160\n",
      "Epoch 559/1000: 100%|███████████| 63/63 [00:01<00:00, 36.96batch/s, loss=0.0162]\n",
      "Epoch 559/1000, Training Loss: 0.0234\n",
      "Epoch 559/1000, Validation Loss: 0.0180\n",
      "Epoch 560/1000: 100%|███████████| 63/63 [00:01<00:00, 36.51batch/s, loss=0.0386]\n",
      "Epoch 560/1000, Training Loss: 0.0240\n",
      "Epoch 560/1000, Validation Loss: 0.0231\n",
      "Epoch 561/1000: 100%|███████████| 63/63 [00:01<00:00, 37.67batch/s, loss=0.0469]\n",
      "Epoch 561/1000, Training Loss: 0.0268\n",
      "Epoch 561/1000, Validation Loss: 0.0186\n",
      "Epoch 562/1000: 100%|███████████| 63/63 [00:01<00:00, 35.90batch/s, loss=0.0155]\n",
      "Epoch 562/1000, Training Loss: 0.0250\n",
      "Epoch 562/1000, Validation Loss: 0.0212\n",
      "Epoch 563/1000: 100%|███████████| 63/63 [00:01<00:00, 37.00batch/s, loss=0.0182]\n",
      "Epoch 563/1000, Training Loss: 0.0287\n",
      "Epoch 563/1000, Validation Loss: 0.0192\n",
      "Epoch 564/1000: 100%|███████████| 63/63 [00:01<00:00, 36.61batch/s, loss=0.0212]\n",
      "Epoch 564/1000, Training Loss: 0.0244\n",
      "Epoch 564/1000, Validation Loss: 0.0186\n",
      "Epoch 565/1000: 100%|███████████| 63/63 [00:01<00:00, 35.07batch/s, loss=0.0174]\n",
      "Epoch 565/1000, Training Loss: 0.0239\n",
      "Epoch 565/1000, Validation Loss: 0.0184\n",
      "Epoch 566/1000: 100%|███████████| 63/63 [00:01<00:00, 37.68batch/s, loss=0.0194]\n",
      "Epoch 566/1000, Training Loss: 0.0253\n",
      "Epoch 566/1000, Validation Loss: 0.0181\n",
      "Epoch 567/1000: 100%|███████████| 63/63 [00:01<00:00, 36.44batch/s, loss=0.0172]\n",
      "Epoch 567/1000, Training Loss: 0.0246\n",
      "Epoch 567/1000, Validation Loss: 0.0166\n",
      "Epoch 568/1000: 100%|███████████| 63/63 [00:01<00:00, 36.05batch/s, loss=0.0175]\n",
      "Epoch 568/1000, Training Loss: 0.0229\n",
      "Epoch 568/1000, Validation Loss: 0.0155\n",
      "Epoch 569/1000: 100%|███████████| 63/63 [00:01<00:00, 38.19batch/s, loss=0.0198]\n",
      "Epoch 569/1000, Training Loss: 0.0252\n",
      "Epoch 569/1000, Validation Loss: 0.0179\n",
      "Epoch 570/1000: 100%|███████████| 63/63 [00:01<00:00, 39.50batch/s, loss=0.0182]\n",
      "Epoch 570/1000, Training Loss: 0.0226\n",
      "Epoch 570/1000, Validation Loss: 0.0151\n",
      "Epoch 571/1000: 100%|███████████| 63/63 [00:01<00:00, 37.18batch/s, loss=0.0558]\n",
      "Epoch 571/1000, Training Loss: 0.0225\n",
      "Epoch 571/1000, Validation Loss: 0.0165\n",
      "Epoch 572/1000: 100%|███████████| 63/63 [00:01<00:00, 37.61batch/s, loss=0.0222]\n",
      "Epoch 572/1000, Training Loss: 0.0230\n",
      "Epoch 572/1000, Validation Loss: 0.0185\n",
      "Epoch 573/1000: 100%|███████████| 63/63 [00:01<00:00, 38.00batch/s, loss=0.0174]\n",
      "Epoch 573/1000, Training Loss: 0.0252\n",
      "Epoch 573/1000, Validation Loss: 0.0167\n",
      "Epoch 574/1000: 100%|███████████| 63/63 [00:01<00:00, 40.14batch/s, loss=0.0210]\n",
      "Epoch 574/1000, Training Loss: 0.0223\n",
      "Epoch 574/1000, Validation Loss: 0.0162\n",
      "Epoch 575/1000: 100%|███████████| 63/63 [00:01<00:00, 40.65batch/s, loss=0.0129]\n",
      "Epoch 575/1000, Training Loss: 0.0243\n",
      "Epoch 575/1000, Validation Loss: 0.0186\n",
      "Epoch 576/1000: 100%|███████████| 63/63 [00:01<00:00, 40.83batch/s, loss=0.0140]\n",
      "Epoch 576/1000, Training Loss: 0.0239\n",
      "Epoch 576/1000, Validation Loss: 0.0157\n",
      "Epoch 577/1000: 100%|███████████| 63/63 [00:01<00:00, 38.92batch/s, loss=0.0217]\n",
      "Epoch 577/1000, Training Loss: 0.0250\n",
      "Epoch 577/1000, Validation Loss: 0.0183\n",
      "Epoch 578/1000: 100%|███████████| 63/63 [00:01<00:00, 40.02batch/s, loss=0.0199]\n",
      "Epoch 578/1000, Training Loss: 0.0250\n",
      "Epoch 578/1000, Validation Loss: 0.0194\n",
      "Epoch 579/1000: 100%|███████████| 63/63 [00:01<00:00, 41.57batch/s, loss=0.0116]\n",
      "Epoch 579/1000, Training Loss: 0.0261\n",
      "Epoch 579/1000, Validation Loss: 0.0180\n",
      "Epoch 580/1000: 100%|███████████| 63/63 [00:01<00:00, 39.35batch/s, loss=0.0182]\n",
      "Epoch 580/1000, Training Loss: 0.0233\n",
      "Epoch 580/1000, Validation Loss: 0.0167\n",
      "Epoch 581/1000: 100%|███████████| 63/63 [00:01<00:00, 41.81batch/s, loss=0.0149]\n",
      "Epoch 581/1000, Training Loss: 0.0226\n",
      "Epoch 581/1000, Validation Loss: 0.0168\n",
      "Epoch 582/1000: 100%|███████████| 63/63 [00:01<00:00, 41.18batch/s, loss=0.0199]\n",
      "Epoch 582/1000, Training Loss: 0.0227\n",
      "Epoch 582/1000, Validation Loss: 0.0154\n",
      "Epoch 583/1000: 100%|███████████| 63/63 [00:01<00:00, 42.20batch/s, loss=0.0240]\n",
      "Epoch 583/1000, Training Loss: 0.0220\n",
      "Epoch 583/1000, Validation Loss: 0.0152\n",
      "Epoch 584/1000: 100%|███████████| 63/63 [00:01<00:00, 41.53batch/s, loss=0.0177]\n",
      "Epoch 584/1000, Training Loss: 0.0240\n",
      "Epoch 584/1000, Validation Loss: 0.0172\n",
      "Epoch 585/1000: 100%|███████████| 63/63 [00:01<00:00, 39.88batch/s, loss=0.0212]\n",
      "Epoch 585/1000, Training Loss: 0.0228\n",
      "Epoch 585/1000, Validation Loss: 0.0179\n",
      "Epoch 586/1000: 100%|███████████| 63/63 [00:01<00:00, 41.00batch/s, loss=0.0347]\n",
      "Epoch 586/1000, Training Loss: 0.0236\n",
      "Epoch 586/1000, Validation Loss: 0.0162\n",
      "Epoch 587/1000: 100%|███████████| 63/63 [00:01<00:00, 41.17batch/s, loss=0.0189]\n",
      "Epoch 587/1000, Training Loss: 0.0253\n",
      "Epoch 587/1000, Validation Loss: 0.0155\n",
      "Epoch 588/1000: 100%|███████████| 63/63 [00:01<00:00, 40.90batch/s, loss=0.0335]\n",
      "Epoch 588/1000, Training Loss: 0.0255\n",
      "Epoch 588/1000, Validation Loss: 0.0145\n",
      "Epoch 589/1000: 100%|███████████| 63/63 [00:01<00:00, 40.42batch/s, loss=0.0321]\n",
      "Epoch 589/1000, Training Loss: 0.0231\n",
      "Epoch 589/1000, Validation Loss: 0.0171\n",
      "Epoch 590/1000: 100%|███████████| 63/63 [00:01<00:00, 39.09batch/s, loss=0.0335]\n",
      "Epoch 590/1000, Training Loss: 0.0229\n",
      "Epoch 590/1000, Validation Loss: 0.0150\n",
      "Epoch 591/1000: 100%|███████████| 63/63 [00:01<00:00, 42.00batch/s, loss=0.0444]\n",
      "Epoch 591/1000, Training Loss: 0.0242\n",
      "Epoch 591/1000, Validation Loss: 0.0163\n",
      "Epoch 592/1000: 100%|███████████| 63/63 [00:01<00:00, 38.40batch/s, loss=0.0095]\n",
      "Epoch 592/1000, Training Loss: 0.0224\n",
      "Epoch 592/1000, Validation Loss: 0.0154\n",
      "Epoch 593/1000: 100%|███████████| 63/63 [00:01<00:00, 39.72batch/s, loss=0.0125]\n",
      "Epoch 593/1000, Training Loss: 0.0219\n",
      "Epoch 593/1000, Validation Loss: 0.0173\n",
      "Epoch 594/1000: 100%|███████████| 63/63 [00:01<00:00, 38.76batch/s, loss=0.0051]\n",
      "Epoch 594/1000, Training Loss: 0.0228\n",
      "Epoch 594/1000, Validation Loss: 0.0179\n",
      "Epoch 595/1000: 100%|███████████| 63/63 [00:01<00:00, 38.79batch/s, loss=0.0168]\n",
      "Epoch 595/1000, Training Loss: 0.0226\n",
      "Epoch 595/1000, Validation Loss: 0.0150\n",
      "Epoch 596/1000: 100%|███████████| 63/63 [00:01<00:00, 39.43batch/s, loss=0.0145]\n",
      "Epoch 596/1000, Training Loss: 0.0219\n",
      "Epoch 596/1000, Validation Loss: 0.0174\n",
      "Epoch 597/1000: 100%|███████████| 63/63 [00:01<00:00, 34.71batch/s, loss=0.0226]\n",
      "Epoch 597/1000, Training Loss: 0.0237\n",
      "Epoch 597/1000, Validation Loss: 0.0178\n",
      "Epoch 598/1000: 100%|███████████| 63/63 [00:01<00:00, 39.30batch/s, loss=0.0395]\n",
      "Epoch 598/1000, Training Loss: 0.0252\n",
      "Epoch 598/1000, Validation Loss: 0.0178\n",
      "Epoch 599/1000: 100%|███████████| 63/63 [00:01<00:00, 38.27batch/s, loss=0.0210]\n",
      "Epoch 599/1000, Training Loss: 0.0231\n",
      "Epoch 599/1000, Validation Loss: 0.0160\n",
      "Epoch 600/1000: 100%|███████████| 63/63 [00:01<00:00, 40.25batch/s, loss=0.0203]\n",
      "Epoch 600/1000, Training Loss: 0.0243\n",
      "Epoch 600/1000, Validation Loss: 0.0178\n",
      "Epoch 601/1000: 100%|███████████| 63/63 [00:01<00:00, 37.72batch/s, loss=0.0335]\n",
      "Epoch 601/1000, Training Loss: 0.0225\n",
      "Epoch 601/1000, Validation Loss: 0.0170\n",
      "Epoch 602/1000: 100%|███████████| 63/63 [00:01<00:00, 39.90batch/s, loss=0.0369]\n",
      "Epoch 602/1000, Training Loss: 0.0218\n",
      "Epoch 602/1000, Validation Loss: 0.0160\n",
      "Epoch 603/1000: 100%|███████████| 63/63 [00:01<00:00, 39.19batch/s, loss=0.0181]\n",
      "Epoch 603/1000, Training Loss: 0.0221\n",
      "Epoch 603/1000, Validation Loss: 0.0146\n",
      "Epoch 604/1000: 100%|███████████| 63/63 [00:01<00:00, 39.95batch/s, loss=0.0379]\n",
      "Epoch 604/1000, Training Loss: 0.0218\n",
      "Epoch 604/1000, Validation Loss: 0.0189\n",
      "Epoch 605/1000: 100%|███████████| 63/63 [00:01<00:00, 40.33batch/s, loss=0.0132]\n",
      "Epoch 605/1000, Training Loss: 0.0243\n",
      "Epoch 605/1000, Validation Loss: 0.0218\n",
      "Epoch 606/1000: 100%|███████████| 63/63 [00:01<00:00, 39.21batch/s, loss=0.0470]\n",
      "Epoch 606/1000, Training Loss: 0.0248\n",
      "Epoch 606/1000, Validation Loss: 0.0171\n",
      "Epoch 607/1000: 100%|███████████| 63/63 [00:01<00:00, 38.96batch/s, loss=0.0526]\n",
      "Epoch 607/1000, Training Loss: 0.0239\n",
      "Epoch 607/1000, Validation Loss: 0.0164\n",
      "Epoch 608/1000: 100%|███████████| 63/63 [00:01<00:00, 39.22batch/s, loss=0.0289]\n",
      "Epoch 608/1000, Training Loss: 0.0249\n",
      "Epoch 608/1000, Validation Loss: 0.0172\n",
      "Epoch 609/1000: 100%|███████████| 63/63 [00:01<00:00, 40.15batch/s, loss=0.0194]\n",
      "Epoch 609/1000, Training Loss: 0.0226\n",
      "Epoch 609/1000, Validation Loss: 0.0169\n",
      "Epoch 610/1000: 100%|███████████| 63/63 [00:01<00:00, 40.36batch/s, loss=0.0193]\n",
      "Epoch 610/1000, Training Loss: 0.0205\n",
      "Epoch 610/1000, Validation Loss: 0.0161\n",
      "Epoch 611/1000: 100%|███████████| 63/63 [00:01<00:00, 40.36batch/s, loss=0.0117]\n",
      "Epoch 611/1000, Training Loss: 0.0217\n",
      "Epoch 611/1000, Validation Loss: 0.0166\n",
      "Epoch 612/1000: 100%|███████████| 63/63 [00:01<00:00, 40.56batch/s, loss=0.0248]\n",
      "Epoch 612/1000, Training Loss: 0.0238\n",
      "Epoch 612/1000, Validation Loss: 0.0334\n",
      "Epoch 613/1000: 100%|███████████| 63/63 [00:01<00:00, 39.74batch/s, loss=0.0169]\n",
      "Epoch 613/1000, Training Loss: 0.0263\n",
      "Epoch 613/1000, Validation Loss: 0.0175\n",
      "Epoch 614/1000: 100%|███████████| 63/63 [00:01<00:00, 40.89batch/s, loss=0.0188]\n",
      "Epoch 614/1000, Training Loss: 0.0248\n",
      "Epoch 614/1000, Validation Loss: 0.0166\n",
      "Epoch 615/1000: 100%|███████████| 63/63 [00:01<00:00, 40.87batch/s, loss=0.0185]\n",
      "Epoch 615/1000, Training Loss: 0.0217\n",
      "Epoch 615/1000, Validation Loss: 0.0162\n",
      "Epoch 616/1000: 100%|███████████| 63/63 [00:01<00:00, 39.05batch/s, loss=0.0292]\n",
      "Epoch 616/1000, Training Loss: 0.0244\n",
      "Epoch 616/1000, Validation Loss: 0.0177\n",
      "Epoch 617/1000: 100%|███████████| 63/63 [00:01<00:00, 40.00batch/s, loss=0.0253]\n",
      "Epoch 617/1000, Training Loss: 0.0236\n",
      "Epoch 617/1000, Validation Loss: 0.0211\n",
      "Epoch 618/1000: 100%|███████████| 63/63 [00:01<00:00, 38.57batch/s, loss=0.0102]\n",
      "Epoch 618/1000, Training Loss: 0.0258\n",
      "Epoch 618/1000, Validation Loss: 0.0174\n",
      "Epoch 619/1000: 100%|███████████| 63/63 [00:01<00:00, 39.44batch/s, loss=0.0250]\n",
      "Epoch 619/1000, Training Loss: 0.0235\n",
      "Epoch 619/1000, Validation Loss: 0.0173\n",
      "Epoch 620/1000: 100%|███████████| 63/63 [00:01<00:00, 39.91batch/s, loss=0.0129]\n",
      "Epoch 620/1000, Training Loss: 0.0223\n",
      "Epoch 620/1000, Validation Loss: 0.0181\n",
      "Epoch 621/1000: 100%|███████████| 63/63 [00:01<00:00, 39.63batch/s, loss=0.0655]\n",
      "Epoch 621/1000, Training Loss: 0.0224\n",
      "Epoch 621/1000, Validation Loss: 0.0168\n",
      "Epoch 622/1000: 100%|███████████| 63/63 [00:01<00:00, 40.79batch/s, loss=0.0070]\n",
      "Epoch 622/1000, Training Loss: 0.0215\n",
      "Epoch 622/1000, Validation Loss: 0.0153\n",
      "Epoch 623/1000: 100%|███████████| 63/63 [00:01<00:00, 40.32batch/s, loss=0.0256]\n",
      "Epoch 623/1000, Training Loss: 0.0233\n",
      "Epoch 623/1000, Validation Loss: 0.0155\n",
      "Epoch 624/1000: 100%|███████████| 63/63 [00:01<00:00, 38.61batch/s, loss=0.0255]\n",
      "Epoch 624/1000, Training Loss: 0.0208\n",
      "Epoch 624/1000, Validation Loss: 0.0168\n",
      "Epoch 625/1000: 100%|███████████| 63/63 [00:01<00:00, 38.71batch/s, loss=0.0326]\n",
      "Epoch 625/1000, Training Loss: 0.0217\n",
      "Epoch 625/1000, Validation Loss: 0.0177\n",
      "Epoch 626/1000: 100%|███████████| 63/63 [00:01<00:00, 39.93batch/s, loss=0.0448]\n",
      "Epoch 626/1000, Training Loss: 0.0242\n",
      "Epoch 626/1000, Validation Loss: 0.0180\n",
      "Epoch 627/1000: 100%|███████████| 63/63 [00:01<00:00, 39.45batch/s, loss=0.0122]\n",
      "Epoch 627/1000, Training Loss: 0.0251\n",
      "Epoch 627/1000, Validation Loss: 0.0189\n",
      "Epoch 628/1000: 100%|███████████| 63/63 [00:01<00:00, 40.88batch/s, loss=0.0158]\n",
      "Epoch 628/1000, Training Loss: 0.0232\n",
      "Epoch 628/1000, Validation Loss: 0.0194\n",
      "Epoch 629/1000: 100%|███████████| 63/63 [00:01<00:00, 41.00batch/s, loss=0.0098]\n",
      "Epoch 629/1000, Training Loss: 0.0247\n",
      "Epoch 629/1000, Validation Loss: 0.0195\n",
      "Epoch 630/1000: 100%|███████████| 63/63 [00:01<00:00, 40.54batch/s, loss=0.0222]\n",
      "Epoch 630/1000, Training Loss: 0.0231\n",
      "Epoch 630/1000, Validation Loss: 0.0169\n",
      "Epoch 631/1000: 100%|███████████| 63/63 [00:01<00:00, 40.40batch/s, loss=0.0267]\n",
      "Epoch 631/1000, Training Loss: 0.0205\n",
      "Epoch 631/1000, Validation Loss: 0.0142\n",
      "Epoch 632/1000: 100%|███████████| 63/63 [00:01<00:00, 39.62batch/s, loss=0.0073]\n",
      "Epoch 632/1000, Training Loss: 0.0213\n",
      "Epoch 632/1000, Validation Loss: 0.0164\n",
      "Epoch 633/1000: 100%|███████████| 63/63 [00:01<00:00, 40.39batch/s, loss=0.0445]\n",
      "Epoch 633/1000, Training Loss: 0.0218\n",
      "Epoch 633/1000, Validation Loss: 0.0185\n",
      "Epoch 634/1000: 100%|███████████| 63/63 [00:01<00:00, 40.90batch/s, loss=0.0234]\n",
      "Epoch 634/1000, Training Loss: 0.0245\n",
      "Epoch 634/1000, Validation Loss: 0.0182\n",
      "Epoch 635/1000: 100%|███████████| 63/63 [00:01<00:00, 39.39batch/s, loss=0.0128]\n",
      "Epoch 635/1000, Training Loss: 0.0243\n",
      "Epoch 635/1000, Validation Loss: 0.0210\n",
      "Epoch 636/1000: 100%|███████████| 63/63 [00:01<00:00, 41.16batch/s, loss=0.0210]\n",
      "Epoch 636/1000, Training Loss: 0.0244\n",
      "Epoch 636/1000, Validation Loss: 0.0179\n",
      "Epoch 637/1000: 100%|███████████| 63/63 [00:01<00:00, 39.36batch/s, loss=0.0334]\n",
      "Epoch 637/1000, Training Loss: 0.0244\n",
      "Epoch 637/1000, Validation Loss: 0.0186\n",
      "Epoch 638/1000: 100%|███████████| 63/63 [00:01<00:00, 40.80batch/s, loss=0.0173]\n",
      "Epoch 638/1000, Training Loss: 0.0273\n",
      "Epoch 638/1000, Validation Loss: 0.0193\n",
      "Epoch 639/1000: 100%|███████████| 63/63 [00:01<00:00, 38.97batch/s, loss=0.0214]\n",
      "Epoch 639/1000, Training Loss: 0.0241\n",
      "Epoch 639/1000, Validation Loss: 0.0161\n",
      "Epoch 640/1000: 100%|███████████| 63/63 [00:01<00:00, 39.20batch/s, loss=0.0329]\n",
      "Epoch 640/1000, Training Loss: 0.0233\n",
      "Epoch 640/1000, Validation Loss: 0.0169\n",
      "Epoch 641/1000: 100%|███████████| 63/63 [00:01<00:00, 38.91batch/s, loss=0.0214]\n",
      "Epoch 641/1000, Training Loss: 0.0228\n",
      "Epoch 641/1000, Validation Loss: 0.0192\n",
      "Epoch 642/1000: 100%|███████████| 63/63 [00:01<00:00, 40.03batch/s, loss=0.0368]\n",
      "Epoch 642/1000, Training Loss: 0.0224\n",
      "Epoch 642/1000, Validation Loss: 0.0155\n",
      "Epoch 643/1000: 100%|███████████| 63/63 [00:01<00:00, 38.56batch/s, loss=0.0019]\n",
      "Epoch 643/1000, Training Loss: 0.0222\n",
      "Epoch 643/1000, Validation Loss: 0.0152\n",
      "Epoch 644/1000: 100%|███████████| 63/63 [00:01<00:00, 39.64batch/s, loss=0.0272]\n",
      "Epoch 644/1000, Training Loss: 0.0219\n",
      "Epoch 644/1000, Validation Loss: 0.0159\n",
      "Epoch 645/1000: 100%|███████████| 63/63 [00:01<00:00, 40.56batch/s, loss=0.0187]\n",
      "Epoch 645/1000, Training Loss: 0.0236\n",
      "Epoch 645/1000, Validation Loss: 0.0142\n",
      "Epoch 646/1000: 100%|███████████| 63/63 [00:01<00:00, 38.97batch/s, loss=0.0172]\n",
      "Epoch 646/1000, Training Loss: 0.0218\n",
      "Epoch 646/1000, Validation Loss: 0.0159\n",
      "Epoch 647/1000: 100%|███████████| 63/63 [00:01<00:00, 39.21batch/s, loss=0.0351]\n",
      "Epoch 647/1000, Training Loss: 0.0283\n",
      "Epoch 647/1000, Validation Loss: 0.0206\n",
      "Epoch 648/1000: 100%|███████████| 63/63 [00:01<00:00, 39.98batch/s, loss=0.0216]\n",
      "Epoch 648/1000, Training Loss: 0.0269\n",
      "Epoch 648/1000, Validation Loss: 0.0183\n",
      "Epoch 649/1000: 100%|███████████| 63/63 [00:01<00:00, 38.79batch/s, loss=0.0239]\n",
      "Epoch 649/1000, Training Loss: 0.0244\n",
      "Epoch 649/1000, Validation Loss: 0.0150\n",
      "Epoch 650/1000: 100%|███████████| 63/63 [00:01<00:00, 39.10batch/s, loss=0.0269]\n",
      "Epoch 650/1000, Training Loss: 0.0209\n",
      "Epoch 650/1000, Validation Loss: 0.0168\n",
      "Epoch 651/1000: 100%|███████████| 63/63 [00:01<00:00, 38.95batch/s, loss=0.0174]\n",
      "Epoch 651/1000, Training Loss: 0.0212\n",
      "Epoch 651/1000, Validation Loss: 0.0148\n",
      "Epoch 652/1000: 100%|███████████| 63/63 [00:01<00:00, 40.32batch/s, loss=0.0144]\n",
      "Epoch 652/1000, Training Loss: 0.0201\n",
      "Epoch 652/1000, Validation Loss: 0.0141\n",
      "Epoch 653/1000: 100%|███████████| 63/63 [00:01<00:00, 39.62batch/s, loss=0.0417]\n",
      "Epoch 653/1000, Training Loss: 0.0228\n",
      "Epoch 653/1000, Validation Loss: 0.0234\n",
      "Epoch 654/1000: 100%|███████████| 63/63 [00:01<00:00, 40.46batch/s, loss=0.0308]\n",
      "Epoch 654/1000, Training Loss: 0.0309\n",
      "Epoch 654/1000, Validation Loss: 0.0172\n",
      "Epoch 655/1000: 100%|███████████| 63/63 [00:01<00:00, 39.89batch/s, loss=0.0333]\n",
      "Epoch 655/1000, Training Loss: 0.0214\n",
      "Epoch 655/1000, Validation Loss: 0.0160\n",
      "Epoch 656/1000: 100%|███████████| 63/63 [00:01<00:00, 39.67batch/s, loss=0.0051]\n",
      "Epoch 656/1000, Training Loss: 0.0217\n",
      "Epoch 656/1000, Validation Loss: 0.0161\n",
      "Epoch 657/1000: 100%|███████████| 63/63 [00:01<00:00, 39.18batch/s, loss=0.0260]\n",
      "Epoch 657/1000, Training Loss: 0.0212\n",
      "Epoch 657/1000, Validation Loss: 0.0165\n",
      "Epoch 658/1000: 100%|███████████| 63/63 [00:01<00:00, 40.80batch/s, loss=0.0200]\n",
      "Epoch 658/1000, Training Loss: 0.0215\n",
      "Epoch 658/1000, Validation Loss: 0.0158\n",
      "Epoch 659/1000: 100%|███████████| 63/63 [00:01<00:00, 43.05batch/s, loss=0.0246]\n",
      "Epoch 659/1000, Training Loss: 0.0233\n",
      "Epoch 659/1000, Validation Loss: 0.0146\n",
      "Epoch 660/1000: 100%|███████████| 63/63 [00:01<00:00, 43.96batch/s, loss=0.0295]\n",
      "Epoch 660/1000, Training Loss: 0.0235\n",
      "Epoch 660/1000, Validation Loss: 0.0193\n",
      "Epoch 661/1000: 100%|███████████| 63/63 [00:01<00:00, 42.28batch/s, loss=0.0199]\n",
      "Epoch 661/1000, Training Loss: 0.0204\n",
      "Epoch 661/1000, Validation Loss: 0.0135\n",
      "Epoch 662/1000: 100%|███████████| 63/63 [00:01<00:00, 42.88batch/s, loss=0.0182]\n",
      "Epoch 662/1000, Training Loss: 0.0206\n",
      "Epoch 662/1000, Validation Loss: 0.0133\n",
      "Epoch 663/1000: 100%|███████████| 63/63 [00:01<00:00, 41.75batch/s, loss=0.0152]\n",
      "Epoch 663/1000, Training Loss: 0.0219\n",
      "Epoch 663/1000, Validation Loss: 0.0144\n",
      "Epoch 664/1000: 100%|███████████| 63/63 [00:01<00:00, 44.15batch/s, loss=0.0125]\n",
      "Epoch 664/1000, Training Loss: 0.0197\n",
      "Epoch 664/1000, Validation Loss: 0.0143\n",
      "Epoch 665/1000: 100%|███████████| 63/63 [00:01<00:00, 41.86batch/s, loss=0.0341]\n",
      "Epoch 665/1000, Training Loss: 0.0201\n",
      "Epoch 665/1000, Validation Loss: 0.0153\n",
      "Epoch 666/1000: 100%|███████████| 63/63 [00:01<00:00, 42.39batch/s, loss=0.0121]\n",
      "Epoch 666/1000, Training Loss: 0.0209\n",
      "Epoch 666/1000, Validation Loss: 0.0157\n",
      "Epoch 667/1000: 100%|███████████| 63/63 [00:01<00:00, 40.93batch/s, loss=0.0304]\n",
      "Epoch 667/1000, Training Loss: 0.0209\n",
      "Epoch 667/1000, Validation Loss: 0.0149\n",
      "Epoch 668/1000: 100%|███████████| 63/63 [00:01<00:00, 41.30batch/s, loss=0.0214]\n",
      "Epoch 668/1000, Training Loss: 0.0230\n",
      "Epoch 668/1000, Validation Loss: 0.0155\n",
      "Epoch 669/1000: 100%|███████████| 63/63 [00:01<00:00, 40.90batch/s, loss=0.0136]\n",
      "Epoch 669/1000, Training Loss: 0.0213\n",
      "Epoch 669/1000, Validation Loss: 0.0139\n",
      "Epoch 670/1000: 100%|███████████| 63/63 [00:01<00:00, 41.64batch/s, loss=0.0352]\n",
      "Epoch 670/1000, Training Loss: 0.0223\n",
      "Epoch 670/1000, Validation Loss: 0.0150\n",
      "Epoch 671/1000: 100%|███████████| 63/63 [00:01<00:00, 41.11batch/s, loss=0.0399]\n",
      "Epoch 671/1000, Training Loss: 0.0244\n",
      "Epoch 671/1000, Validation Loss: 0.0163\n",
      "Epoch 672/1000: 100%|███████████| 63/63 [00:01<00:00, 42.29batch/s, loss=0.0128]\n",
      "Epoch 672/1000, Training Loss: 0.0224\n",
      "Epoch 672/1000, Validation Loss: 0.0171\n",
      "Epoch 673/1000: 100%|███████████| 63/63 [00:01<00:00, 42.35batch/s, loss=0.0090]\n",
      "Epoch 673/1000, Training Loss: 0.0230\n",
      "Epoch 673/1000, Validation Loss: 0.0145\n",
      "Epoch 674/1000: 100%|███████████| 63/63 [00:01<00:00, 43.53batch/s, loss=0.0363]\n",
      "Epoch 674/1000, Training Loss: 0.0206\n",
      "Epoch 674/1000, Validation Loss: 0.0157\n",
      "Epoch 675/1000: 100%|███████████| 63/63 [00:01<00:00, 41.50batch/s, loss=0.0247]\n",
      "Epoch 675/1000, Training Loss: 0.0214\n",
      "Epoch 675/1000, Validation Loss: 0.0148\n",
      "Epoch 676/1000: 100%|███████████| 63/63 [00:01<00:00, 43.38batch/s, loss=0.0323]\n",
      "Epoch 676/1000, Training Loss: 0.0216\n",
      "Epoch 676/1000, Validation Loss: 0.0165\n",
      "Epoch 677/1000: 100%|███████████| 63/63 [00:01<00:00, 44.52batch/s, loss=0.0271]\n",
      "Epoch 677/1000, Training Loss: 0.0214\n",
      "Epoch 677/1000, Validation Loss: 0.0152\n",
      "Epoch 678/1000: 100%|███████████| 63/63 [00:01<00:00, 41.13batch/s, loss=0.0193]\n",
      "Epoch 678/1000, Training Loss: 0.0205\n",
      "Epoch 678/1000, Validation Loss: 0.0153\n",
      "Epoch 679/1000: 100%|███████████| 63/63 [00:01<00:00, 42.52batch/s, loss=0.0352]\n",
      "Epoch 679/1000, Training Loss: 0.0220\n",
      "Epoch 679/1000, Validation Loss: 0.0145\n",
      "Epoch 680/1000: 100%|███████████| 63/63 [00:01<00:00, 41.39batch/s, loss=0.0084]\n",
      "Epoch 680/1000, Training Loss: 0.0230\n",
      "Epoch 680/1000, Validation Loss: 0.0153\n",
      "Epoch 681/1000: 100%|███████████| 63/63 [00:01<00:00, 42.63batch/s, loss=0.0235]\n",
      "Epoch 681/1000, Training Loss: 0.0214\n",
      "Epoch 681/1000, Validation Loss: 0.0164\n",
      "Epoch 682/1000: 100%|███████████| 63/63 [00:01<00:00, 41.45batch/s, loss=0.0109]\n",
      "Epoch 682/1000, Training Loss: 0.0233\n",
      "Epoch 682/1000, Validation Loss: 0.0148\n",
      "Epoch 683/1000: 100%|███████████| 63/63 [00:01<00:00, 41.57batch/s, loss=0.0156]\n",
      "Epoch 683/1000, Training Loss: 0.0209\n",
      "Epoch 683/1000, Validation Loss: 0.0152\n",
      "Epoch 684/1000: 100%|███████████| 63/63 [00:01<00:00, 40.68batch/s, loss=0.0132]\n",
      "Epoch 684/1000, Training Loss: 0.0209\n",
      "Epoch 684/1000, Validation Loss: 0.0172\n",
      "Epoch 685/1000: 100%|███████████| 63/63 [00:01<00:00, 42.90batch/s, loss=0.0266]\n",
      "Epoch 685/1000, Training Loss: 0.0224\n",
      "Epoch 685/1000, Validation Loss: 0.0140\n",
      "Epoch 686/1000: 100%|███████████| 63/63 [00:01<00:00, 43.63batch/s, loss=0.0276]\n",
      "Epoch 686/1000, Training Loss: 0.0217\n",
      "Epoch 686/1000, Validation Loss: 0.0138\n",
      "Epoch 687/1000: 100%|███████████| 63/63 [00:01<00:00, 40.98batch/s, loss=0.0195]\n",
      "Epoch 687/1000, Training Loss: 0.0211\n",
      "Epoch 687/1000, Validation Loss: 0.0144\n",
      "Epoch 688/1000: 100%|███████████| 63/63 [00:01<00:00, 43.09batch/s, loss=0.0153]\n",
      "Epoch 688/1000, Training Loss: 0.0223\n",
      "Epoch 688/1000, Validation Loss: 0.0136\n",
      "Epoch 689/1000: 100%|███████████| 63/63 [00:01<00:00, 41.13batch/s, loss=0.0217]\n",
      "Epoch 689/1000, Training Loss: 0.0214\n",
      "Epoch 689/1000, Validation Loss: 0.0151\n",
      "Epoch 690/1000: 100%|███████████| 63/63 [00:01<00:00, 41.20batch/s, loss=0.0157]\n",
      "Epoch 690/1000, Training Loss: 0.0249\n",
      "Epoch 690/1000, Validation Loss: 0.0161\n",
      "Epoch 691/1000: 100%|███████████| 63/63 [00:01<00:00, 44.01batch/s, loss=0.0148]\n",
      "Epoch 691/1000, Training Loss: 0.0228\n",
      "Epoch 691/1000, Validation Loss: 0.0179\n",
      "Epoch 692/1000: 100%|███████████| 63/63 [00:01<00:00, 41.62batch/s, loss=0.0153]\n",
      "Epoch 692/1000, Training Loss: 0.0216\n",
      "Epoch 692/1000, Validation Loss: 0.0181\n",
      "Epoch 693/1000: 100%|███████████| 63/63 [00:01<00:00, 42.29batch/s, loss=0.0204]\n",
      "Epoch 693/1000, Training Loss: 0.0210\n",
      "Epoch 693/1000, Validation Loss: 0.0144\n",
      "Epoch 694/1000: 100%|███████████| 63/63 [00:01<00:00, 41.50batch/s, loss=0.0146]\n",
      "Epoch 694/1000, Training Loss: 0.0224\n",
      "Epoch 694/1000, Validation Loss: 0.0145\n",
      "Epoch 695/1000: 100%|███████████| 63/63 [00:01<00:00, 40.80batch/s, loss=0.0175]\n",
      "Epoch 695/1000, Training Loss: 0.0210\n",
      "Epoch 695/1000, Validation Loss: 0.0155\n",
      "Epoch 696/1000: 100%|███████████| 63/63 [00:01<00:00, 42.93batch/s, loss=0.0305]\n",
      "Epoch 696/1000, Training Loss: 0.0204\n",
      "Epoch 696/1000, Validation Loss: 0.0148\n",
      "Epoch 697/1000: 100%|███████████| 63/63 [00:01<00:00, 43.17batch/s, loss=0.0160]\n",
      "Epoch 697/1000, Training Loss: 0.0218\n",
      "Epoch 697/1000, Validation Loss: 0.0168\n",
      "Epoch 698/1000: 100%|███████████| 63/63 [00:01<00:00, 42.75batch/s, loss=0.0350]\n",
      "Epoch 698/1000, Training Loss: 0.0255\n",
      "Epoch 698/1000, Validation Loss: 0.0176\n",
      "Epoch 699/1000: 100%|███████████| 63/63 [00:01<00:00, 41.39batch/s, loss=0.0140]\n",
      "Epoch 699/1000, Training Loss: 0.0240\n",
      "Epoch 699/1000, Validation Loss: 0.0147\n",
      "Epoch 700/1000: 100%|███████████| 63/63 [00:01<00:00, 43.39batch/s, loss=0.0136]\n",
      "Epoch 700/1000, Training Loss: 0.0208\n",
      "Epoch 700/1000, Validation Loss: 0.0160\n",
      "Epoch 701/1000: 100%|███████████| 63/63 [00:01<00:00, 42.91batch/s, loss=0.0448]\n",
      "Epoch 701/1000, Training Loss: 0.0223\n",
      "Epoch 701/1000, Validation Loss: 0.0173\n",
      "Epoch 702/1000: 100%|███████████| 63/63 [00:01<00:00, 42.71batch/s, loss=0.0279]\n",
      "Epoch 702/1000, Training Loss: 0.0242\n",
      "Epoch 702/1000, Validation Loss: 0.0162\n",
      "Epoch 703/1000: 100%|███████████| 63/63 [00:01<00:00, 42.10batch/s, loss=0.0197]\n",
      "Epoch 703/1000, Training Loss: 0.0236\n",
      "Epoch 703/1000, Validation Loss: 0.0148\n",
      "Epoch 704/1000: 100%|███████████| 63/63 [00:01<00:00, 43.28batch/s, loss=0.0200]\n",
      "Epoch 704/1000, Training Loss: 0.0211\n",
      "Epoch 704/1000, Validation Loss: 0.0149\n",
      "Epoch 705/1000: 100%|███████████| 63/63 [00:01<00:00, 43.17batch/s, loss=0.0139]\n",
      "Epoch 705/1000, Training Loss: 0.0208\n",
      "Epoch 705/1000, Validation Loss: 0.0142\n",
      "Epoch 706/1000: 100%|███████████| 63/63 [00:01<00:00, 42.28batch/s, loss=0.0323]\n",
      "Epoch 706/1000, Training Loss: 0.0197\n",
      "Epoch 706/1000, Validation Loss: 0.0146\n",
      "Epoch 707/1000: 100%|███████████| 63/63 [00:01<00:00, 41.26batch/s, loss=0.0300]\n",
      "Epoch 707/1000, Training Loss: 0.0206\n",
      "Epoch 707/1000, Validation Loss: 0.0150\n",
      "Epoch 708/1000: 100%|███████████| 63/63 [00:01<00:00, 43.22batch/s, loss=0.0306]\n",
      "Epoch 708/1000, Training Loss: 0.0209\n",
      "Epoch 708/1000, Validation Loss: 0.0169\n",
      "Epoch 709/1000: 100%|███████████| 63/63 [00:01<00:00, 44.23batch/s, loss=0.0052]\n",
      "Epoch 709/1000, Training Loss: 0.0206\n",
      "Epoch 709/1000, Validation Loss: 0.0165\n",
      "Epoch 710/1000: 100%|███████████| 63/63 [00:01<00:00, 44.10batch/s, loss=0.0113]\n",
      "Epoch 710/1000, Training Loss: 0.0240\n",
      "Epoch 710/1000, Validation Loss: 0.0156\n",
      "Epoch 711/1000: 100%|███████████| 63/63 [00:01<00:00, 42.75batch/s, loss=0.0042]\n",
      "Epoch 711/1000, Training Loss: 0.0224\n",
      "Epoch 711/1000, Validation Loss: 0.0148\n",
      "Epoch 712/1000: 100%|███████████| 63/63 [00:01<00:00, 44.37batch/s, loss=0.0161]\n",
      "Epoch 712/1000, Training Loss: 0.0239\n",
      "Epoch 712/1000, Validation Loss: 0.0162\n",
      "Epoch 713/1000: 100%|███████████| 63/63 [00:01<00:00, 41.35batch/s, loss=0.0190]\n",
      "Epoch 713/1000, Training Loss: 0.0227\n",
      "Epoch 713/1000, Validation Loss: 0.0156\n",
      "Epoch 714/1000: 100%|███████████| 63/63 [00:01<00:00, 42.45batch/s, loss=0.0274]\n",
      "Epoch 714/1000, Training Loss: 0.0203\n",
      "Epoch 714/1000, Validation Loss: 0.0168\n",
      "Epoch 715/1000: 100%|███████████| 63/63 [00:01<00:00, 43.56batch/s, loss=0.0200]\n",
      "Epoch 715/1000, Training Loss: 0.0217\n",
      "Epoch 715/1000, Validation Loss: 0.0144\n",
      "Epoch 716/1000: 100%|███████████| 63/63 [00:01<00:00, 39.87batch/s, loss=0.0357]\n",
      "Epoch 716/1000, Training Loss: 0.0219\n",
      "Epoch 716/1000, Validation Loss: 0.0151\n",
      "Epoch 717/1000: 100%|███████████| 63/63 [00:01<00:00, 42.13batch/s, loss=0.0084]\n",
      "Epoch 717/1000, Training Loss: 0.0197\n",
      "Epoch 717/1000, Validation Loss: 0.0190\n",
      "Epoch 718/1000: 100%|███████████| 63/63 [00:01<00:00, 41.67batch/s, loss=0.0409]\n",
      "Epoch 718/1000, Training Loss: 0.0202\n",
      "Epoch 718/1000, Validation Loss: 0.0134\n",
      "Epoch 719/1000: 100%|███████████| 63/63 [00:01<00:00, 42.26batch/s, loss=0.0284]\n",
      "Epoch 719/1000, Training Loss: 0.0213\n",
      "Epoch 719/1000, Validation Loss: 0.0143\n",
      "Epoch 720/1000: 100%|███████████| 63/63 [00:01<00:00, 43.54batch/s, loss=0.0101]\n",
      "Epoch 720/1000, Training Loss: 0.0196\n",
      "Epoch 720/1000, Validation Loss: 0.0172\n",
      "Epoch 721/1000: 100%|███████████| 63/63 [00:01<00:00, 42.85batch/s, loss=0.0213]\n",
      "Epoch 721/1000, Training Loss: 0.0204\n",
      "Epoch 721/1000, Validation Loss: 0.0139\n",
      "Epoch 722/1000: 100%|███████████| 63/63 [00:01<00:00, 43.89batch/s, loss=0.0201]\n",
      "Epoch 722/1000, Training Loss: 0.0208\n",
      "Epoch 722/1000, Validation Loss: 0.0138\n",
      "Epoch 723/1000: 100%|███████████| 63/63 [00:01<00:00, 43.06batch/s, loss=0.0189]\n",
      "Epoch 723/1000, Training Loss: 0.0217\n",
      "Epoch 723/1000, Validation Loss: 0.0146\n",
      "Epoch 724/1000: 100%|███████████| 63/63 [00:01<00:00, 41.41batch/s, loss=0.0183]\n",
      "Epoch 724/1000, Training Loss: 0.0195\n",
      "Epoch 724/1000, Validation Loss: 0.0147\n",
      "Epoch 725/1000: 100%|███████████| 63/63 [00:01<00:00, 40.61batch/s, loss=0.0409]\n",
      "Epoch 725/1000, Training Loss: 0.0200\n",
      "Epoch 725/1000, Validation Loss: 0.0153\n",
      "Epoch 726/1000: 100%|███████████| 63/63 [00:01<00:00, 42.77batch/s, loss=0.0159]\n",
      "Epoch 726/1000, Training Loss: 0.0213\n",
      "Epoch 726/1000, Validation Loss: 0.0153\n",
      "Epoch 727/1000: 100%|███████████| 63/63 [00:01<00:00, 41.50batch/s, loss=0.0178]\n",
      "Epoch 727/1000, Training Loss: 0.0210\n",
      "Epoch 727/1000, Validation Loss: 0.0152\n",
      "Epoch 728/1000: 100%|███████████| 63/63 [00:01<00:00, 42.25batch/s, loss=0.0232]\n",
      "Epoch 728/1000, Training Loss: 0.0211\n",
      "Epoch 728/1000, Validation Loss: 0.0153\n",
      "Epoch 729/1000: 100%|███████████| 63/63 [00:01<00:00, 41.12batch/s, loss=0.0322]\n",
      "Epoch 729/1000, Training Loss: 0.0194\n",
      "Epoch 729/1000, Validation Loss: 0.0132\n",
      "Epoch 730/1000: 100%|███████████| 63/63 [00:01<00:00, 41.82batch/s, loss=0.0128]\n",
      "Epoch 730/1000, Training Loss: 0.0209\n",
      "Epoch 730/1000, Validation Loss: 0.0153\n",
      "Epoch 731/1000: 100%|███████████| 63/63 [00:01<00:00, 43.04batch/s, loss=0.0225]\n",
      "Epoch 731/1000, Training Loss: 0.0197\n",
      "Epoch 731/1000, Validation Loss: 0.0140\n",
      "Epoch 732/1000: 100%|███████████| 63/63 [00:01<00:00, 42.24batch/s, loss=0.0237]\n",
      "Epoch 732/1000, Training Loss: 0.0211\n",
      "Epoch 732/1000, Validation Loss: 0.0126\n",
      "Epoch 733/1000: 100%|███████████| 63/63 [00:01<00:00, 40.91batch/s, loss=0.0057]\n",
      "Epoch 733/1000, Training Loss: 0.0201\n",
      "Epoch 733/1000, Validation Loss: 0.0147\n",
      "Epoch 734/1000: 100%|███████████| 63/63 [00:01<00:00, 42.69batch/s, loss=0.0256]\n",
      "Epoch 734/1000, Training Loss: 0.0222\n",
      "Epoch 734/1000, Validation Loss: 0.0147\n",
      "Epoch 735/1000: 100%|███████████| 63/63 [00:01<00:00, 41.67batch/s, loss=0.0199]\n",
      "Epoch 735/1000, Training Loss: 0.0234\n",
      "Epoch 735/1000, Validation Loss: 0.0161\n",
      "Epoch 736/1000: 100%|███████████| 63/63 [00:01<00:00, 41.91batch/s, loss=0.0098]\n",
      "Epoch 736/1000, Training Loss: 0.0254\n",
      "Epoch 736/1000, Validation Loss: 0.0148\n",
      "Epoch 737/1000: 100%|███████████| 63/63 [00:01<00:00, 41.43batch/s, loss=0.0238]\n",
      "Epoch 737/1000, Training Loss: 0.0228\n",
      "Epoch 737/1000, Validation Loss: 0.0163\n",
      "Epoch 738/1000: 100%|███████████| 63/63 [00:01<00:00, 42.02batch/s, loss=0.0138]\n",
      "Epoch 738/1000, Training Loss: 0.0202\n",
      "Epoch 738/1000, Validation Loss: 0.0133\n",
      "Epoch 739/1000: 100%|███████████| 63/63 [00:01<00:00, 41.12batch/s, loss=0.0374]\n",
      "Epoch 739/1000, Training Loss: 0.0216\n",
      "Epoch 739/1000, Validation Loss: 0.0143\n",
      "Epoch 740/1000: 100%|███████████| 63/63 [00:01<00:00, 40.86batch/s, loss=0.0195]\n",
      "Epoch 740/1000, Training Loss: 0.0225\n",
      "Epoch 740/1000, Validation Loss: 0.0140\n",
      "Epoch 741/1000: 100%|███████████| 63/63 [00:01<00:00, 41.03batch/s, loss=0.0293]\n",
      "Epoch 741/1000, Training Loss: 0.0231\n",
      "Epoch 741/1000, Validation Loss: 0.0151\n",
      "Epoch 742/1000: 100%|███████████| 63/63 [00:01<00:00, 40.78batch/s, loss=0.0288]\n",
      "Epoch 742/1000, Training Loss: 0.0220\n",
      "Epoch 742/1000, Validation Loss: 0.0141\n",
      "Epoch 743/1000: 100%|███████████| 63/63 [00:01<00:00, 40.23batch/s, loss=0.0095]\n",
      "Epoch 743/1000, Training Loss: 0.0210\n",
      "Epoch 743/1000, Validation Loss: 0.0162\n",
      "Epoch 744/1000: 100%|███████████| 63/63 [00:01<00:00, 41.55batch/s, loss=0.0256]\n",
      "Epoch 744/1000, Training Loss: 0.0205\n",
      "Epoch 744/1000, Validation Loss: 0.0147\n",
      "Epoch 745/1000: 100%|███████████| 63/63 [00:01<00:00, 40.29batch/s, loss=0.0105]\n",
      "Epoch 745/1000, Training Loss: 0.0199\n",
      "Epoch 745/1000, Validation Loss: 0.0175\n",
      "Epoch 746/1000: 100%|███████████| 63/63 [00:01<00:00, 38.99batch/s, loss=0.0268]\n",
      "Epoch 746/1000, Training Loss: 0.0220\n",
      "Epoch 746/1000, Validation Loss: 0.0182\n",
      "Epoch 747/1000: 100%|███████████| 63/63 [00:01<00:00, 39.59batch/s, loss=0.0127]\n",
      "Epoch 747/1000, Training Loss: 0.0202\n",
      "Epoch 747/1000, Validation Loss: 0.0131\n",
      "Epoch 748/1000: 100%|███████████| 63/63 [00:01<00:00, 40.95batch/s, loss=0.0219]\n",
      "Epoch 748/1000, Training Loss: 0.0196\n",
      "Epoch 748/1000, Validation Loss: 0.0132\n",
      "Epoch 749/1000: 100%|███████████| 63/63 [00:01<00:00, 41.24batch/s, loss=0.0111]\n",
      "Epoch 749/1000, Training Loss: 0.0188\n",
      "Epoch 749/1000, Validation Loss: 0.0131\n",
      "Epoch 750/1000: 100%|███████████| 63/63 [00:01<00:00, 39.37batch/s, loss=0.0181]\n",
      "Epoch 750/1000, Training Loss: 0.0194\n",
      "Epoch 750/1000, Validation Loss: 0.0132\n",
      "Epoch 751/1000: 100%|███████████| 63/63 [00:01<00:00, 39.53batch/s, loss=0.0152]\n",
      "Epoch 751/1000, Training Loss: 0.0189\n",
      "Epoch 751/1000, Validation Loss: 0.0133\n",
      "Epoch 752/1000: 100%|███████████| 63/63 [00:01<00:00, 38.75batch/s, loss=0.0302]\n",
      "Epoch 752/1000, Training Loss: 0.0227\n",
      "Epoch 752/1000, Validation Loss: 0.0196\n",
      "Epoch 753/1000: 100%|███████████| 63/63 [00:01<00:00, 40.41batch/s, loss=0.0102]\n",
      "Epoch 753/1000, Training Loss: 0.0261\n",
      "Epoch 753/1000, Validation Loss: 0.0150\n",
      "Epoch 754/1000: 100%|███████████| 63/63 [00:01<00:00, 42.36batch/s, loss=0.0287]\n",
      "Epoch 754/1000, Training Loss: 0.0216\n",
      "Epoch 754/1000, Validation Loss: 0.0151\n",
      "Epoch 755/1000: 100%|███████████| 63/63 [00:01<00:00, 39.00batch/s, loss=0.0183]\n",
      "Epoch 755/1000, Training Loss: 0.0206\n",
      "Epoch 755/1000, Validation Loss: 0.0136\n",
      "Epoch 756/1000: 100%|███████████| 63/63 [00:01<00:00, 43.11batch/s, loss=0.0096]\n",
      "Epoch 756/1000, Training Loss: 0.0203\n",
      "Epoch 756/1000, Validation Loss: 0.0140\n",
      "Epoch 757/1000: 100%|███████████| 63/63 [00:01<00:00, 43.04batch/s, loss=0.0096]\n",
      "Epoch 757/1000, Training Loss: 0.0205\n",
      "Epoch 757/1000, Validation Loss: 0.0171\n",
      "Epoch 758/1000: 100%|███████████| 63/63 [00:01<00:00, 44.12batch/s, loss=0.0146]\n",
      "Epoch 758/1000, Training Loss: 0.0216\n",
      "Epoch 758/1000, Validation Loss: 0.0137\n",
      "Epoch 759/1000: 100%|███████████| 63/63 [00:01<00:00, 42.26batch/s, loss=0.0120]\n",
      "Epoch 759/1000, Training Loss: 0.0219\n",
      "Epoch 759/1000, Validation Loss: 0.0140\n",
      "Epoch 760/1000: 100%|███████████| 63/63 [00:01<00:00, 42.28batch/s, loss=0.0422]\n",
      "Epoch 760/1000, Training Loss: 0.0197\n",
      "Epoch 760/1000, Validation Loss: 0.0125\n",
      "Epoch 761/1000: 100%|███████████| 63/63 [00:01<00:00, 41.55batch/s, loss=0.0400]\n",
      "Epoch 761/1000, Training Loss: 0.0221\n",
      "Epoch 761/1000, Validation Loss: 0.0142\n",
      "Epoch 762/1000: 100%|███████████| 63/63 [00:01<00:00, 40.35batch/s, loss=0.0259]\n",
      "Epoch 762/1000, Training Loss: 0.0206\n",
      "Epoch 762/1000, Validation Loss: 0.0166\n",
      "Epoch 763/1000: 100%|███████████| 63/63 [00:01<00:00, 39.02batch/s, loss=0.0282]\n",
      "Epoch 763/1000, Training Loss: 0.0222\n",
      "Epoch 763/1000, Validation Loss: 0.0173\n",
      "Epoch 764/1000: 100%|███████████| 63/63 [00:01<00:00, 42.07batch/s, loss=0.0170]\n",
      "Epoch 764/1000, Training Loss: 0.0222\n",
      "Epoch 764/1000, Validation Loss: 0.0149\n",
      "Epoch 765/1000: 100%|███████████| 63/63 [00:01<00:00, 39.86batch/s, loss=0.0201]\n",
      "Epoch 765/1000, Training Loss: 0.0214\n",
      "Epoch 765/1000, Validation Loss: 0.0145\n",
      "Epoch 766/1000: 100%|███████████| 63/63 [00:01<00:00, 39.41batch/s, loss=0.0210]\n",
      "Epoch 766/1000, Training Loss: 0.0209\n",
      "Epoch 766/1000, Validation Loss: 0.0138\n",
      "Epoch 767/1000: 100%|███████████| 63/63 [00:01<00:00, 40.29batch/s, loss=0.0435]\n",
      "Epoch 767/1000, Training Loss: 0.0208\n",
      "Epoch 767/1000, Validation Loss: 0.0141\n",
      "Epoch 768/1000: 100%|███████████| 63/63 [00:01<00:00, 38.18batch/s, loss=0.0161]\n",
      "Epoch 768/1000, Training Loss: 0.0197\n",
      "Epoch 768/1000, Validation Loss: 0.0138\n",
      "Epoch 769/1000: 100%|███████████| 63/63 [00:01<00:00, 41.45batch/s, loss=0.0222]\n",
      "Epoch 769/1000, Training Loss: 0.0203\n",
      "Epoch 769/1000, Validation Loss: 0.0144\n",
      "Epoch 770/1000: 100%|███████████| 63/63 [00:01<00:00, 40.10batch/s, loss=0.0127]\n",
      "Epoch 770/1000, Training Loss: 0.0215\n",
      "Epoch 770/1000, Validation Loss: 0.0165\n",
      "Epoch 771/1000: 100%|███████████| 63/63 [00:01<00:00, 38.85batch/s, loss=0.0228]\n",
      "Epoch 771/1000, Training Loss: 0.0201\n",
      "Epoch 771/1000, Validation Loss: 0.0166\n",
      "Epoch 772/1000: 100%|███████████| 63/63 [00:01<00:00, 37.49batch/s, loss=0.0070]\n",
      "Epoch 772/1000, Training Loss: 0.0204\n",
      "Epoch 772/1000, Validation Loss: 0.0152\n",
      "Epoch 773/1000: 100%|███████████| 63/63 [00:01<00:00, 37.92batch/s, loss=0.0250]\n",
      "Epoch 773/1000, Training Loss: 0.0199\n",
      "Epoch 773/1000, Validation Loss: 0.0168\n",
      "Epoch 774/1000: 100%|███████████| 63/63 [00:01<00:00, 39.19batch/s, loss=0.0106]\n",
      "Epoch 774/1000, Training Loss: 0.0204\n",
      "Epoch 774/1000, Validation Loss: 0.0135\n",
      "Epoch 775/1000: 100%|███████████| 63/63 [00:01<00:00, 39.56batch/s, loss=0.0142]\n",
      "Epoch 775/1000, Training Loss: 0.0197\n",
      "Epoch 775/1000, Validation Loss: 0.0152\n",
      "Epoch 776/1000: 100%|███████████| 63/63 [00:01<00:00, 38.58batch/s, loss=0.0230]\n",
      "Epoch 776/1000, Training Loss: 0.0207\n",
      "Epoch 776/1000, Validation Loss: 0.0164\n",
      "Epoch 777/1000: 100%|███████████| 63/63 [00:01<00:00, 38.19batch/s, loss=0.0151]\n",
      "Epoch 777/1000, Training Loss: 0.0202\n",
      "Epoch 777/1000, Validation Loss: 0.0143\n",
      "Epoch 778/1000: 100%|███████████| 63/63 [00:01<00:00, 38.62batch/s, loss=0.0542]\n",
      "Epoch 778/1000, Training Loss: 0.0199\n",
      "Epoch 778/1000, Validation Loss: 0.0132\n",
      "Epoch 779/1000: 100%|███████████| 63/63 [00:01<00:00, 39.42batch/s, loss=0.0331]\n",
      "Epoch 779/1000, Training Loss: 0.0231\n",
      "Epoch 779/1000, Validation Loss: 0.0144\n",
      "Epoch 780/1000: 100%|███████████| 63/63 [00:01<00:00, 37.90batch/s, loss=0.0173]\n",
      "Epoch 780/1000, Training Loss: 0.0224\n",
      "Epoch 780/1000, Validation Loss: 0.0145\n",
      "Epoch 781/1000: 100%|███████████| 63/63 [00:01<00:00, 40.33batch/s, loss=0.0226]\n",
      "Epoch 781/1000, Training Loss: 0.0211\n",
      "Epoch 781/1000, Validation Loss: 0.0151\n",
      "Epoch 782/1000: 100%|███████████| 63/63 [00:01<00:00, 40.09batch/s, loss=0.0206]\n",
      "Epoch 782/1000, Training Loss: 0.0242\n",
      "Epoch 782/1000, Validation Loss: 0.0164\n",
      "Epoch 783/1000: 100%|███████████| 63/63 [00:01<00:00, 40.13batch/s, loss=0.0263]\n",
      "Epoch 783/1000, Training Loss: 0.0234\n",
      "Epoch 783/1000, Validation Loss: 0.0166\n",
      "Epoch 784/1000: 100%|███████████| 63/63 [00:01<00:00, 36.07batch/s, loss=0.0130]\n",
      "Epoch 784/1000, Training Loss: 0.0195\n",
      "Epoch 784/1000, Validation Loss: 0.0134\n",
      "Epoch 785/1000: 100%|███████████| 63/63 [00:01<00:00, 38.45batch/s, loss=0.0117]\n",
      "Epoch 785/1000, Training Loss: 0.0195\n",
      "Epoch 785/1000, Validation Loss: 0.0131\n",
      "Epoch 786/1000: 100%|███████████| 63/63 [00:01<00:00, 37.86batch/s, loss=0.0117]\n",
      "Epoch 786/1000, Training Loss: 0.0186\n",
      "Epoch 786/1000, Validation Loss: 0.0136\n",
      "Epoch 787/1000: 100%|███████████| 63/63 [00:01<00:00, 40.82batch/s, loss=0.0052]\n",
      "Epoch 787/1000, Training Loss: 0.0216\n",
      "Epoch 787/1000, Validation Loss: 0.0121\n",
      "Epoch 788/1000: 100%|███████████| 63/63 [00:01<00:00, 40.42batch/s, loss=0.0220]\n",
      "Epoch 788/1000, Training Loss: 0.0217\n",
      "Epoch 788/1000, Validation Loss: 0.0143\n",
      "Epoch 789/1000: 100%|███████████| 63/63 [00:01<00:00, 37.24batch/s, loss=0.0145]\n",
      "Epoch 789/1000, Training Loss: 0.0191\n",
      "Epoch 789/1000, Validation Loss: 0.0155\n",
      "Epoch 790/1000: 100%|███████████| 63/63 [00:01<00:00, 38.49batch/s, loss=0.0339]\n",
      "Epoch 790/1000, Training Loss: 0.0197\n",
      "Epoch 790/1000, Validation Loss: 0.0145\n",
      "Epoch 791/1000: 100%|███████████| 63/63 [00:01<00:00, 39.43batch/s, loss=0.0402]\n",
      "Epoch 791/1000, Training Loss: 0.0202\n",
      "Epoch 791/1000, Validation Loss: 0.0162\n",
      "Epoch 792/1000: 100%|███████████| 63/63 [00:01<00:00, 39.31batch/s, loss=0.0106]\n",
      "Epoch 792/1000, Training Loss: 0.0200\n",
      "Epoch 792/1000, Validation Loss: 0.0151\n",
      "Epoch 793/1000: 100%|███████████| 63/63 [00:01<00:00, 40.81batch/s, loss=0.0208]\n",
      "Epoch 793/1000, Training Loss: 0.0227\n",
      "Epoch 793/1000, Validation Loss: 0.0133\n",
      "Epoch 794/1000: 100%|███████████| 63/63 [00:01<00:00, 39.54batch/s, loss=0.0121]\n",
      "Epoch 794/1000, Training Loss: 0.0198\n",
      "Epoch 794/1000, Validation Loss: 0.0147\n",
      "Epoch 795/1000: 100%|███████████| 63/63 [00:01<00:00, 39.59batch/s, loss=0.0240]\n",
      "Epoch 795/1000, Training Loss: 0.0200\n",
      "Epoch 795/1000, Validation Loss: 0.0146\n",
      "Epoch 796/1000: 100%|███████████| 63/63 [00:01<00:00, 40.77batch/s, loss=0.0050]\n",
      "Epoch 796/1000, Training Loss: 0.0226\n",
      "Epoch 796/1000, Validation Loss: 0.0182\n",
      "Epoch 797/1000: 100%|███████████| 63/63 [00:01<00:00, 39.88batch/s, loss=0.0147]\n",
      "Epoch 797/1000, Training Loss: 0.0215\n",
      "Epoch 797/1000, Validation Loss: 0.0160\n",
      "Epoch 798/1000: 100%|███████████| 63/63 [00:01<00:00, 40.10batch/s, loss=0.0150]\n",
      "Epoch 798/1000, Training Loss: 0.0223\n",
      "Epoch 798/1000, Validation Loss: 0.0161\n",
      "Epoch 799/1000: 100%|███████████| 63/63 [00:01<00:00, 38.49batch/s, loss=0.0096]\n",
      "Epoch 799/1000, Training Loss: 0.0205\n",
      "Epoch 799/1000, Validation Loss: 0.0150\n",
      "Epoch 800/1000: 100%|███████████| 63/63 [00:01<00:00, 39.69batch/s, loss=0.0390]\n",
      "Epoch 800/1000, Training Loss: 0.0207\n",
      "Epoch 800/1000, Validation Loss: 0.0163\n",
      "Epoch 801/1000: 100%|███████████| 63/63 [00:01<00:00, 39.63batch/s, loss=0.0096]\n",
      "Epoch 801/1000, Training Loss: 0.0199\n",
      "Epoch 801/1000, Validation Loss: 0.0134\n",
      "Epoch 802/1000: 100%|███████████| 63/63 [00:01<00:00, 39.60batch/s, loss=0.0443]\n",
      "Epoch 802/1000, Training Loss: 0.0204\n",
      "Epoch 802/1000, Validation Loss: 0.0165\n",
      "Epoch 803/1000: 100%|███████████| 63/63 [00:01<00:00, 39.12batch/s, loss=0.0426]\n",
      "Epoch 803/1000, Training Loss: 0.0215\n",
      "Epoch 803/1000, Validation Loss: 0.0147\n",
      "Epoch 804/1000: 100%|███████████| 63/63 [00:01<00:00, 39.36batch/s, loss=0.0168]\n",
      "Epoch 804/1000, Training Loss: 0.0191\n",
      "Epoch 804/1000, Validation Loss: 0.0157\n",
      "Epoch 805/1000: 100%|███████████| 63/63 [00:01<00:00, 38.52batch/s, loss=0.0142]\n",
      "Epoch 805/1000, Training Loss: 0.0195\n",
      "Epoch 805/1000, Validation Loss: 0.0145\n",
      "Epoch 806/1000: 100%|███████████| 63/63 [00:01<00:00, 39.99batch/s, loss=0.0166]\n",
      "Epoch 806/1000, Training Loss: 0.0215\n",
      "Epoch 806/1000, Validation Loss: 0.0161\n",
      "Epoch 807/1000: 100%|███████████| 63/63 [00:01<00:00, 39.65batch/s, loss=0.0181]\n",
      "Epoch 807/1000, Training Loss: 0.0192\n",
      "Epoch 807/1000, Validation Loss: 0.0130\n",
      "Epoch 808/1000: 100%|███████████| 63/63 [00:01<00:00, 38.93batch/s, loss=0.0177]\n",
      "Epoch 808/1000, Training Loss: 0.0195\n",
      "Epoch 808/1000, Validation Loss: 0.0129\n",
      "Epoch 809/1000: 100%|███████████| 63/63 [00:01<00:00, 38.91batch/s, loss=0.0275]\n",
      "Epoch 809/1000, Training Loss: 0.0193\n",
      "Epoch 809/1000, Validation Loss: 0.0157\n",
      "Epoch 810/1000: 100%|███████████| 63/63 [00:01<00:00, 38.39batch/s, loss=0.0331]\n",
      "Epoch 810/1000, Training Loss: 0.0205\n",
      "Epoch 810/1000, Validation Loss: 0.0146\n",
      "Epoch 811/1000: 100%|███████████| 63/63 [00:01<00:00, 39.13batch/s, loss=0.0119]\n",
      "Epoch 811/1000, Training Loss: 0.0204\n",
      "Epoch 811/1000, Validation Loss: 0.0158\n",
      "Epoch 812/1000: 100%|███████████| 63/63 [00:01<00:00, 39.03batch/s, loss=0.0185]\n",
      "Epoch 812/1000, Training Loss: 0.0202\n",
      "Epoch 812/1000, Validation Loss: 0.0143\n",
      "Epoch 813/1000: 100%|███████████| 63/63 [00:01<00:00, 38.37batch/s, loss=0.0130]\n",
      "Epoch 813/1000, Training Loss: 0.0188\n",
      "Epoch 813/1000, Validation Loss: 0.0162\n",
      "Epoch 814/1000: 100%|███████████| 63/63 [00:01<00:00, 38.08batch/s, loss=0.0184]\n",
      "Epoch 814/1000, Training Loss: 0.0202\n",
      "Epoch 814/1000, Validation Loss: 0.0186\n",
      "Epoch 815/1000: 100%|███████████| 63/63 [00:01<00:00, 36.88batch/s, loss=0.0159]\n",
      "Epoch 815/1000, Training Loss: 0.0202\n",
      "Epoch 815/1000, Validation Loss: 0.0132\n",
      "Epoch 816/1000: 100%|███████████| 63/63 [00:01<00:00, 37.76batch/s, loss=0.0216]\n",
      "Epoch 816/1000, Training Loss: 0.0199\n",
      "Epoch 816/1000, Validation Loss: 0.0151\n",
      "Epoch 817/1000: 100%|███████████| 63/63 [00:01<00:00, 36.74batch/s, loss=0.0264]\n",
      "Epoch 817/1000, Training Loss: 0.0192\n",
      "Epoch 817/1000, Validation Loss: 0.0138\n",
      "Epoch 818/1000: 100%|███████████| 63/63 [00:01<00:00, 39.02batch/s, loss=0.0136]\n",
      "Epoch 818/1000, Training Loss: 0.0232\n",
      "Epoch 818/1000, Validation Loss: 0.0149\n",
      "Epoch 819/1000: 100%|███████████| 63/63 [00:01<00:00, 37.55batch/s, loss=0.0469]\n",
      "Epoch 819/1000, Training Loss: 0.0208\n",
      "Epoch 819/1000, Validation Loss: 0.0151\n",
      "Epoch 820/1000: 100%|███████████| 63/63 [00:01<00:00, 40.14batch/s, loss=0.0129]\n",
      "Epoch 820/1000, Training Loss: 0.0195\n",
      "Epoch 820/1000, Validation Loss: 0.0125\n",
      "Epoch 821/1000: 100%|███████████| 63/63 [00:01<00:00, 39.15batch/s, loss=0.0286]\n",
      "Epoch 821/1000, Training Loss: 0.0184\n",
      "Epoch 821/1000, Validation Loss: 0.0142\n",
      "Epoch 822/1000: 100%|███████████| 63/63 [00:01<00:00, 40.32batch/s, loss=0.0140]\n",
      "Epoch 822/1000, Training Loss: 0.0206\n",
      "Epoch 822/1000, Validation Loss: 0.0164\n",
      "Epoch 823/1000: 100%|███████████| 63/63 [00:01<00:00, 39.23batch/s, loss=0.0196]\n",
      "Epoch 823/1000, Training Loss: 0.0197\n",
      "Epoch 823/1000, Validation Loss: 0.0136\n",
      "Epoch 824/1000: 100%|███████████| 63/63 [00:01<00:00, 39.62batch/s, loss=0.0042]\n",
      "Epoch 824/1000, Training Loss: 0.0192\n",
      "Epoch 824/1000, Validation Loss: 0.0160\n",
      "Epoch 825/1000: 100%|███████████| 63/63 [00:01<00:00, 39.26batch/s, loss=0.0181]\n",
      "Epoch 825/1000, Training Loss: 0.0203\n",
      "Epoch 825/1000, Validation Loss: 0.0151\n",
      "Epoch 826/1000: 100%|███████████| 63/63 [00:01<00:00, 40.16batch/s, loss=0.0098]\n",
      "Epoch 826/1000, Training Loss: 0.0205\n",
      "Epoch 826/1000, Validation Loss: 0.0154\n",
      "Epoch 827/1000: 100%|███████████| 63/63 [00:01<00:00, 38.41batch/s, loss=0.0109]\n",
      "Epoch 827/1000, Training Loss: 0.0211\n",
      "Epoch 827/1000, Validation Loss: 0.0143\n",
      "Epoch 828/1000: 100%|███████████| 63/63 [00:01<00:00, 38.24batch/s, loss=0.0150]\n",
      "Epoch 828/1000, Training Loss: 0.0202\n",
      "Epoch 828/1000, Validation Loss: 0.0149\n",
      "Epoch 829/1000: 100%|███████████| 63/63 [00:01<00:00, 36.77batch/s, loss=0.0081]\n",
      "Epoch 829/1000, Training Loss: 0.0214\n",
      "Epoch 829/1000, Validation Loss: 0.0136\n",
      "Epoch 830/1000: 100%|███████████| 63/63 [00:01<00:00, 34.60batch/s, loss=0.0392]\n",
      "Epoch 830/1000, Training Loss: 0.0207\n",
      "Epoch 830/1000, Validation Loss: 0.0148\n",
      "Epoch 831/1000: 100%|███████████| 63/63 [00:01<00:00, 38.81batch/s, loss=0.0237]\n",
      "Epoch 831/1000, Training Loss: 0.0218\n",
      "Epoch 831/1000, Validation Loss: 0.0175\n",
      "Epoch 832/1000: 100%|███████████| 63/63 [00:01<00:00, 37.56batch/s, loss=0.0216]\n",
      "Epoch 832/1000, Training Loss: 0.0205\n",
      "Epoch 832/1000, Validation Loss: 0.0141\n",
      "Epoch 833/1000: 100%|███████████| 63/63 [00:01<00:00, 39.33batch/s, loss=0.0194]\n",
      "Epoch 833/1000, Training Loss: 0.0205\n",
      "Epoch 833/1000, Validation Loss: 0.0142\n",
      "Epoch 834/1000: 100%|███████████| 63/63 [00:01<00:00, 39.73batch/s, loss=0.0169]\n",
      "Epoch 834/1000, Training Loss: 0.0189\n",
      "Epoch 834/1000, Validation Loss: 0.0148\n",
      "Epoch 835/1000: 100%|███████████| 63/63 [00:01<00:00, 38.97batch/s, loss=0.0126]\n",
      "Epoch 835/1000, Training Loss: 0.0195\n",
      "Epoch 835/1000, Validation Loss: 0.0141\n",
      "Epoch 836/1000: 100%|███████████| 63/63 [00:01<00:00, 38.25batch/s, loss=0.0122]\n",
      "Epoch 836/1000, Training Loss: 0.0179\n",
      "Epoch 836/1000, Validation Loss: 0.0144\n",
      "Epoch 837/1000: 100%|███████████| 63/63 [00:01<00:00, 37.40batch/s, loss=0.0326]\n",
      "Epoch 837/1000, Training Loss: 0.0192\n",
      "Epoch 837/1000, Validation Loss: 0.0156\n",
      "Epoch 838/1000: 100%|███████████| 63/63 [00:01<00:00, 38.19batch/s, loss=0.0048]\n",
      "Epoch 838/1000, Training Loss: 0.0208\n",
      "Epoch 838/1000, Validation Loss: 0.0165\n",
      "Epoch 839/1000: 100%|███████████| 63/63 [00:01<00:00, 39.58batch/s, loss=0.0274]\n",
      "Epoch 839/1000, Training Loss: 0.0200\n",
      "Epoch 839/1000, Validation Loss: 0.0144\n",
      "Epoch 840/1000: 100%|███████████| 63/63 [00:01<00:00, 38.11batch/s, loss=0.0153]\n",
      "Epoch 840/1000, Training Loss: 0.0196\n",
      "Epoch 840/1000, Validation Loss: 0.0141\n",
      "Epoch 841/1000: 100%|███████████| 63/63 [00:01<00:00, 38.78batch/s, loss=0.0284]\n",
      "Epoch 841/1000, Training Loss: 0.0183\n",
      "Epoch 841/1000, Validation Loss: 0.0142\n",
      "Epoch 842/1000: 100%|███████████| 63/63 [00:01<00:00, 40.28batch/s, loss=0.0124]\n",
      "Epoch 842/1000, Training Loss: 0.0223\n",
      "Epoch 842/1000, Validation Loss: 0.0124\n",
      "Epoch 843/1000: 100%|███████████| 63/63 [00:01<00:00, 38.76batch/s, loss=0.0377]\n",
      "Epoch 843/1000, Training Loss: 0.0211\n",
      "Epoch 843/1000, Validation Loss: 0.0141\n",
      "Epoch 844/1000: 100%|███████████| 63/63 [00:01<00:00, 39.68batch/s, loss=0.0435]\n",
      "Epoch 844/1000, Training Loss: 0.0199\n",
      "Epoch 844/1000, Validation Loss: 0.0121\n",
      "Epoch 845/1000: 100%|███████████| 63/63 [00:01<00:00, 38.83batch/s, loss=0.0348]\n",
      "Epoch 845/1000, Training Loss: 0.0205\n",
      "Epoch 845/1000, Validation Loss: 0.0166\n",
      "Epoch 846/1000: 100%|███████████| 63/63 [00:01<00:00, 38.82batch/s, loss=0.0098]\n",
      "Epoch 846/1000, Training Loss: 0.0213\n",
      "Epoch 846/1000, Validation Loss: 0.0155\n",
      "Epoch 847/1000: 100%|███████████| 63/63 [00:01<00:00, 39.88batch/s, loss=0.0208]\n",
      "Epoch 847/1000, Training Loss: 0.0185\n",
      "Epoch 847/1000, Validation Loss: 0.0183\n",
      "Epoch 848/1000: 100%|███████████| 63/63 [00:01<00:00, 38.85batch/s, loss=0.0216]\n",
      "Epoch 848/1000, Training Loss: 0.0189\n",
      "Epoch 848/1000, Validation Loss: 0.0143\n",
      "Epoch 849/1000: 100%|███████████| 63/63 [00:01<00:00, 40.37batch/s, loss=0.0279]\n",
      "Epoch 849/1000, Training Loss: 0.0194\n",
      "Epoch 849/1000, Validation Loss: 0.0119\n",
      "Epoch 850/1000: 100%|███████████| 63/63 [00:01<00:00, 39.89batch/s, loss=0.0365]\n",
      "Epoch 850/1000, Training Loss: 0.0238\n",
      "Epoch 850/1000, Validation Loss: 0.0123\n",
      "Epoch 851/1000: 100%|███████████| 63/63 [00:01<00:00, 41.34batch/s, loss=0.0091]\n",
      "Epoch 851/1000, Training Loss: 0.0202\n",
      "Epoch 851/1000, Validation Loss: 0.0148\n",
      "Epoch 852/1000: 100%|███████████| 63/63 [00:01<00:00, 42.02batch/s, loss=0.0145]\n",
      "Epoch 852/1000, Training Loss: 0.0195\n",
      "Epoch 852/1000, Validation Loss: 0.0134\n",
      "Epoch 853/1000: 100%|███████████| 63/63 [00:01<00:00, 38.86batch/s, loss=0.0227]\n",
      "Epoch 853/1000, Training Loss: 0.0202\n",
      "Epoch 853/1000, Validation Loss: 0.0127\n",
      "Epoch 854/1000: 100%|███████████| 63/63 [00:01<00:00, 39.93batch/s, loss=0.0146]\n",
      "Epoch 854/1000, Training Loss: 0.0196\n",
      "Epoch 854/1000, Validation Loss: 0.0138\n",
      "Epoch 855/1000: 100%|███████████| 63/63 [00:01<00:00, 38.93batch/s, loss=0.0123]\n",
      "Epoch 855/1000, Training Loss: 0.0200\n",
      "Epoch 855/1000, Validation Loss: 0.0142\n",
      "Epoch 856/1000: 100%|███████████| 63/63 [00:01<00:00, 39.86batch/s, loss=0.0320]\n",
      "Epoch 856/1000, Training Loss: 0.0189\n",
      "Epoch 856/1000, Validation Loss: 0.0166\n",
      "Epoch 857/1000: 100%|███████████| 63/63 [00:01<00:00, 40.34batch/s, loss=0.0125]\n",
      "Epoch 857/1000, Training Loss: 0.0210\n",
      "Epoch 857/1000, Validation Loss: 0.0191\n",
      "Epoch 858/1000: 100%|███████████| 63/63 [00:01<00:00, 40.83batch/s, loss=0.0098]\n",
      "Epoch 858/1000, Training Loss: 0.0191\n",
      "Epoch 858/1000, Validation Loss: 0.0139\n",
      "Epoch 859/1000: 100%|███████████| 63/63 [00:01<00:00, 40.50batch/s, loss=0.0296]\n",
      "Epoch 859/1000, Training Loss: 0.0211\n",
      "Epoch 859/1000, Validation Loss: 0.0159\n",
      "Epoch 860/1000: 100%|███████████| 63/63 [00:01<00:00, 41.22batch/s, loss=0.0170]\n",
      "Epoch 860/1000, Training Loss: 0.0193\n",
      "Epoch 860/1000, Validation Loss: 0.0136\n",
      "Epoch 861/1000: 100%|███████████| 63/63 [00:01<00:00, 41.13batch/s, loss=0.0183]\n",
      "Epoch 861/1000, Training Loss: 0.0178\n",
      "Epoch 861/1000, Validation Loss: 0.0141\n",
      "Epoch 862/1000: 100%|███████████| 63/63 [00:01<00:00, 39.35batch/s, loss=0.0225]\n",
      "Epoch 862/1000, Training Loss: 0.0210\n",
      "Epoch 862/1000, Validation Loss: 0.0139\n",
      "Epoch 863/1000: 100%|███████████| 63/63 [00:01<00:00, 39.52batch/s, loss=0.0069]\n",
      "Epoch 863/1000, Training Loss: 0.0187\n",
      "Epoch 863/1000, Validation Loss: 0.0137\n",
      "Epoch 864/1000: 100%|███████████| 63/63 [00:01<00:00, 42.15batch/s, loss=0.0094]\n",
      "Epoch 864/1000, Training Loss: 0.0176\n",
      "Epoch 864/1000, Validation Loss: 0.0121\n",
      "Epoch 865/1000: 100%|███████████| 63/63 [00:01<00:00, 41.04batch/s, loss=0.0051]\n",
      "Epoch 865/1000, Training Loss: 0.0194\n",
      "Epoch 865/1000, Validation Loss: 0.0124\n",
      "Epoch 866/1000: 100%|███████████| 63/63 [00:01<00:00, 39.06batch/s, loss=0.0165]\n",
      "Epoch 866/1000, Training Loss: 0.0180\n",
      "Epoch 866/1000, Validation Loss: 0.0131\n",
      "Epoch 867/1000: 100%|███████████| 63/63 [00:01<00:00, 41.97batch/s, loss=0.0242]\n",
      "Epoch 867/1000, Training Loss: 0.0189\n",
      "Epoch 867/1000, Validation Loss: 0.0147\n",
      "Epoch 868/1000: 100%|███████████| 63/63 [00:01<00:00, 41.87batch/s, loss=0.0331]\n",
      "Epoch 868/1000, Training Loss: 0.0188\n",
      "Epoch 868/1000, Validation Loss: 0.0144\n",
      "Epoch 869/1000: 100%|███████████| 63/63 [00:01<00:00, 42.06batch/s, loss=0.0092]\n",
      "Epoch 869/1000, Training Loss: 0.0202\n",
      "Epoch 869/1000, Validation Loss: 0.0135\n",
      "Epoch 870/1000: 100%|███████████| 63/63 [00:01<00:00, 42.03batch/s, loss=0.0208]\n",
      "Epoch 870/1000, Training Loss: 0.0191\n",
      "Epoch 870/1000, Validation Loss: 0.0125\n",
      "Epoch 871/1000: 100%|███████████| 63/63 [00:01<00:00, 40.50batch/s, loss=0.0248]\n",
      "Epoch 871/1000, Training Loss: 0.0176\n",
      "Epoch 871/1000, Validation Loss: 0.0144\n",
      "Epoch 872/1000: 100%|███████████| 63/63 [00:01<00:00, 40.36batch/s, loss=0.0605]\n",
      "Epoch 872/1000, Training Loss: 0.0208\n",
      "Epoch 872/1000, Validation Loss: 0.0159\n",
      "Epoch 873/1000: 100%|███████████| 63/63 [00:01<00:00, 39.92batch/s, loss=0.0161]\n",
      "Epoch 873/1000, Training Loss: 0.0216\n",
      "Epoch 873/1000, Validation Loss: 0.0177\n",
      "Epoch 874/1000: 100%|███████████| 63/63 [00:01<00:00, 41.15batch/s, loss=0.0107]\n",
      "Epoch 874/1000, Training Loss: 0.0197\n",
      "Epoch 874/1000, Validation Loss: 0.0145\n",
      "Epoch 875/1000: 100%|███████████| 63/63 [00:01<00:00, 41.27batch/s, loss=0.0243]\n",
      "Epoch 875/1000, Training Loss: 0.0204\n",
      "Epoch 875/1000, Validation Loss: 0.0144\n",
      "Epoch 876/1000: 100%|███████████| 63/63 [00:01<00:00, 39.19batch/s, loss=0.0131]\n",
      "Epoch 876/1000, Training Loss: 0.0195\n",
      "Epoch 876/1000, Validation Loss: 0.0127\n",
      "Epoch 877/1000: 100%|███████████| 63/63 [00:01<00:00, 38.43batch/s, loss=0.0101]\n",
      "Epoch 877/1000, Training Loss: 0.0182\n",
      "Epoch 877/1000, Validation Loss: 0.0150\n",
      "Epoch 878/1000: 100%|███████████| 63/63 [00:01<00:00, 39.61batch/s, loss=0.0226]\n",
      "Epoch 878/1000, Training Loss: 0.0180\n",
      "Epoch 878/1000, Validation Loss: 0.0135\n",
      "Epoch 879/1000: 100%|███████████| 63/63 [00:01<00:00, 39.23batch/s, loss=0.0101]\n",
      "Epoch 879/1000, Training Loss: 0.0189\n",
      "Epoch 879/1000, Validation Loss: 0.0138\n",
      "Epoch 880/1000: 100%|███████████| 63/63 [00:01<00:00, 36.51batch/s, loss=0.0198]\n",
      "Epoch 880/1000, Training Loss: 0.0197\n",
      "Epoch 880/1000, Validation Loss: 0.0159\n",
      "Epoch 881/1000: 100%|███████████| 63/63 [00:01<00:00, 38.70batch/s, loss=0.0333]\n",
      "Epoch 881/1000, Training Loss: 0.0204\n",
      "Epoch 881/1000, Validation Loss: 0.0140\n",
      "Epoch 882/1000: 100%|███████████| 63/63 [00:01<00:00, 37.56batch/s, loss=0.0067]\n",
      "Epoch 882/1000, Training Loss: 0.0202\n",
      "Epoch 882/1000, Validation Loss: 0.0130\n",
      "Epoch 883/1000:  76%|████████▍  | 48/63 [00:01<00:00, 36.79batch/s, loss=0.0194]^C\n",
      "Epoch 883/1000:  76%|████████▍  | 48/63 [00:01<00:00, 37.04batch/s, loss=0.0194]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/james/Documents/UniWork/GDL/NAR_project/clrs/interp/train.py\", line 182, in <module>\n",
      "    main(args)\n",
      "  File \"/home/james/Documents/UniWork/GDL/NAR_project/clrs/interp/train.py\", line 139, in main\n",
      "    train_loss = train_one_epoch(model, train_dataloader, optimizer, device, epoch, num_epochs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/james/Documents/UniWork/GDL/NAR_project/clrs/interp/train.py\", line 49, in train_one_epoch\n",
      "    optimizer.zero_grad()\n",
      "  File \"/home/james/anaconda3/envs/gdl_env/lib/python3.11/site-packages/torch/_compile.py\", line 32, in inner\n",
      "    return disable_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/james/anaconda3/envs/gdl_env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 745, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/james/anaconda3/envs/gdl_env/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 975, in zero_grad\n",
      "    p.grad = None\n",
      "    ^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m interp.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c937ca6e-48bd-40f4-b6fb-4f8efe119b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.337585244178772"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interp.models import DummyModel\n",
    "from interp.train import evaluate\n",
    "from interp.dataset import HDF5Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_dataset = HDF5Dataset(\"data/interp_data_7_eval.h5\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "m = DummyModel()\n",
    "evaluate(m, val_dataloader, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e01947-a43d-42af-8d23-549918a89f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
